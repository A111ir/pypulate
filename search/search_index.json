{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Pypulate Documentation","text":"<p>Pypulate framework</p> <p>High performance financial and business analytics framework</p> <p> </p> <p>Welcome to Pypulate, a high-performance Python framework for financial analysis and business metrics. Pypulate offers powerful classes designed to handle different aspects of financial and business analytics (more to come):</p>"},{"location":"#core-components","title":"Core Components","text":""},{"location":"#parray-pypulate-array","title":"Parray (Pypulate Array)","text":"<p>A specialized array class for financial time series analysis with built-in technical analysis capabilities and chain methodss:</p> <pre><code>from pypulate import Parray\n\n# Create a price array\nprices = Parray([10, 11, 12, 11, 10, 9, 10, 11, 12, 13, 15, 11, 8, 10, 14, 16])\n\n# Technical Analysis\nsma = prices.sma(5)                   \nrsi = prices.rsi(14)                  \nbb_upper, bb_mid, bb_lower = prices.bollinger_bands(20, 2)\n\n# Signal Detection\ngolden_cross = prices.sma(5).crossover(prices.sma(10))\ndeath_cross = prices.sma(5).crossunder(prices.sma(10))\n\n# Volatility Analysis\nvolatility = prices.historical_volatility(7)\n</code></pre>"},{"location":"#kpi-key-performance-indicators","title":"KPI (Key Performance Indicators)","text":"<p>A comprehensive class for calculating and tracking business metrics:</p> <pre><code>from pypulate import KPI\n\nkpi = KPI()\n\n# Customer Metrics\nchurn = kpi.churn_rate(customers_start=1000, customers_end=950, new_customers=50)\nretention = kpi.retention_rate(customers_start=1000, customers_end=950, new_customers=50)\n\n# Financial Metrics\nclv = kpi.customer_lifetime_value(\n    avg_revenue_per_customer=100,\n    gross_margin=70,\n    churn_rate_value=5\n)\n\n# Health Assessment\nhealth = kpi.health  # Returns overall business health score and component analysis\n</code></pre>"},{"location":"#portfolio","title":"Portfolio","text":"<p>A class for portfolio analysis and risk management:</p> <pre><code>from pypulate import Portfolio\nimport numpy as np\n\nportfolio = Portfolio()\n\n# Sample data\nstart = [100, 102, 105, 103, 107, 108, 107, 110, 112, 111]\nend = [110, 95, 111, 103, 130, 89, 99, 104, 102, 100]\n\ncash_flows = [0, -1000, 0, 500, 0, -2000, 0, 1000, 0, 0]\nrisk_free_rate = 0.02\n\n# Return Metrics\nreturns = portfolio.simple_return(end, start)\nlog_ret = portfolio.log_return(end, start)\n\n# Risk Metrics\nsharpe = portfolio.sharpe_ratio(returns, risk_free_rate)\nvar = portfolio.value_at_risk(returns, confidence_level=0.95)\ndd = portfolio.drawdown(returns)\n\n# Portfolio Health\nhealth = portfolio.health  # Returns portfolio health analysis\n</code></pre>"},{"location":"#allocation","title":"Allocation","text":"<p>A comprehensive class for portfolio optimization and asset allocation:</p> <pre><code>from pypulate import Allocation\nimport numpy as np\n\nallocation = Allocation()\n\n# Sample returns data (252 days, 5 assets)\nreturns = np.random.normal(0.0001, 0.02, (252, 5))\nrisk_free_rate = 0.04\n\n# Mean-Variance Optimization\nweights, ret, risk = allocation.mean_variance(returns, risk_free_rate=risk_free_rate)\n\n# Risk Parity Portfolio\nweights, ret, risk = allocation.risk_parity(returns)\n\n# Kelly Criterion (with half-Kelly for conservative sizing)\nweights, ret, risk = allocation.kelly_criterion(returns, kelly_fraction=0.5)\n\n# Black-Litterman with views\nviews = {0: 0.15, 1: 0.12}  # Views on first two assets\nview_confidences = {0: 0.8, 1: 0.7}\nmarket_caps = np.array([1000, 800, 600, 400, 200])\nweights, ret, risk = allocation.black_litterman(\n    returns, market_caps, views, view_confidences\n)\n\n# Hierarchical Risk Parity\nweights, ret, risk = allocation.hierarchical_risk_parity(returns)\n</code></pre>"},{"location":"#servicepricing","title":"ServicePricing","text":"<p>A unified interface for calculating and managing various service pricing models:</p> <pre><code>from pypulate import ServicePricing\n\npricing = ServicePricing()\n\n# Tiered Pricing\nprice = pricing.calculate_tiered_price(\n    usage_units=1500,\n    tiers={\n        \"0-1000\": 0.10,    # $0.10 per unit for first 1000 units\n        \"1001-2000\": 0.08, # $0.08 per unit for next 500 units\n        \"2001+\": 0.05      # $0.05 per unit for remaining units\n    }\n)\n\n# Subscription with Features\nsub_price = pricing.calculate_subscription_price(\n    base_price=99.99,\n    features=['premium', 'api_access'],\n    feature_prices={'premium': 49.99, 'api_access': 29.99},\n    duration_months=12,\n    discount_rate=0.10\n)\n\n# Dynamic Pricing\ndynamic_price = pricing.apply_dynamic_pricing(\n    base_price=100.0,\n    demand_factor=1.2,\n    competition_factor=0.9,\n    seasonality_factor=1.1\n)\n\n# Track Pricing History\npricing.save_current_pricing()\nhistory = pricing.get_pricing_history()\n</code></pre>"},{"location":"#creditscoring","title":"CreditScoring","text":"<p>A comprehensive class for credit risk assessment, scoring, and loan analysis:</p> <pre><code>from pypulate.dtypes import CreditScoring\n\ncredit = CreditScoring()\n\n# Corporate Bankruptcy Risk Assessment\nz_score = credit.altman_z_score(\n    working_capital=1200000,\n    retained_earnings=1500000,\n    ebit=800000,\n    market_value_equity=5000000,\n    sales=4500000,\n    total_assets=6000000,\n    total_liabilities=2500000\n)\n\n# Default Probability Using Structural Model\npd_result = credit.merton_model(\n    asset_value=10000000,\n    debt_face_value=5000000,\n    asset_volatility=0.25,\n    risk_free_rate=0.03,\n    time_to_maturity=1.0\n)\n\n# Retail Credit Scoring\nscorecard_result = credit.create_scorecard(\n    features={\"age\": 35, \"income\": 75000, \"years_employed\": 5},\n    weights={\"age\": 2.5, \"income\": 3.2, \"years_employed\": 4.0},\n    scaling_factor=20,\n    base_score=600\n)\n\n# Financial Ratio Analysis\nratios = credit.financial_ratios(\n    current_assets=2000000,\n    current_liabilities=1200000,\n    total_assets=8000000,\n    total_liabilities=4000000,\n    ebit=1200000,\n    interest_expense=300000,\n    net_income=700000,\n    total_equity=4000000,\n    sales=6000000\n)\n\n# Risk-Based Loan Pricing\npricing = credit.loan_pricing(\n    loan_amount=250000,\n    term=5,\n    pd=0.03,\n    lgd=0.35,\n    funding_cost=0.04,\n    operating_cost=0.01,\n    capital_requirement=0.08,\n    target_roe=0.15\n)\n\n# Expected Credit Loss Calculation\necl = credit.expected_credit_loss(\n    pd=0.05,\n    lgd=0.4,\n    ead=100000\n)\n\n# Model Usage History\nhistory = credit.get_history()\n</code></pre>"},{"location":"#installation","title":"Installation","text":"<pre><code>pip install pypulate\n</code></pre>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Parray: </li> <li>Technical indicators (30+ implementations)</li> <li>Signal detection and pattern recognition</li> <li>Time series transformations</li> <li> <p>Built-in filtering methods</p> </li> <li> <p>KPI:</p> </li> <li>Customer metrics (churn, retention, LTV)</li> <li>Financial metrics (ROI, CAC, ARR)</li> <li>Engagement metrics (NPS, CSAT)</li> <li> <p>Health scoring system</p> </li> <li> <p>Portfolio:</p> </li> <li>Return calculations</li> <li>Risk metrics</li> <li>Performance attribution</li> <li> <p>Health assessment</p> </li> <li> <p>Allocation:</p> </li> <li>Portfolio optimization</li> <li>Asset allocation</li> <li> <p>Risk management</p> </li> <li> <p>ServicePricing:</p> </li> <li>Tiered pricing models</li> <li>Subscription pricing with features</li> <li>Usage-based pricing</li> <li>Dynamic pricing adjustments</li> <li>Volume discounts</li> <li>Custom pricing rules</li> <li> <p>Pricing history tracking</p> </li> <li> <p>CreditScoring:</p> </li> <li>Bankruptcy prediction models</li> <li>Default probability estimation</li> <li>Credit scorecard development</li> <li>Financial ratio analysis</li> <li>Expected credit loss calculation</li> <li>Risk-based loan pricing</li> <li>Credit model validation</li> <li>Loss given default estimation</li> <li>Exposure at default calculation</li> </ul>"},{"location":"#user-guide","title":"User Guide","text":"<ul> <li>Getting Started</li> <li>Parray Guide</li> <li>KPI Guide</li> <li>Portfolio Guide</li> <li>Service Pricing Guide</li> <li>Credit Scoring Guide</li> </ul>"},{"location":"#contributing","title":"Contributing","text":"<p>Contributions are welcome! Please feel free to submit a Pull Request.</p>"},{"location":"#license","title":"License","text":"<p>This project is licensed under the MIT License - see the LICENSE file for details.</p>"},{"location":"changelog/","title":"Changelog","text":"<p>All notable changes to this project will be documented in this file.</p> <p>The format is based on Keep a Changelog, and this project adheres to Semantic Versioning.</p>"},{"location":"changelog/#022","title":"[0.2.2]","text":"<ul> <li>Various credit and loan models added.</li> </ul>"},{"location":"changelog/#021","title":"[0.2.1]","text":"<ul> <li>Added more pricing models.</li> <li>Minor improvements in code and docs.</li> </ul>"},{"location":"changelog/#020","title":"[0.2.0]","text":""},{"location":"changelog/#added","title":"Added","text":"<ul> <li>New Class for Allocation portfolio</li> <li>mean_variance_optimization,</li> <li>minimum_variance_portfolio,</li> <li>maximum_sharpe_ratio,</li> <li>risk_parity_portfolio,</li> <li>maximum_diversification_portfolio,</li> <li>equal_weight_portfolio,</li> <li>market_cap_weight_portfolio,</li> <li>hierarchical_risk_parity,</li> <li>black_litterman,</li> <li>kelly_criterion_optimization</li> </ul>"},{"location":"changelog/#010-2025-03-04","title":"[0.1.0] - 2025-03-04","text":""},{"location":"changelog/#added_1","title":"Added","text":"<ul> <li>Initial release </li> </ul>"},{"location":"contributing/","title":"Contributing to Pypulate","text":"<p>Thank you for considering contributing to Pypulate! This document provides guidelines and instructions for contributing to the project.</p>"},{"location":"contributing/#code-of-conduct","title":"Code of Conduct","text":"<p>Please be respectful and considerate of others when contributing to this project. We aim to foster an inclusive and welcoming community.</p>"},{"location":"contributing/#how-to-contribute","title":"How to Contribute","text":"<p>There are many ways to contribute to Pypulate:</p> <ol> <li> <p>Report bugs: If you find a bug, please create an issue on GitHub with a detailed description of the problem, including steps to reproduce it.</p> </li> <li> <p>Suggest features: If you have an idea for a new feature or improvement, please create an issue on GitHub to discuss it.</p> </li> <li> <p>Contribute code: If you want to contribute code, please follow the steps below.</p> </li> </ol>"},{"location":"contributing/#development-setup","title":"Development Setup","text":"<ol> <li> <p>Fork the repository on GitHub.</p> </li> <li> <p>Clone your fork locally:    <pre><code>git clone https://github.com/yourusername/pypulate.git\ncd pypulate\n</code></pre></p> </li> <li> <p>Create a virtual environment and install development dependencies:    <pre><code>python -m venv .venv\nsource .venv/bin/activate  # On Windows, use: .venv\\Scripts\\activate\npip install -e \".[dev]\"\n</code></pre></p> </li> <li> <p>Create a branch for your changes:    <pre><code>git checkout -b feature/your-feature-name\n</code></pre></p> </li> </ol>"},{"location":"contributing/#development-guidelines","title":"Development Guidelines","text":""},{"location":"contributing/#code-style","title":"Code Style","text":"<p>We follow the PEP 8 style guide for Python code. We use the following tools to enforce code style:</p> <ul> <li>Black: For code formatting</li> <li>isort: For import sorting</li> <li>flake8: For linting</li> </ul> <p>You can run these tools with: <pre><code>black src tests\nisort src tests\nflake8 src tests\n</code></pre></p>"},{"location":"contributing/#documentation","title":"Documentation","text":"<ul> <li>All functions, classes, and modules should have docstrings following the NumPy docstring format.</li> <li>Update the documentation when adding or modifying features.</li> <li>Run the documentation locally to check your changes:   <pre><code>mkdocs serve\n</code></pre></li> </ul>"},{"location":"contributing/#testing","title":"Testing","text":"<ul> <li>Write tests for all new features and bug fixes.</li> <li>Make sure all tests pass before submitting a pull request:   <pre><code>pytest\n</code></pre></li> </ul>"},{"location":"contributing/#pull-request-process","title":"Pull Request Process","text":"<ol> <li>Update the documentation with details of changes to the interface, if applicable.</li> <li>Update the tests to cover your changes.</li> <li>Make sure all tests pass.</li> <li>Submit a pull request to the <code>main</code> branch.</li> <li>The pull request will be reviewed by maintainers, who may request changes or improvements.</li> <li>Once approved, your pull request will be merged.</li> </ol>"},{"location":"contributing/#adding-new-kpis-or-moving-averages","title":"Adding New KPIs or Moving Averages","text":"<p>If you want to add a new KPI or moving average function:</p> <ol> <li>Add the function to the appropriate module (<code>kpi/business_kpi.py</code> for KPIs, <code>moving_averages/movingaverages.py</code> for moving averages).</li> <li>Write comprehensive docstrings with parameters, return values, and examples.</li> <li>Add tests for the new function.</li> <li>Update the documentation to include the new function.</li> <li>Add the function to the appropriate <code>__init__.py</code> file to expose it.</li> </ol>"},{"location":"contributing/#license","title":"License","text":"<p>By contributing to Pypulate, you agree that your contributions will be licensed under the project's MIT License. </p>"},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#prerequisites","title":"Prerequisites","text":"<p>Pypulate requires:</p> <ul> <li>Python 3.7 or higher</li> <li>NumPy 1.20.0 or higher</li> </ul>"},{"location":"installation/#installing-from-pypi","title":"Installing from PyPI","text":"<p>The easiest way to install Pypulate is using pip:</p> <pre><code>pip install pypulate\n</code></pre> <p>This will install Pypulate and all its dependencies.</p>"},{"location":"installation/#installing-from-source","title":"Installing from Source","text":"<p>If you want to install the latest development version, you can install directly from the GitHub repository:</p> <pre><code>pip install git+https://github.com/yourusername/pypulate.git\n</code></pre>"},{"location":"installation/#development-installation","title":"Development Installation","text":"<p>For development purposes, you can clone the repository and install in development mode:</p> <pre><code>git clone https://github.com/yourusername/pypulate.git\ncd pypulate\npip install -e .\n</code></pre> <p>This will install the package in development mode, allowing you to modify the code and see the changes immediately without reinstalling.</p>"},{"location":"installation/#verifying-installation","title":"Verifying Installation","text":"<p>You can verify that Pypulate is installed correctly by importing it in Python:</p> <pre><code>import pypulate\nprint(pypulate.__version__)\n</code></pre> <p>This should print the version number of Pypulate. </p>"},{"location":"license/","title":"License","text":"<p>Pypulate is released under the MIT License, which is a permissive open-source license that allows for free use, modification, and distribution of the software.</p>"},{"location":"license/#mit-license","title":"MIT License","text":"<pre><code>MIT License\n\nCopyright (c) 2025 Amir Rezaei\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n</code></pre>"},{"location":"license/#what-this-means","title":"What This Means","text":"<p>The MIT License is one of the most permissive open-source licenses available. It allows you to:</p> <ul> <li>Use the code for commercial purposes</li> <li>Modify the code</li> <li>Distribute the code</li> <li>Use the code in private projects</li> <li>Sublicense the code</li> </ul> <p>The only requirement is that you include the original copyright notice and license text in any copy of the software/source.</p>"},{"location":"license/#third-party-libraries","title":"Third-Party Libraries","text":"<p>Pypulate depends on several third-party libraries, each with their own licenses:</p> <ul> <li>NumPy: BSD 3-Clause License</li> <li>MkDocs (for documentation): BSD 3-Clause License</li> <li>MkDocs Material Theme: MIT License</li> </ul> <p>Please refer to each library's documentation for more details on their licenses. </p>"},{"location":"api/business-kpis/","title":"Business KPIs API Reference","text":"<p>This page documents the API for the business KPIs module in Pypulate.</p> <p>Business KPIs Module</p> <p>This module provides functions for calculating various business metrics commonly used in SaaS and subscription-based businesses.</p>"},{"location":"api/business-kpis/#pypulate.kpi.business_kpi.annual_recurring_revenue","title":"<code>annual_recurring_revenue(paying_customers, avg_revenue_per_customer)</code>","text":"<p>Calculate Annual Recurring Revenue (ARR).</p> <p>ARR is the value of the recurring revenue of a business's term subscriptions normalized for a single calendar year.</p> <p>Parameters:</p> Name Type Description Default <code>paying_customers</code> <code>int or float</code> <p>Number of paying customers</p> required <code>avg_revenue_per_customer</code> <code>int or float</code> <p>Average revenue per customer per month</p> required <p>Returns:</p> Type Description <code>float</code> <p>Annual Recurring Revenue</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; annual_recurring_revenue(100, 50)\n60000.0\n</code></pre>"},{"location":"api/business-kpis/#pypulate.kpi.business_kpi.average_revenue_per_paying_user","title":"<code>average_revenue_per_paying_user(total_revenue, paying_users)</code>","text":"<p>Calculate Average Revenue Per Paying User (ARPPU).</p> <p>ARPPU measures the average revenue generated per paying user or customer.</p> <p>Parameters:</p> Name Type Description Default <code>total_revenue</code> <code>int or float</code> <p>Total revenue for the period</p> required <code>paying_users</code> <code>int or float</code> <p>Number of paying users or customers</p> required <p>Returns:</p> Type Description <code>float</code> <p>Average Revenue Per Paying User</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; average_revenue_per_paying_user(10000, 200)\n50.0\n</code></pre>"},{"location":"api/business-kpis/#pypulate.kpi.business_kpi.average_revenue_per_user","title":"<code>average_revenue_per_user(total_revenue, total_users)</code>","text":"<p>Calculate Average Revenue Per User (ARPU).</p> <p>ARPU measures the average revenue generated per user or customer.</p> <p>Parameters:</p> Name Type Description Default <code>total_revenue</code> <code>(int, float, array - like)</code> <p>Total revenue for the period</p> required <code>total_users</code> <code>(int, float, array - like)</code> <p>Total number of users or customers</p> required <p>Returns:</p> Type Description <code>float or ndarray</code> <p>Average Revenue Per User</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; average_revenue_per_user(10000, 500)\n20.0\n</code></pre>"},{"location":"api/business-kpis/#pypulate.kpi.business_kpi.burn_rate","title":"<code>burn_rate(starting_capital, ending_capital, months)</code>","text":"<p>Calculate Monthly Burn Rate.</p> <p>Burn Rate is the rate at which a company is losing money.</p> <p>Parameters:</p> Name Type Description Default <code>starting_capital</code> <code>int or float</code> <p>Capital at the start of the period</p> required <code>ending_capital</code> <code>int or float</code> <p>Capital at the end of the period</p> required <code>months</code> <code>int or float</code> <p>Number of months in the period</p> required <p>Returns:</p> Type Description <code>float</code> <p>Monthly Burn Rate</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; burn_rate(100000, 70000, 6)\n5000.0\n</code></pre>"},{"location":"api/business-kpis/#pypulate.kpi.business_kpi.churn_rate","title":"<code>churn_rate(customers_start, customers_end, new_customers)</code>","text":"<p>Calculate customer churn rate.</p> <p>Churn rate is the percentage of customers who stop using your product or service during a given time period.</p> <p>Parameters:</p> Name Type Description Default <code>customers_start</code> <code>(int, float, array - like)</code> <p>Number of customers at the start of the period</p> required <code>customers_end</code> <code>(int, float, array - like)</code> <p>Number of customers at the end of the period</p> required <code>new_customers</code> <code>(int, float, array - like)</code> <p>Number of new customers acquired during the period</p> required <p>Returns:</p> Type Description <code>float or ndarray</code> <p>Churn rate as a percentage</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; churn_rate(100, 90, 10)\n20.0\n</code></pre>"},{"location":"api/business-kpis/#pypulate.kpi.business_kpi.conversion_rate","title":"<code>conversion_rate(conversions, total_visitors)</code>","text":"<p>Calculate Conversion Rate.</p> <p>Conversion Rate is the percentage of visitors who take a desired action.</p> <p>Parameters:</p> Name Type Description Default <code>conversions</code> <code>(int, float, array - like)</code> <p>Number of conversions (desired actions taken)</p> required <code>total_visitors</code> <code>(int, float, array - like)</code> <p>Total number of visitors or users</p> required <p>Returns:</p> Type Description <code>float or ndarray</code> <p>Conversion Rate as a percentage</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; conversion_rate(50, 1000)\n5.0\n</code></pre>"},{"location":"api/business-kpis/#pypulate.kpi.business_kpi.customer_acquisition_cost","title":"<code>customer_acquisition_cost(marketing_costs, sales_costs, new_customers)</code>","text":"<p>Calculate Customer Acquisition Cost (CAC).</p> <p>CAC is the cost of convincing a potential customer to buy a product or service.</p> <p>Parameters:</p> Name Type Description Default <code>marketing_costs</code> <code>(int, float, array - like)</code> <p>Total marketing costs for the period</p> required <code>sales_costs</code> <code>(int, float, array - like)</code> <p>Total sales costs for the period</p> required <code>new_customers</code> <code>(int, float, array - like)</code> <p>Number of new customers acquired during the period</p> required <p>Returns:</p> Type Description <code>float or ndarray</code> <p>Customer Acquisition Cost</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; customer_acquisition_cost(5000, 3000, 100)\n80.0\n</code></pre>"},{"location":"api/business-kpis/#pypulate.kpi.business_kpi.customer_effort_score","title":"<code>customer_effort_score(effort_ratings, max_rating=7)</code>","text":"<p>Calculate Customer Effort Score (CES).</p> <p>CES measures how much effort a customer has to exert to use a product or service. Lower scores are better.</p> <p>Parameters:</p> Name Type Description Default <code>effort_ratings</code> <code>array - like</code> <p>Array of customer effort ratings</p> required <code>max_rating</code> <code>int or float</code> <p>Maximum possible rating value</p> <code>7</code> <p>Returns:</p> Type Description <code>float</code> <p>Customer Effort Score (average)</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; customer_effort_score([2, 3, 1, 2, 4])\n2.4\n</code></pre>"},{"location":"api/business-kpis/#pypulate.kpi.business_kpi.customer_engagement_score","title":"<code>customer_engagement_score(active_days, total_days)</code>","text":"<p>Calculate Customer Engagement Score.</p> <p>Customer Engagement Score measures how actively customers are using a product or service.</p> <p>Parameters:</p> Name Type Description Default <code>active_days</code> <code>int or float</code> <p>Number of days the customer was active</p> required <code>total_days</code> <code>int or float</code> <p>Total number of days in the period</p> required <p>Returns:</p> Type Description <code>float</code> <p>Customer Engagement Score as a percentage</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; customer_engagement_score(15, 30)\n50.0\n</code></pre>"},{"location":"api/business-kpis/#pypulate.kpi.business_kpi.customer_lifetime_value","title":"<code>customer_lifetime_value(avg_revenue_per_customer, gross_margin, churn_rate_value, discount_rate=10.0)</code>","text":"<p>Calculate Customer Lifetime Value (CLV).</p> <p>CLV is the total worth to a business of a customer over the whole period of their relationship.</p> <p>Parameters:</p> Name Type Description Default <code>avg_revenue_per_customer</code> <code>int or float</code> <p>Average revenue per customer per period (e.g., monthly)</p> required <code>gross_margin</code> <code>int or float</code> <p>Gross margin percentage (0-100)</p> required <code>churn_rate_value</code> <code>int or float</code> <p>Churn rate percentage (0-100)</p> required <code>discount_rate</code> <code>int or float</code> <p>Annual discount rate for future cash flows (0-100)</p> <code>10.0</code> <p>Returns:</p> Type Description <code>float</code> <p>Customer Lifetime Value</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; customer_lifetime_value(100, 70, 5, 10)\n466.66\n</code></pre>"},{"location":"api/business-kpis/#pypulate.kpi.business_kpi.customer_satisfaction_score","title":"<code>customer_satisfaction_score(satisfaction_ratings, max_rating=5)</code>","text":"<p>Calculate Customer Satisfaction Score (CSAT).</p> <p>CSAT measures how satisfied customers are with a product, service, or interaction.</p> <p>Parameters:</p> Name Type Description Default <code>satisfaction_ratings</code> <code>array - like</code> <p>Array of customer satisfaction ratings</p> required <code>max_rating</code> <code>int or float</code> <p>Maximum possible rating value</p> <code>5</code> <p>Returns:</p> Type Description <code>float</code> <p>Customer Satisfaction Score as a percentage</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; customer_satisfaction_score([4, 5, 3, 5, 4])\n84.0\n</code></pre>"},{"location":"api/business-kpis/#pypulate.kpi.business_kpi.daily_active_users_ratio","title":"<code>daily_active_users_ratio(daily_active_users, total_users)</code>","text":"<p>Calculate Daily Active Users (DAU) Ratio.</p> <p>DAU Ratio measures the percentage of total users who are active on a daily basis.</p> <p>Parameters:</p> Name Type Description Default <code>daily_active_users</code> <code>int or float</code> <p>Number of daily active users</p> required <code>total_users</code> <code>int or float</code> <p>Total number of users</p> required <p>Returns:</p> Type Description <code>float</code> <p>Daily Active Users Ratio as a percentage</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; daily_active_users_ratio(500, 2000)\n25.0\n</code></pre>"},{"location":"api/business-kpis/#pypulate.kpi.business_kpi.expansion_revenue_rate","title":"<code>expansion_revenue_rate(upsell_revenue, cross_sell_revenue, revenue_start)</code>","text":"<p>Calculate Expansion Revenue Rate.</p> <p>Expansion Revenue Rate is the percentage of additional revenue generated from existing customers.</p> <p>Parameters:</p> Name Type Description Default <code>upsell_revenue</code> <code>int or float</code> <p>Revenue from upselling to existing customers</p> required <code>cross_sell_revenue</code> <code>int or float</code> <p>Revenue from cross-selling to existing customers</p> required <code>revenue_start</code> <code>int or float</code> <p>Revenue at the start of the period</p> required <p>Returns:</p> Type Description <code>float</code> <p>Expansion Revenue Rate as a percentage</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; expansion_revenue_rate(1000, 500, 10000)\n15.0\n</code></pre>"},{"location":"api/business-kpis/#pypulate.kpi.business_kpi.feature_adoption_rate","title":"<code>feature_adoption_rate(users_adopting_feature, total_users)</code>","text":"<p>Calculate Feature Adoption Rate.</p> <p>Feature Adoption Rate measures the percentage of users who adopt a specific feature.</p> <p>Parameters:</p> Name Type Description Default <code>users_adopting_feature</code> <code>int or float</code> <p>Number of users who adopted the feature</p> required <code>total_users</code> <code>int or float</code> <p>Total number of users</p> required <p>Returns:</p> Type Description <code>float</code> <p>Feature Adoption Rate as a percentage</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; feature_adoption_rate(300, 1000)\n30.0\n</code></pre>"},{"location":"api/business-kpis/#pypulate.kpi.business_kpi.gross_margin","title":"<code>gross_margin(revenue, cost_of_goods_sold)</code>","text":"<p>Calculate Gross Margin.</p> <p>Gross Margin is the percentage of revenue that exceeds the cost of goods sold.</p> <p>Parameters:</p> Name Type Description Default <code>revenue</code> <code>int or float</code> <p>Total revenue</p> required <code>cost_of_goods_sold</code> <code>int or float</code> <p>Cost of goods sold</p> required <p>Returns:</p> Type Description <code>float</code> <p>Gross Margin as a percentage</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; gross_margin(10000, 3000)\n70.0\n</code></pre>"},{"location":"api/business-kpis/#pypulate.kpi.business_kpi.ltv_cac_ratio","title":"<code>ltv_cac_ratio(ltv, cac)</code>","text":"<p>Calculate LTV:CAC Ratio.</p> <p>LTV:CAC Ratio is a metric that compares the lifetime value of a customer to the cost of acquiring that customer.</p> <p>Parameters:</p> Name Type Description Default <code>ltv</code> <code>int or float</code> <p>Customer Lifetime Value</p> required <code>cac</code> <code>int or float</code> <p>Customer Acquisition Cost</p> required <p>Returns:</p> Type Description <code>float</code> <p>LTV:CAC Ratio</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; ltv_cac_ratio(1000, 200)\n5.0\n</code></pre>"},{"location":"api/business-kpis/#pypulate.kpi.business_kpi.monthly_active_users_ratio","title":"<code>monthly_active_users_ratio(monthly_active_users, total_users)</code>","text":"<p>Calculate Monthly Active Users (MAU) Ratio.</p> <p>MAU Ratio measures the percentage of total users who are active on a monthly basis.</p> <p>Parameters:</p> Name Type Description Default <code>monthly_active_users</code> <code>int or float</code> <p>Number of monthly active users</p> required <code>total_users</code> <code>int or float</code> <p>Total number of users</p> required <p>Returns:</p> Type Description <code>float</code> <p>Monthly Active Users Ratio as a percentage</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; monthly_active_users_ratio(1500, 2000)\n75.0\n</code></pre>"},{"location":"api/business-kpis/#pypulate.kpi.business_kpi.monthly_recurring_revenue","title":"<code>monthly_recurring_revenue(paying_customers, avg_revenue_per_customer)</code>","text":"<p>Calculate Monthly Recurring Revenue (MRR).</p> <p>MRR is the predictable total revenue generated by all the active subscriptions in a month.</p> <p>Parameters:</p> Name Type Description Default <code>paying_customers</code> <code>(int, float, array - like)</code> <p>Number of paying customers</p> required <code>avg_revenue_per_customer</code> <code>(int, float, array - like)</code> <p>Average revenue per customer per month</p> required <p>Returns:</p> Type Description <code>float or ndarray</code> <p>Monthly Recurring Revenue</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; monthly_recurring_revenue(100, 50)\n5000.0\n</code></pre>"},{"location":"api/business-kpis/#pypulate.kpi.business_kpi.net_promoter_score","title":"<code>net_promoter_score(promoters, detractors, total_respondents)</code>","text":"<p>Calculate Net Promoter Score (NPS).</p> <p>NPS measures customer experience and predicts business growth.</p> <p>Parameters:</p> Name Type Description Default <code>promoters</code> <code>(int, float, array - like)</code> <p>Number of promoters (customers who rated 9-10)</p> required <code>detractors</code> <code>(int, float, array - like)</code> <p>Number of detractors (customers who rated 0-6)</p> required <code>total_respondents</code> <code>(int, float, array - like)</code> <p>Total number of survey respondents</p> required <p>Returns:</p> Type Description <code>float or ndarray</code> <p>Net Promoter Score (ranges from -100 to 100)</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; net_promoter_score(70, 10, 100)\n60.0\n</code></pre>"},{"location":"api/business-kpis/#pypulate.kpi.business_kpi.payback_period","title":"<code>payback_period(cac, avg_monthly_revenue, gross_margin)</code>","text":"<p>Calculate CAC Payback Period in months.</p> <p>CAC Payback Period is the number of months it takes to recover the cost of acquiring a customer.</p> <p>Parameters:</p> Name Type Description Default <code>cac</code> <code>int or float</code> <p>Customer Acquisition Cost</p> required <code>avg_monthly_revenue</code> <code>int or float</code> <p>Average monthly revenue per customer</p> required <code>gross_margin</code> <code>int or float</code> <p>Gross margin percentage (0-100)</p> required <p>Returns:</p> Type Description <code>float</code> <p>CAC Payback Period in months</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; payback_period(1000, 100, 70)\n14.29\n</code></pre>"},{"location":"api/business-kpis/#pypulate.kpi.business_kpi.retention_rate","title":"<code>retention_rate(customers_start, customers_end, new_customers)</code>","text":"<p>Calculate customer retention rate.</p> <p>Retention rate is the percentage of customers who remain with your product or service over a given time period.</p> <p>Parameters:</p> Name Type Description Default <code>customers_start</code> <code>(int, float, array - like)</code> <p>Number of customers at the start of the period</p> required <code>customers_end</code> <code>(int, float, array - like)</code> <p>Number of customers at the end of the period</p> required <code>new_customers</code> <code>(int, float, array - like)</code> <p>Number of new customers acquired during the period</p> required <p>Returns:</p> Type Description <code>float or ndarray</code> <p>Retention rate as a percentage</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; retention_rate(100, 90, 10)\n80.0\n</code></pre>"},{"location":"api/business-kpis/#pypulate.kpi.business_kpi.revenue_churn_rate","title":"<code>revenue_churn_rate(revenue_start, revenue_end, new_revenue)</code>","text":"<p>Calculate Revenue Churn Rate.</p> <p>Revenue Churn Rate is the percentage of revenue lost from existing customers in a given period.</p> <p>Parameters:</p> Name Type Description Default <code>revenue_start</code> <code>(int, float, array - like)</code> <p>Revenue at the start of the period</p> required <code>revenue_end</code> <code>(int, float, array - like)</code> <p>Revenue at the end of the period</p> required <code>new_revenue</code> <code>(int, float, array - like)</code> <p>New revenue acquired during the period</p> required <p>Returns:</p> Type Description <code>float or ndarray</code> <p>Revenue Churn Rate as a percentage</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; revenue_churn_rate(10000, 9500, 1000)\n15.0\n</code></pre>"},{"location":"api/business-kpis/#pypulate.kpi.business_kpi.roi","title":"<code>roi(revenue, costs)</code>","text":"<p>Calculate Return on Investment (ROI).</p> <p>ROI measures the return on an investment relative to its cost.</p> <p>Parameters:</p> Name Type Description Default <code>revenue</code> <code>(int, float, array - like)</code> <p>Revenue or return from the investment</p> required <code>costs</code> <code>(int, float, array - like)</code> <p>Cost of the investment</p> required <p>Returns:</p> Type Description <code>float or ndarray</code> <p>Return on Investment as a percentage</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; roi(150, 100)\n50.0\n&gt;&gt;&gt; roi([150, 200, 250], [100, 120, 150])\narray([50., 66.67, 66.67])\n</code></pre>"},{"location":"api/business-kpis/#pypulate.kpi.business_kpi.runway","title":"<code>runway(current_capital, monthly_burn_rate)</code>","text":"<p>Calculate Runway in months.</p> <p>Runway is the amount of time a company has before it runs out of money.</p> <p>Parameters:</p> Name Type Description Default <code>current_capital</code> <code>int or float</code> <p>Current capital</p> required <code>monthly_burn_rate</code> <code>int or float</code> <p>Monthly burn rate</p> required <p>Returns:</p> Type Description <code>float</code> <p>Runway in months</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; runway(100000, 5000)\n20.0\n</code></pre>"},{"location":"api/business-kpis/#pypulate.kpi.business_kpi.stickiness_ratio","title":"<code>stickiness_ratio(daily_active_users, monthly_active_users)</code>","text":"<p>Calculate Stickiness Ratio (DAU/MAU).</p> <p>Stickiness Ratio measures how frequently active users engage with a product.</p> <p>Parameters:</p> Name Type Description Default <code>daily_active_users</code> <code>int or float</code> <p>Number of daily active users</p> required <code>monthly_active_users</code> <code>int or float</code> <p>Number of monthly active users</p> required <p>Returns:</p> Type Description <code>float</code> <p>Stickiness Ratio as a percentage</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; stickiness_ratio(500, 1500)\n33.33\n</code></pre>"},{"location":"api/business-kpis/#pypulate.kpi.business_kpi.time_to_value","title":"<code>time_to_value(onboarding_time, setup_time, learning_time)</code>","text":"<p>Calculate Time to Value (TTV).</p> <p>Time to Value is the amount of time it takes for a customer to realize value from a product.</p> <p>Parameters:</p> Name Type Description Default <code>onboarding_time</code> <code>int or float</code> <p>Time spent on onboarding</p> required <code>setup_time</code> <code>int or float</code> <p>Time spent on setup</p> required <code>learning_time</code> <code>int or float</code> <p>Time spent on learning</p> required <p>Returns:</p> Type Description <code>float</code> <p>Time to Value</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; time_to_value(2, 3, 5)\n10.0\n</code></pre>"},{"location":"api/business-kpis/#pypulate.kpi.business_kpi.virality_coefficient","title":"<code>virality_coefficient(new_users, invites_sent, total_users)</code>","text":"<p>Calculate Virality Coefficient (K-factor).</p> <p>Virality Coefficient measures how many new users each existing user brings in.</p> <p>Parameters:</p> Name Type Description Default <code>new_users</code> <code>int or float</code> <p>Number of new users from invites</p> required <code>invites_sent</code> <code>int or float</code> <p>Number of invites sent</p> required <code>total_users</code> <code>int or float</code> <p>Total number of users</p> required <p>Returns:</p> Type Description <code>float</code> <p>Virality Coefficient</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; virality_coefficient(100, 500, 1000)\n0.1\n</code></pre>"},{"location":"api/filters/","title":"Filters API Reference","text":"<p>This page documents the API for the filters module in Pypulate.</p>"},{"location":"api/filters/#kalman-filters","title":"Kalman Filters","text":"<p>Apply a standard Kalman filter to a time series.</p> <p>The Kalman filter is an optimal estimator that infers parameters of interest from indirect, inaccurate and uncertain observations. It's recursive so new measurements can be processed as they arrive.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>Input time series data</p> required <code>process_variance</code> <code>float</code> <p>Process noise variance (Q)</p> <code>1e-5</code> <code>measurement_variance</code> <code>float</code> <p>Measurement noise variance (R)</p> <code>1e-3</code> <code>initial_state</code> <code>float</code> <p>Initial state estimate. If None, the first data point is used</p> <code>None</code> <code>initial_covariance</code> <code>float</code> <p>Initial estimate covariance</p> <code>1.0</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Filtered time series</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from pypulate.filters import kalman_filter\n&gt;&gt;&gt; # Create noisy data\n&gt;&gt;&gt; x = np.linspace(0, 10, 100)\n&gt;&gt;&gt; true_signal = np.sin(x)\n&gt;&gt;&gt; noisy_signal = true_signal + np.random.normal(0, 0.1, len(x))\n&gt;&gt;&gt; # Apply Kalman filter\n&gt;&gt;&gt; filtered_signal = kalman_filter(noisy_signal)\n</code></pre> <p>Apply an Extended Kalman Filter (EKF) to a time series with non-linear dynamics.</p> <p>The EKF is a nonlinear version of the Kalman filter that linearizes about the current mean and covariance. It's used when the state transition or observation models are non-linear.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>Input time series data (observations)</p> required <code>state_transition_func</code> <code>callable</code> <p>Function that computes the state transition (f)</p> required <code>observation_func</code> <code>callable</code> <p>Function that computes the observation from state (h)</p> required <code>process_jacobian_func</code> <code>callable</code> <p>Function that computes the Jacobian of the state transition function</p> required <code>observation_jacobian_func</code> <code>callable</code> <p>Function that computes the Jacobian of the observation function</p> required <code>process_covariance</code> <code>ndarray</code> <p>Process noise covariance matrix (Q)</p> required <code>observation_covariance</code> <code>ndarray</code> <p>Observation noise covariance matrix (R)</p> required <code>initial_state</code> <code>ndarray</code> <p>Initial state estimate. If None, zeros are used</p> <code>None</code> <code>initial_covariance</code> <code>ndarray</code> <p>Initial estimate covariance matrix. If None, identity is used</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Filtered time series (state estimates)</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from pypulate.filters import extended_kalman_filter\n&gt;&gt;&gt; # Define non-linear system\n&gt;&gt;&gt; def state_transition(x):\n...     # Non-linear state transition function\n...     return np.array([x[0] + x[1], 0.5 * x[1]])\n&gt;&gt;&gt; def observation(x):\n...     # Non-linear observation function\n...     return np.array([np.sin(x[0])])\n&gt;&gt;&gt; def process_jacobian(x):\n...     # Jacobian of state transition function\n...     return np.array([[1, 1], [0, 0.5]])\n&gt;&gt;&gt; def observation_jacobian(x):\n...     # Jacobian of observation function\n...     return np.array([[np.cos(x[0]), 0]])\n&gt;&gt;&gt; # Create data\n&gt;&gt;&gt; n = 100\n&gt;&gt;&gt; true_states = np.zeros((n, 2))\n&gt;&gt;&gt; true_states[0] = [0, 1]\n&gt;&gt;&gt; for i in range(1, n):\n...     true_states[i] = state_transition(true_states[i-1])\n&gt;&gt;&gt; observations = np.array([observation(x)[0] for x in true_states])\n&gt;&gt;&gt; observations += np.random.normal(0, 0.1, n)\n&gt;&gt;&gt; # Apply EKF\n&gt;&gt;&gt; Q = np.eye(2) * 0.01  # Process noise covariance\n&gt;&gt;&gt; R = np.array([[0.1]])  # Observation noise covariance\n&gt;&gt;&gt; filtered_states = extended_kalman_filter(\n...     observations, state_transition, observation,\n...     process_jacobian, observation_jacobian, Q, R\n... )\n</code></pre> <p>Apply an Unscented Kalman Filter (UKF) to a time series with non-linear dynamics.</p> <p>The UKF uses the unscented transform to pick a minimal set of sample points (sigma points) around the mean. These sigma points are then propagated through the non-linear functions, and the mean and covariance of the estimate are recovered.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>Input time series data (observations)</p> required <code>state_transition_func</code> <code>callable</code> <p>Function that computes the state transition</p> required <code>observation_func</code> <code>callable</code> <p>Function that computes the observation from state</p> required <code>process_covariance</code> <code>ndarray</code> <p>Process noise covariance matrix (Q)</p> required <code>observation_covariance</code> <code>ndarray</code> <p>Observation noise covariance matrix (R)</p> required <code>initial_state</code> <code>ndarray</code> <p>Initial state estimate. If None, zeros are used</p> <code>None</code> <code>initial_covariance</code> <code>ndarray</code> <p>Initial estimate covariance matrix. If None, identity is used</p> <code>None</code> <code>alpha</code> <code>float</code> <p>Spread of sigma points around mean</p> <code>1e-3</code> <code>beta</code> <code>float</code> <p>Prior knowledge about distribution (2 is optimal for Gaussian)</p> <code>2.0</code> <code>kappa</code> <code>float</code> <p>Secondary scaling parameter</p> <code>0.0</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Filtered time series (state estimates)</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from pypulate.filters import unscented_kalman_filter\n&gt;&gt;&gt; # Define non-linear system\n&gt;&gt;&gt; def state_transition(x):\n...     # Non-linear state transition function\n...     return np.array([x[0] + x[1], 0.5 * x[1]])\n&gt;&gt;&gt; def observation(x):\n...     # Non-linear observation function\n...     return np.array([np.sin(x[0])])\n&gt;&gt;&gt; # Create data\n&gt;&gt;&gt; n = 100\n&gt;&gt;&gt; true_states = np.zeros((n, 2))\n&gt;&gt;&gt; true_states[0] = [0, 1]\n&gt;&gt;&gt; for i in range(1, n):\n...     true_states[i] = state_transition(true_states[i-1])\n&gt;&gt;&gt; observations = np.array([observation(x)[0] for x in true_states])\n&gt;&gt;&gt; observations += np.random.normal(0, 0.1, n)\n&gt;&gt;&gt; # Apply UKF\n&gt;&gt;&gt; Q = np.eye(2) * 0.01  # Process noise covariance\n&gt;&gt;&gt; R = np.array([[0.1]])  # Observation noise covariance\n&gt;&gt;&gt; filtered_states = unscented_kalman_filter(\n...     observations, state_transition, observation, Q, R\n... )\n</code></pre>"},{"location":"api/filters/#signal-filters","title":"Signal Filters","text":"<p>Apply a Butterworth filter to a time series.</p> <p>The Butterworth filter is a type of signal processing filter designed to have a frequency response as flat as possible in the passband.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>Input time series data</p> required <code>cutoff</code> <code>float or tuple of float</code> <p>Cutoff frequency. For lowpass and highpass, this is a scalar. For bandpass and bandstop, this is a tuple of (low, high)</p> required <code>order</code> <code>int</code> <p>Filter order</p> <code>4</code> <code>filter_type</code> <code>str</code> <p>Filter type: 'lowpass', 'highpass', 'bandpass', or 'bandstop'</p> <code>'lowpass'</code> <code>fs</code> <code>float</code> <p>Sampling frequency</p> <code>1.0</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Filtered time series</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from pypulate.filters import butterworth_filter\n&gt;&gt;&gt; # Create noisy data\n&gt;&gt;&gt; x = np.linspace(0, 10, 1000)\n&gt;&gt;&gt; signal = np.sin(2 * np.pi * 0.05 * x) + 0.5 * np.sin(2 * np.pi * 0.25 * x)\n&gt;&gt;&gt; # Apply lowpass filter to remove high frequency component\n&gt;&gt;&gt; filtered = butterworth_filter(signal, cutoff=0.1, filter_type='lowpass', fs=1.0)\n</code></pre> <p>Apply a Chebyshev filter to a time series.</p> <p>The Chebyshev filter is a filter with steeper roll-off than the Butterworth but more passband ripple (type I) or stopband ripple (type II).</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>Input time series data</p> required <code>cutoff</code> <code>float or tuple of float</code> <p>Cutoff frequency. For lowpass and highpass, this is a scalar. For bandpass and bandstop, this is a tuple of (low, high)</p> required <code>order</code> <code>int</code> <p>Filter order</p> <code>4</code> <code>ripple</code> <code>float</code> <p>Maximum ripple allowed in the passband (type I) or stopband (type II)</p> <code>1.0</code> <code>filter_type</code> <code>str</code> <p>Filter type: 'lowpass', 'highpass', 'bandpass', or 'bandstop'</p> <code>'lowpass'</code> <code>fs</code> <code>float</code> <p>Sampling frequency</p> <code>1.0</code> <code>type_num</code> <code>int</code> <p>Type of Chebyshev filter: 1 for Type I, 2 for Type II</p> <code>1</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Filtered time series</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from pypulate.filters import chebyshev_filter\n&gt;&gt;&gt; # Create noisy data\n&gt;&gt;&gt; x = np.linspace(0, 10, 1000)\n&gt;&gt;&gt; signal = np.sin(2 * np.pi * 0.05 * x) + 0.5 * np.sin(2 * np.pi * 0.25 * x)\n&gt;&gt;&gt; # Apply Chebyshev type I lowpass filter\n&gt;&gt;&gt; filtered = chebyshev_filter(signal, cutoff=0.1, ripple=0.5, type_num=1)\n</code></pre> <p>Apply a Savitzky-Golay filter to a time series.</p> <p>The Savitzky-Golay filter is a digital filter that can be applied to a set of digital data points to smooth the data by increasing the signal-to-noise ratio without greatly distorting the signal.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>Input time series data</p> required <code>window_length</code> <code>int</code> <p>Length of the filter window (must be odd)</p> <code>11</code> <code>polyorder</code> <code>int</code> <p>Order of the polynomial used to fit the samples (must be less than window_length)</p> <code>3</code> <code>deriv</code> <code>int</code> <p>Order of the derivative to compute</p> <code>0</code> <code>delta</code> <code>float</code> <p>Spacing of the samples to which the filter is applied</p> <code>1.0</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Filtered time series</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from pypulate.filters import savitzky_golay_filter\n&gt;&gt;&gt; # Create noisy data\n&gt;&gt;&gt; x = np.linspace(0, 10, 100)\n&gt;&gt;&gt; signal = np.sin(x) + np.random.normal(0, 0.1, len(x))\n&gt;&gt;&gt; # Apply Savitzky-Golay filter\n&gt;&gt;&gt; filtered = savitzky_golay_filter(signal, window_length=11, polyorder=3)\n</code></pre> <p>Apply a Wiener filter to a time series.</p> <p>The Wiener filter is a filter used to produce an estimate of a desired or target signal by linear filtering of an observed noisy signal.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>Input time series data</p> required <code>mysize</code> <code>int or tuple of int</code> <p>Size of the filter window</p> <code>3</code> <code>noise</code> <code>float</code> <p>Estimate of the noise power. If None, it's estimated from the data</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Filtered time series</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from pypulate.filters import wiener_filter\n&gt;&gt;&gt; # Create noisy data\n&gt;&gt;&gt; x = np.linspace(0, 10, 100)\n&gt;&gt;&gt; signal = np.sin(x) + np.random.normal(0, 0.1, len(x))\n&gt;&gt;&gt; # Apply Wiener filter\n&gt;&gt;&gt; filtered = wiener_filter(signal, mysize=5)\n</code></pre> <p>Apply a median filter to a time series.</p> <p>The median filter is a nonlinear digital filtering technique used to remove noise from a signal. It replaces each entry with the median of neighboring entries.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>Input time series data</p> required <code>kernel_size</code> <code>int</code> <p>Size of the filter kernel</p> <code>3</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Filtered time series</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from pypulate.filters import median_filter\n&gt;&gt;&gt; # Create noisy data with outliers\n&gt;&gt;&gt; x = np.linspace(0, 10, 100)\n&gt;&gt;&gt; signal = np.sin(x)\n&gt;&gt;&gt; signal[10] = 5  # Add outlier\n&gt;&gt;&gt; signal[50] = -5  # Add outlier\n&gt;&gt;&gt; # Apply median filter to remove outliers\n&gt;&gt;&gt; filtered = median_filter(signal, kernel_size=5)\n</code></pre> <p>Apply a Hampel filter to a time series.</p> <p>The Hampel filter is used to identify and replace outliers in a time series. It uses the median and the median absolute deviation (MAD) to identify outliers.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>Input time series data</p> required <code>window_size</code> <code>int</code> <p>Size of the window (number of points on each side of the current point)</p> <code>5</code> <code>n_sigmas</code> <code>float</code> <p>Number of standard deviations to use for outlier detection</p> <code>3.0</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Filtered time series</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from pypulate.filters import hampel_filter\n&gt;&gt;&gt; # Create noisy data with outliers\n&gt;&gt;&gt; x = np.linspace(0, 10, 100)\n&gt;&gt;&gt; signal = np.sin(x)\n&gt;&gt;&gt; signal[10] = 5  # Add outlier\n&gt;&gt;&gt; signal[50] = -5  # Add outlier\n&gt;&gt;&gt; # Apply Hampel filter to remove outliers\n&gt;&gt;&gt; filtered = hampel_filter(signal, window_size=5, n_sigmas=3.0)\n</code></pre> <p>Apply the Hodrick-Prescott filter to decompose a time series into trend and cycle components.</p> <p>The Hodrick-Prescott filter is a mathematical tool used in macroeconomics to separate the cyclical component of a time series from raw data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>Input time series data</p> required <code>lambda_param</code> <code>float</code> <p>Smoothing parameter. The larger the value, the smoother the trend component</p> <code>1600.0</code> <p>Returns:</p> Type Description <code>tuple of np.ndarray</code> <p>Tuple containing (trend, cycle) components</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from pypulate.filters import hodrick_prescott_filter\n&gt;&gt;&gt; # Create data with trend and cycle\n&gt;&gt;&gt; x = np.linspace(0, 10, 100)\n&gt;&gt;&gt; trend = 0.1 * x**2\n&gt;&gt;&gt; cycle = np.sin(2 * np.pi * 0.1 * x)\n&gt;&gt;&gt; data = trend + cycle\n&gt;&gt;&gt; # Apply Hodrick-Prescott filter\n&gt;&gt;&gt; trend_component, cycle_component = hodrick_prescott_filter(data, lambda_param=100)\n</code></pre> <p>Apply the Baxter-King bandpass filter to extract business cycle components.</p> <p>The Baxter-King filter is a bandpass filter used to extract business cycle components from macroeconomic time series.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>Input time series data</p> required <code>low</code> <code>float</code> <p>Minimum period of oscillations (in number of observations)</p> <code>6</code> <code>high</code> <code>float</code> <p>Maximum period of oscillations (in number of observations)</p> <code>32</code> <code>K</code> <code>int</code> <p>Number of terms in the approximation (lead/lag)</p> <code>12</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Filtered time series (cycle component)</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from pypulate.filters import baxter_king_filter\n&gt;&gt;&gt; # Create data with trend and multiple cycles\n&gt;&gt;&gt; x = np.linspace(0, 100, 1000)\n&gt;&gt;&gt; trend = 0.01 * x\n&gt;&gt;&gt; long_cycle = np.sin(2 * np.pi * x / 100)  # Period of 100\n&gt;&gt;&gt; business_cycle = np.sin(2 * np.pi * x / 20)  # Period of 20\n&gt;&gt;&gt; short_cycle = np.sin(2 * np.pi * x / 5)  # Period of 5\n&gt;&gt;&gt; data = trend + long_cycle + business_cycle + short_cycle\n&gt;&gt;&gt; # Extract business cycle component (periods between 8 and 32)\n&gt;&gt;&gt; cycle = baxter_king_filter(data, low=8, high=32, K=12)\n</code></pre>"},{"location":"api/filters/#adaptive-filters","title":"Adaptive Filters","text":"<p>Apply an adaptive Kalman filter to a time series.</p> <p>The adaptive Kalman filter automatically adjusts its parameters based on the observed data, making it more robust to changing dynamics.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>Input time series data</p> required <code>process_variance_init</code> <code>float</code> <p>Initial process noise variance (Q)</p> <code>1e-5</code> <code>measurement_variance_init</code> <code>float</code> <p>Initial measurement noise variance (R)</p> <code>1e-3</code> <code>adaptation_rate</code> <code>float</code> <p>Rate at which the filter adapts to changes</p> <code>0.01</code> <code>window_size</code> <code>int</code> <p>Size of the window for innovation estimation</p> <code>10</code> <code>initial_state</code> <code>float</code> <p>Initial state estimate. If None, the first data point is used</p> <code>None</code> <code>initial_covariance</code> <code>float</code> <p>Initial estimate covariance</p> <code>1.0</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Filtered time series</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from pypulate.filters import adaptive_kalman_filter\n&gt;&gt;&gt; # Create noisy data with changing dynamics\n&gt;&gt;&gt; x = np.linspace(0, 10, 200)\n&gt;&gt;&gt; true_signal = np.sin(x) + 0.1 * x\n&gt;&gt;&gt; noise_level = 0.1 * (1 + np.sin(x/2))  # Changing noise level\n&gt;&gt;&gt; noisy_signal = true_signal + noise_level * np.random.randn(len(x))\n&gt;&gt;&gt; # Apply adaptive Kalman filter\n&gt;&gt;&gt; filtered_signal = adaptive_kalman_filter(noisy_signal, adaptation_rate=0.05)\n</code></pre> <p>Apply a Least Mean Squares (LMS) adaptive filter to a time series.</p> <p>The LMS algorithm is an adaptive filter that adjusts its coefficients to minimize the mean square error between the desired signal and the filter output.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>Input time series data</p> required <code>desired</code> <code>ndarray</code> <p>Desired signal. If None, a delayed version of the input is used</p> <code>None</code> <code>filter_length</code> <code>int</code> <p>Length of the adaptive filter</p> <code>5</code> <code>mu</code> <code>float</code> <p>Step size (learning rate) of the adaptation</p> <code>0.01</code> <code>initial_weights</code> <code>ndarray</code> <p>Initial filter weights. If None, zeros are used</p> <code>None</code> <p>Returns:</p> Type Description <code>tuple of np.ndarray</code> <p>Tuple containing (filtered_data, filter_weights)</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from pypulate.filters import least_mean_squares_filter\n&gt;&gt;&gt; # Create noisy data\n&gt;&gt;&gt; x = np.linspace(0, 10, 1000)\n&gt;&gt;&gt; clean_signal = np.sin(2 * np.pi * 0.05 * x)\n&gt;&gt;&gt; noise = 0.2 * np.random.randn(len(x))\n&gt;&gt;&gt; noisy_signal = clean_signal + noise\n&gt;&gt;&gt; # Apply LMS filter\n&gt;&gt;&gt; filtered_signal, weights = least_mean_squares_filter(noisy_signal, filter_length=10, mu=0.02)\n</code></pre> <p>Apply a Recursive Least Squares (RLS) adaptive filter to a time series.</p> <p>The RLS algorithm is an adaptive filter that recursively finds the filter coefficients that minimize a weighted linear least squares cost function related to the input signals.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>Input time series data</p> required <code>desired</code> <code>ndarray</code> <p>Desired signal. If None, a delayed version of the input is used</p> <code>None</code> <code>filter_length</code> <code>int</code> <p>Length of the adaptive filter</p> <code>5</code> <code>forgetting_factor</code> <code>float</code> <p>Forgetting factor (0 &lt; lambda &lt;= 1)</p> <code>0.99</code> <code>delta</code> <code>float</code> <p>Regularization parameter for the initial correlation matrix</p> <code>1.0</code> <code>initial_weights</code> <code>ndarray</code> <p>Initial filter weights. If None, zeros are used</p> <code>None</code> <p>Returns:</p> Type Description <code>tuple of np.ndarray</code> <p>Tuple containing (filtered_data, filter_weights)</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from pypulate.filters import recursive_least_squares_filter\n&gt;&gt;&gt; # Create noisy data\n&gt;&gt;&gt; x = np.linspace(0, 10, 1000)\n&gt;&gt;&gt; clean_signal = np.sin(2 * np.pi * 0.05 * x)\n&gt;&gt;&gt; noise = 0.2 * np.random.randn(len(x))\n&gt;&gt;&gt; noisy_signal = clean_signal + noise\n&gt;&gt;&gt; # Apply RLS filter\n&gt;&gt;&gt; filtered_signal, weights = recursive_least_squares_filter(\n...     noisy_signal, filter_length=10, forgetting_factor=0.99\n... )\n</code></pre>"},{"location":"api/filters/#particle-filters","title":"Particle Filters","text":"<p>Apply a particle filter to a time series.</p> <p>The particle filter is a sequential Monte Carlo method that uses a set of particles (samples) to represent the posterior distribution of some stochastic process given noisy and/or partial observations.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>Input time series data (observations)</p> required <code>state_transition_func</code> <code>callable</code> <p>Function that propagates particles through the state transition model</p> required <code>observation_func</code> <code>callable</code> <p>Function that computes the expected observation from a state</p> required <code>process_noise_func</code> <code>callable</code> <p>Function that adds process noise to particles</p> required <code>observation_likelihood_func</code> <code>callable</code> <p>Function that computes the likelihood of an observation given a state</p> required <code>n_particles</code> <code>int</code> <p>Number of particles</p> <code>100</code> <code>initial_state_func</code> <code>callable</code> <p>Function that generates initial particles. If None, a default is used</p> <code>None</code> <code>resample_threshold</code> <code>float</code> <p>Threshold for effective sample size ratio below which resampling occurs</p> <code>0.5</code> <p>Returns:</p> Type Description <code>tuple of np.ndarray</code> <p>Tuple containing (filtered_states, particle_weights)</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from pypulate.filters import particle_filter\n&gt;&gt;&gt; # Define model functions\n&gt;&gt;&gt; def state_transition(particles):\n...     # Simple random walk model\n...     return particles\n&gt;&gt;&gt; def process_noise(particles):\n...     # Add Gaussian noise\n...     return particles + np.random.normal(0, 0.1, particles.shape)\n&gt;&gt;&gt; def observation_func(state):\n...     # Identity observation model\n...     return state\n&gt;&gt;&gt; def observation_likelihood(observation, predicted_observation):\n...     # Gaussian likelihood\n...     return np.exp(-0.5 * ((observation - predicted_observation) / 0.1) ** 2)\n&gt;&gt;&gt; def initial_state(n):\n...     # Initial particles from normal distribution\n...     return np.random.normal(0, 1, n)\n&gt;&gt;&gt; # Create data\n&gt;&gt;&gt; true_states = np.cumsum(np.random.normal(0, 0.1, 100))\n&gt;&gt;&gt; observations = true_states + np.random.normal(0, 0.1, 100)\n&gt;&gt;&gt; # Apply particle filter\n&gt;&gt;&gt; filtered_states, weights = particle_filter(\n...     observations, state_transition, observation_func,\n...     process_noise, observation_likelihood, n_particles=1000,\n...     initial_state_func=initial_state\n... )\n</code></pre> <p>Apply a bootstrap particle filter to a time series.</p> <p>The bootstrap particle filter is a simplified version of the particle filter that resamples at every step and uses the state transition prior as the proposal.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>Input time series data (observations)</p> required <code>state_transition_func</code> <code>callable</code> <p>Function that propagates particles through the state transition model</p> required <code>observation_func</code> <code>callable</code> <p>Function that computes the expected observation from a state</p> required <code>process_noise_std</code> <code>float</code> <p>Standard deviation of the process noise</p> <code>0.1</code> <code>observation_noise_std</code> <code>float</code> <p>Standard deviation of the observation noise</p> <code>0.1</code> <code>n_particles</code> <code>int</code> <p>Number of particles</p> <code>100</code> <code>initial_state_mean</code> <code>float</code> <p>Mean of the initial state distribution. If None, the first observation is used</p> <code>None</code> <code>initial_state_std</code> <code>float</code> <p>Standard deviation of the initial state distribution</p> <code>1.0</code> <p>Returns:</p> Type Description <code>tuple of np.ndarray</code> <p>Tuple containing (filtered_states, particle_weights)</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from pypulate.filters import bootstrap_particle_filter\n&gt;&gt;&gt; # Define model functions\n&gt;&gt;&gt; def state_transition(particles):\n...     # Simple random walk model\n...     return particles\n&gt;&gt;&gt; def observation_func(state):\n...     # Identity observation model\n...     return state\n&gt;&gt;&gt; # Create data\n&gt;&gt;&gt; true_states = np.cumsum(np.random.normal(0, 0.1, 100))\n&gt;&gt;&gt; observations = true_states + np.random.normal(0, 0.1, 100)\n&gt;&gt;&gt; # Apply bootstrap particle filter\n&gt;&gt;&gt; filtered_states, weights = bootstrap_particle_filter(\n...     observations, state_transition, observation_func,\n...     process_noise_std=0.1, observation_noise_std=0.1, n_particles=1000\n... )\n</code></pre>"},{"location":"api/kpi/","title":"business kpi API Reference","text":"<p>Business KPIs Module</p> <p>This module provides functions for calculating various business metrics commonly used in SaaS and subscription-based businesses.</p>"},{"location":"api/kpi/#pypulate.kpi.business_kpi.annual_recurring_revenue","title":"<code>annual_recurring_revenue(paying_customers, avg_revenue_per_customer)</code>","text":"<p>Calculate Annual Recurring Revenue (ARR).</p> <p>ARR is the value of the recurring revenue of a business's term subscriptions normalized for a single calendar year.</p> <p>Parameters:</p> Name Type Description Default <code>paying_customers</code> <code>int or float</code> <p>Number of paying customers</p> required <code>avg_revenue_per_customer</code> <code>int or float</code> <p>Average revenue per customer per month</p> required <p>Returns:</p> Type Description <code>float</code> <p>Annual Recurring Revenue</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; annual_recurring_revenue(100, 50)\n60000.0\n</code></pre>"},{"location":"api/kpi/#pypulate.kpi.business_kpi.average_revenue_per_paying_user","title":"<code>average_revenue_per_paying_user(total_revenue, paying_users)</code>","text":"<p>Calculate Average Revenue Per Paying User (ARPPU).</p> <p>ARPPU measures the average revenue generated per paying user or customer.</p> <p>Parameters:</p> Name Type Description Default <code>total_revenue</code> <code>int or float</code> <p>Total revenue for the period</p> required <code>paying_users</code> <code>int or float</code> <p>Number of paying users or customers</p> required <p>Returns:</p> Type Description <code>float</code> <p>Average Revenue Per Paying User</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; average_revenue_per_paying_user(10000, 200)\n50.0\n</code></pre>"},{"location":"api/kpi/#pypulate.kpi.business_kpi.average_revenue_per_user","title":"<code>average_revenue_per_user(total_revenue, total_users)</code>","text":"<p>Calculate Average Revenue Per User (ARPU).</p> <p>ARPU measures the average revenue generated per user or customer.</p> <p>Parameters:</p> Name Type Description Default <code>total_revenue</code> <code>(int, float, array - like)</code> <p>Total revenue for the period</p> required <code>total_users</code> <code>(int, float, array - like)</code> <p>Total number of users or customers</p> required <p>Returns:</p> Type Description <code>float or ndarray</code> <p>Average Revenue Per User</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; average_revenue_per_user(10000, 500)\n20.0\n</code></pre>"},{"location":"api/kpi/#pypulate.kpi.business_kpi.burn_rate","title":"<code>burn_rate(starting_capital, ending_capital, months)</code>","text":"<p>Calculate Monthly Burn Rate.</p> <p>Burn Rate is the rate at which a company is losing money.</p> <p>Parameters:</p> Name Type Description Default <code>starting_capital</code> <code>int or float</code> <p>Capital at the start of the period</p> required <code>ending_capital</code> <code>int or float</code> <p>Capital at the end of the period</p> required <code>months</code> <code>int or float</code> <p>Number of months in the period</p> required <p>Returns:</p> Type Description <code>float</code> <p>Monthly Burn Rate</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; burn_rate(100000, 70000, 6)\n5000.0\n</code></pre>"},{"location":"api/kpi/#pypulate.kpi.business_kpi.churn_rate","title":"<code>churn_rate(customers_start, customers_end, new_customers)</code>","text":"<p>Calculate customer churn rate.</p> <p>Churn rate is the percentage of customers who stop using your product or service during a given time period.</p> <p>Parameters:</p> Name Type Description Default <code>customers_start</code> <code>(int, float, array - like)</code> <p>Number of customers at the start of the period</p> required <code>customers_end</code> <code>(int, float, array - like)</code> <p>Number of customers at the end of the period</p> required <code>new_customers</code> <code>(int, float, array - like)</code> <p>Number of new customers acquired during the period</p> required <p>Returns:</p> Type Description <code>float or ndarray</code> <p>Churn rate as a percentage</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; churn_rate(100, 90, 10)\n20.0\n</code></pre>"},{"location":"api/kpi/#pypulate.kpi.business_kpi.conversion_rate","title":"<code>conversion_rate(conversions, total_visitors)</code>","text":"<p>Calculate Conversion Rate.</p> <p>Conversion Rate is the percentage of visitors who take a desired action.</p> <p>Parameters:</p> Name Type Description Default <code>conversions</code> <code>(int, float, array - like)</code> <p>Number of conversions (desired actions taken)</p> required <code>total_visitors</code> <code>(int, float, array - like)</code> <p>Total number of visitors or users</p> required <p>Returns:</p> Type Description <code>float or ndarray</code> <p>Conversion Rate as a percentage</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; conversion_rate(50, 1000)\n5.0\n</code></pre>"},{"location":"api/kpi/#pypulate.kpi.business_kpi.customer_acquisition_cost","title":"<code>customer_acquisition_cost(marketing_costs, sales_costs, new_customers)</code>","text":"<p>Calculate Customer Acquisition Cost (CAC).</p> <p>CAC is the cost of convincing a potential customer to buy a product or service.</p> <p>Parameters:</p> Name Type Description Default <code>marketing_costs</code> <code>(int, float, array - like)</code> <p>Total marketing costs for the period</p> required <code>sales_costs</code> <code>(int, float, array - like)</code> <p>Total sales costs for the period</p> required <code>new_customers</code> <code>(int, float, array - like)</code> <p>Number of new customers acquired during the period</p> required <p>Returns:</p> Type Description <code>float or ndarray</code> <p>Customer Acquisition Cost</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; customer_acquisition_cost(5000, 3000, 100)\n80.0\n</code></pre>"},{"location":"api/kpi/#pypulate.kpi.business_kpi.customer_effort_score","title":"<code>customer_effort_score(effort_ratings, max_rating=7)</code>","text":"<p>Calculate Customer Effort Score (CES).</p> <p>CES measures how much effort a customer has to exert to use a product or service. Lower scores are better.</p> <p>Parameters:</p> Name Type Description Default <code>effort_ratings</code> <code>array - like</code> <p>Array of customer effort ratings</p> required <code>max_rating</code> <code>int or float</code> <p>Maximum possible rating value</p> <code>7</code> <p>Returns:</p> Type Description <code>float</code> <p>Customer Effort Score (average)</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; customer_effort_score([2, 3, 1, 2, 4])\n2.4\n</code></pre>"},{"location":"api/kpi/#pypulate.kpi.business_kpi.customer_engagement_score","title":"<code>customer_engagement_score(active_days, total_days)</code>","text":"<p>Calculate Customer Engagement Score.</p> <p>Customer Engagement Score measures how actively customers are using a product or service.</p> <p>Parameters:</p> Name Type Description Default <code>active_days</code> <code>int or float</code> <p>Number of days the customer was active</p> required <code>total_days</code> <code>int or float</code> <p>Total number of days in the period</p> required <p>Returns:</p> Type Description <code>float</code> <p>Customer Engagement Score as a percentage</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; customer_engagement_score(15, 30)\n50.0\n</code></pre>"},{"location":"api/kpi/#pypulate.kpi.business_kpi.customer_lifetime_value","title":"<code>customer_lifetime_value(avg_revenue_per_customer, gross_margin, churn_rate_value, discount_rate=10.0)</code>","text":"<p>Calculate Customer Lifetime Value (CLV).</p> <p>CLV is the total worth to a business of a customer over the whole period of their relationship.</p> <p>Parameters:</p> Name Type Description Default <code>avg_revenue_per_customer</code> <code>int or float</code> <p>Average revenue per customer per period (e.g., monthly)</p> required <code>gross_margin</code> <code>int or float</code> <p>Gross margin percentage (0-100)</p> required <code>churn_rate_value</code> <code>int or float</code> <p>Churn rate percentage (0-100)</p> required <code>discount_rate</code> <code>int or float</code> <p>Annual discount rate for future cash flows (0-100)</p> <code>10.0</code> <p>Returns:</p> Type Description <code>float</code> <p>Customer Lifetime Value</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; customer_lifetime_value(100, 70, 5, 10)\n466.66\n</code></pre>"},{"location":"api/kpi/#pypulate.kpi.business_kpi.customer_satisfaction_score","title":"<code>customer_satisfaction_score(satisfaction_ratings, max_rating=5)</code>","text":"<p>Calculate Customer Satisfaction Score (CSAT).</p> <p>CSAT measures how satisfied customers are with a product, service, or interaction.</p> <p>Parameters:</p> Name Type Description Default <code>satisfaction_ratings</code> <code>array - like</code> <p>Array of customer satisfaction ratings</p> required <code>max_rating</code> <code>int or float</code> <p>Maximum possible rating value</p> <code>5</code> <p>Returns:</p> Type Description <code>float</code> <p>Customer Satisfaction Score as a percentage</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; customer_satisfaction_score([4, 5, 3, 5, 4])\n84.0\n</code></pre>"},{"location":"api/kpi/#pypulate.kpi.business_kpi.daily_active_users_ratio","title":"<code>daily_active_users_ratio(daily_active_users, total_users)</code>","text":"<p>Calculate Daily Active Users (DAU) Ratio.</p> <p>DAU Ratio measures the percentage of total users who are active on a daily basis.</p> <p>Parameters:</p> Name Type Description Default <code>daily_active_users</code> <code>int or float</code> <p>Number of daily active users</p> required <code>total_users</code> <code>int or float</code> <p>Total number of users</p> required <p>Returns:</p> Type Description <code>float</code> <p>Daily Active Users Ratio as a percentage</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; daily_active_users_ratio(500, 2000)\n25.0\n</code></pre>"},{"location":"api/kpi/#pypulate.kpi.business_kpi.expansion_revenue_rate","title":"<code>expansion_revenue_rate(upsell_revenue, cross_sell_revenue, revenue_start)</code>","text":"<p>Calculate Expansion Revenue Rate.</p> <p>Expansion Revenue Rate is the percentage of additional revenue generated from existing customers.</p> <p>Parameters:</p> Name Type Description Default <code>upsell_revenue</code> <code>int or float</code> <p>Revenue from upselling to existing customers</p> required <code>cross_sell_revenue</code> <code>int or float</code> <p>Revenue from cross-selling to existing customers</p> required <code>revenue_start</code> <code>int or float</code> <p>Revenue at the start of the period</p> required <p>Returns:</p> Type Description <code>float</code> <p>Expansion Revenue Rate as a percentage</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; expansion_revenue_rate(1000, 500, 10000)\n15.0\n</code></pre>"},{"location":"api/kpi/#pypulate.kpi.business_kpi.feature_adoption_rate","title":"<code>feature_adoption_rate(users_adopting_feature, total_users)</code>","text":"<p>Calculate Feature Adoption Rate.</p> <p>Feature Adoption Rate measures the percentage of users who adopt a specific feature.</p> <p>Parameters:</p> Name Type Description Default <code>users_adopting_feature</code> <code>int or float</code> <p>Number of users who adopted the feature</p> required <code>total_users</code> <code>int or float</code> <p>Total number of users</p> required <p>Returns:</p> Type Description <code>float</code> <p>Feature Adoption Rate as a percentage</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; feature_adoption_rate(300, 1000)\n30.0\n</code></pre>"},{"location":"api/kpi/#pypulate.kpi.business_kpi.gross_margin","title":"<code>gross_margin(revenue, cost_of_goods_sold)</code>","text":"<p>Calculate Gross Margin.</p> <p>Gross Margin is the percentage of revenue that exceeds the cost of goods sold.</p> <p>Parameters:</p> Name Type Description Default <code>revenue</code> <code>int or float</code> <p>Total revenue</p> required <code>cost_of_goods_sold</code> <code>int or float</code> <p>Cost of goods sold</p> required <p>Returns:</p> Type Description <code>float</code> <p>Gross Margin as a percentage</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; gross_margin(10000, 3000)\n70.0\n</code></pre>"},{"location":"api/kpi/#pypulate.kpi.business_kpi.ltv_cac_ratio","title":"<code>ltv_cac_ratio(ltv, cac)</code>","text":"<p>Calculate LTV:CAC Ratio.</p> <p>LTV:CAC Ratio is a metric that compares the lifetime value of a customer to the cost of acquiring that customer.</p> <p>Parameters:</p> Name Type Description Default <code>ltv</code> <code>int or float</code> <p>Customer Lifetime Value</p> required <code>cac</code> <code>int or float</code> <p>Customer Acquisition Cost</p> required <p>Returns:</p> Type Description <code>float</code> <p>LTV:CAC Ratio</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; ltv_cac_ratio(1000, 200)\n5.0\n</code></pre>"},{"location":"api/kpi/#pypulate.kpi.business_kpi.monthly_active_users_ratio","title":"<code>monthly_active_users_ratio(monthly_active_users, total_users)</code>","text":"<p>Calculate Monthly Active Users (MAU) Ratio.</p> <p>MAU Ratio measures the percentage of total users who are active on a monthly basis.</p> <p>Parameters:</p> Name Type Description Default <code>monthly_active_users</code> <code>int or float</code> <p>Number of monthly active users</p> required <code>total_users</code> <code>int or float</code> <p>Total number of users</p> required <p>Returns:</p> Type Description <code>float</code> <p>Monthly Active Users Ratio as a percentage</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; monthly_active_users_ratio(1500, 2000)\n75.0\n</code></pre>"},{"location":"api/kpi/#pypulate.kpi.business_kpi.monthly_recurring_revenue","title":"<code>monthly_recurring_revenue(paying_customers, avg_revenue_per_customer)</code>","text":"<p>Calculate Monthly Recurring Revenue (MRR).</p> <p>MRR is the predictable total revenue generated by all the active subscriptions in a month.</p> <p>Parameters:</p> Name Type Description Default <code>paying_customers</code> <code>(int, float, array - like)</code> <p>Number of paying customers</p> required <code>avg_revenue_per_customer</code> <code>(int, float, array - like)</code> <p>Average revenue per customer per month</p> required <p>Returns:</p> Type Description <code>float or ndarray</code> <p>Monthly Recurring Revenue</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; monthly_recurring_revenue(100, 50)\n5000.0\n</code></pre>"},{"location":"api/kpi/#pypulate.kpi.business_kpi.net_promoter_score","title":"<code>net_promoter_score(promoters, detractors, total_respondents)</code>","text":"<p>Calculate Net Promoter Score (NPS).</p> <p>NPS measures customer experience and predicts business growth.</p> <p>Parameters:</p> Name Type Description Default <code>promoters</code> <code>(int, float, array - like)</code> <p>Number of promoters (customers who rated 9-10)</p> required <code>detractors</code> <code>(int, float, array - like)</code> <p>Number of detractors (customers who rated 0-6)</p> required <code>total_respondents</code> <code>(int, float, array - like)</code> <p>Total number of survey respondents</p> required <p>Returns:</p> Type Description <code>float or ndarray</code> <p>Net Promoter Score (ranges from -100 to 100)</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; net_promoter_score(70, 10, 100)\n60.0\n</code></pre>"},{"location":"api/kpi/#pypulate.kpi.business_kpi.payback_period","title":"<code>payback_period(cac, avg_monthly_revenue, gross_margin)</code>","text":"<p>Calculate CAC Payback Period in months.</p> <p>CAC Payback Period is the number of months it takes to recover the cost of acquiring a customer.</p> <p>Parameters:</p> Name Type Description Default <code>cac</code> <code>int or float</code> <p>Customer Acquisition Cost</p> required <code>avg_monthly_revenue</code> <code>int or float</code> <p>Average monthly revenue per customer</p> required <code>gross_margin</code> <code>int or float</code> <p>Gross margin percentage (0-100)</p> required <p>Returns:</p> Type Description <code>float</code> <p>CAC Payback Period in months</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; payback_period(1000, 100, 70)\n14.29\n</code></pre>"},{"location":"api/kpi/#pypulate.kpi.business_kpi.retention_rate","title":"<code>retention_rate(customers_start, customers_end, new_customers)</code>","text":"<p>Calculate customer retention rate.</p> <p>Retention rate is the percentage of customers who remain with your product or service over a given time period.</p> <p>Parameters:</p> Name Type Description Default <code>customers_start</code> <code>(int, float, array - like)</code> <p>Number of customers at the start of the period</p> required <code>customers_end</code> <code>(int, float, array - like)</code> <p>Number of customers at the end of the period</p> required <code>new_customers</code> <code>(int, float, array - like)</code> <p>Number of new customers acquired during the period</p> required <p>Returns:</p> Type Description <code>float or ndarray</code> <p>Retention rate as a percentage</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; retention_rate(100, 90, 10)\n80.0\n</code></pre>"},{"location":"api/kpi/#pypulate.kpi.business_kpi.revenue_churn_rate","title":"<code>revenue_churn_rate(revenue_start, revenue_end, new_revenue)</code>","text":"<p>Calculate Revenue Churn Rate.</p> <p>Revenue Churn Rate is the percentage of revenue lost from existing customers in a given period.</p> <p>Parameters:</p> Name Type Description Default <code>revenue_start</code> <code>(int, float, array - like)</code> <p>Revenue at the start of the period</p> required <code>revenue_end</code> <code>(int, float, array - like)</code> <p>Revenue at the end of the period</p> required <code>new_revenue</code> <code>(int, float, array - like)</code> <p>New revenue acquired during the period</p> required <p>Returns:</p> Type Description <code>float or ndarray</code> <p>Revenue Churn Rate as a percentage</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; revenue_churn_rate(10000, 9500, 1000)\n15.0\n</code></pre>"},{"location":"api/kpi/#pypulate.kpi.business_kpi.roi","title":"<code>roi(revenue, costs)</code>","text":"<p>Calculate Return on Investment (ROI).</p> <p>ROI measures the return on an investment relative to its cost.</p> <p>Parameters:</p> Name Type Description Default <code>revenue</code> <code>(int, float, array - like)</code> <p>Revenue or return from the investment</p> required <code>costs</code> <code>(int, float, array - like)</code> <p>Cost of the investment</p> required <p>Returns:</p> Type Description <code>float or ndarray</code> <p>Return on Investment as a percentage</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; roi(150, 100)\n50.0\n&gt;&gt;&gt; roi([150, 200, 250], [100, 120, 150])\narray([50., 66.67, 66.67])\n</code></pre>"},{"location":"api/kpi/#pypulate.kpi.business_kpi.runway","title":"<code>runway(current_capital, monthly_burn_rate)</code>","text":"<p>Calculate Runway in months.</p> <p>Runway is the amount of time a company has before it runs out of money.</p> <p>Parameters:</p> Name Type Description Default <code>current_capital</code> <code>int or float</code> <p>Current capital</p> required <code>monthly_burn_rate</code> <code>int or float</code> <p>Monthly burn rate</p> required <p>Returns:</p> Type Description <code>float</code> <p>Runway in months</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; runway(100000, 5000)\n20.0\n</code></pre>"},{"location":"api/kpi/#pypulate.kpi.business_kpi.stickiness_ratio","title":"<code>stickiness_ratio(daily_active_users, monthly_active_users)</code>","text":"<p>Calculate Stickiness Ratio (DAU/MAU).</p> <p>Stickiness Ratio measures how frequently active users engage with a product.</p> <p>Parameters:</p> Name Type Description Default <code>daily_active_users</code> <code>int or float</code> <p>Number of daily active users</p> required <code>monthly_active_users</code> <code>int or float</code> <p>Number of monthly active users</p> required <p>Returns:</p> Type Description <code>float</code> <p>Stickiness Ratio as a percentage</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; stickiness_ratio(500, 1500)\n33.33\n</code></pre>"},{"location":"api/kpi/#pypulate.kpi.business_kpi.time_to_value","title":"<code>time_to_value(onboarding_time, setup_time, learning_time)</code>","text":"<p>Calculate Time to Value (TTV).</p> <p>Time to Value is the amount of time it takes for a customer to realize value from a product.</p> <p>Parameters:</p> Name Type Description Default <code>onboarding_time</code> <code>int or float</code> <p>Time spent on onboarding</p> required <code>setup_time</code> <code>int or float</code> <p>Time spent on setup</p> required <code>learning_time</code> <code>int or float</code> <p>Time spent on learning</p> required <p>Returns:</p> Type Description <code>float</code> <p>Time to Value</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; time_to_value(2, 3, 5)\n10.0\n</code></pre>"},{"location":"api/kpi/#pypulate.kpi.business_kpi.virality_coefficient","title":"<code>virality_coefficient(new_users, invites_sent, total_users)</code>","text":"<p>Calculate Virality Coefficient (K-factor).</p> <p>Virality Coefficient measures how many new users each existing user brings in.</p> <p>Parameters:</p> Name Type Description Default <code>new_users</code> <code>int or float</code> <p>Number of new users from invites</p> required <code>invites_sent</code> <code>int or float</code> <p>Number of invites sent</p> required <code>total_users</code> <code>int or float</code> <p>Total number of users</p> required <p>Returns:</p> Type Description <code>float</code> <p>Virality Coefficient</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; virality_coefficient(100, 500, 1000)\n0.1\n</code></pre>"},{"location":"api/moving_averages/","title":"Moving Averages API Reference","text":"<p>Moving Averages Module</p> <p>This module provides various moving average implementations for financial time series analysis. All functions use numpy arrays for input and output to ensure high performance.</p>"},{"location":"api/moving_averages/#pypulate.moving_averages.movingaverages.alma","title":"<code>alma(data, period=9, offset=0.85, sigma=6.0)</code>","text":"<p>Arnaud Legoux Moving Average (ALMA)</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>Input price data</p> required <code>period</code> <code>int</code> <p>Window size for the moving average</p> <code>9</code> <code>offset</code> <code>float</code> <p>Controls tradeoff between smoothness and responsiveness (0-1)</p> <code>0.85</code> <code>sigma</code> <code>float</code> <p>Controls the filter width</p> <code>6.0</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Arnaud Legoux moving average values</p>"},{"location":"api/moving_averages/#pypulate.moving_averages.movingaverages.ema","title":"<code>ema(data, period=9, alpha=None)</code>","text":"<p>Exponential Moving Average (EMA)</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>Input price data</p> required <code>period</code> <code>int</code> <p>Window size for the moving average</p> <code>9</code> <code>alpha</code> <code>float</code> <p>Smoothing factor. If None, alpha = 2/(period+1)</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Exponential moving average values</p>"},{"location":"api/moving_averages/#pypulate.moving_averages.movingaverages.frama","title":"<code>frama(data, period=9, fc_period=198)</code>","text":"<p>Fractal Adaptive Moving Average (FRAMA)</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>Input price data</p> required <code>period</code> <code>int</code> <p>Window size for the moving average</p> <code>9</code> <code>fc_period</code> <code>int</code> <p>Fractal cycle period</p> <code>198</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Fractal adaptive moving average values</p>"},{"location":"api/moving_averages/#pypulate.moving_averages.movingaverages.hma","title":"<code>hma(data, period=9)</code>","text":"<p>Hull Moving Average (HMA)</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>Input price data</p> required <code>period</code> <code>int</code> <p>Window size for the moving average</p> <code>9</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Hull moving average values</p>"},{"location":"api/moving_averages/#pypulate.moving_averages.movingaverages.jma","title":"<code>jma(data, period=9, phase=0)</code>","text":"<p>Jurik Moving Average (JMA)</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>Input price data</p> required <code>period</code> <code>int</code> <p>Window size for the moving average</p> <code>9</code> <code>phase</code> <code>float</code> <p>Phase parameter (-100 to 100)</p> <code>0</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Jurik moving average values</p>"},{"location":"api/moving_averages/#pypulate.moving_averages.movingaverages.kama","title":"<code>kama(data, period=9, fast_period=2, slow_period=30)</code>","text":"<p>Kaufman Adaptive Moving Average (KAMA)</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>Input price data</p> required <code>period</code> <code>int</code> <p>Window size for the efficiency ratio calculation</p> <code>9</code> <code>fast_period</code> <code>int</code> <p>Fast EMA period</p> <code>2</code> <code>slow_period</code> <code>int</code> <p>Slow EMA period</p> <code>30</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Kaufman adaptive moving average values</p>"},{"location":"api/moving_averages/#pypulate.moving_averages.movingaverages.laguerre_filter","title":"<code>laguerre_filter(data, gamma=0.8)</code>","text":"<p>Laguerre Filter</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>Input price data</p> required <code>gamma</code> <code>float</code> <p>Damping factor (0-1)</p> <code>0.8</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Laguerre filter values</p>"},{"location":"api/moving_averages/#pypulate.moving_averages.movingaverages.lsma","title":"<code>lsma(data, period=9)</code>","text":"<p>Least Squares Moving Average (LSMA)</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>Input price data</p> required <code>period</code> <code>int</code> <p>Window size for the moving average</p> <code>9</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Least squares moving average values</p>"},{"location":"api/moving_averages/#pypulate.moving_averages.movingaverages.mcginley_dynamic","title":"<code>mcginley_dynamic(data, period=9, k=0.6)</code>","text":"<p>McGinley Dynamic Indicator</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>Input price data</p> required <code>period</code> <code>int</code> <p>Window size for the moving average</p> <code>9</code> <code>k</code> <code>float</code> <p>Adjustment factor</p> <code>0.6</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>McGinley dynamic indicator values</p>"},{"location":"api/moving_averages/#pypulate.moving_averages.movingaverages.modular_filter","title":"<code>modular_filter(data, period=9, phase=0.5)</code>","text":"<p>Modular Filter</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>Input price data</p> required <code>period</code> <code>int</code> <p>Window size for the filter</p> <code>9</code> <code>phase</code> <code>float</code> <p>Phase parameter (0-1)</p> <code>0.5</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Modular filter values</p>"},{"location":"api/moving_averages/#pypulate.moving_averages.movingaverages.rdma","title":"<code>rdma(data)</code>","text":"<p>Rex Dog Moving Average (RDMA)</p> <p>This implementation follows the original RexDog definition, which is the average of six SMAs with periods 5, 9, 24, 50, 100, and 200.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>Input price data</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Rex Dog moving average values</p>"},{"location":"api/moving_averages/#pypulate.moving_averages.movingaverages.sma","title":"<code>sma(data, period=9)</code>","text":"<p>Simple Moving Average (SMA)</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>Input price data</p> required <code>period</code> <code>int</code> <p>Window size for the moving average</p> <code>9</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Simple moving average values</p>"},{"location":"api/moving_averages/#pypulate.moving_averages.movingaverages.smma","title":"<code>smma(data, period=9)</code>","text":"<p>Smoothed Moving Average (SMMA) or Running Moving Average (RMA)</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>Input price data</p> required <code>period</code> <code>int</code> <p>Window size for the moving average</p> <code>9</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Smoothed moving average values</p>"},{"location":"api/moving_averages/#pypulate.moving_averages.movingaverages.t3","title":"<code>t3(data, period=9, vfactor=0.7)</code>","text":"<p>Tillson T3 Moving Average</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>Input price data</p> required <code>period</code> <code>int</code> <p>Window size for the moving average</p> <code>9</code> <code>vfactor</code> <code>float</code> <p>Volume factor (0-1)</p> <code>0.7</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>T3 moving average values</p>"},{"location":"api/moving_averages/#pypulate.moving_averages.movingaverages.tma","title":"<code>tma(data, period=9)</code>","text":"<p>Triangular Moving Average (TMA)</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>Input price data</p> required <code>period</code> <code>int</code> <p>Window size for the moving average</p> <code>9</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Triangular moving average values</p>"},{"location":"api/moving_averages/#pypulate.moving_averages.movingaverages.vama","title":"<code>vama(data, volatility, period=9)</code>","text":"<p>Volatility-Adjusted Moving Average (VAMA)</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>Input price data</p> required <code>volatility</code> <code>ndarray</code> <p>Volatility data corresponding to price data</p> required <code>period</code> <code>int</code> <p>Window size for the moving average</p> <code>9</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Volatility-adjusted moving average values</p>"},{"location":"api/moving_averages/#pypulate.moving_averages.movingaverages.vwma","title":"<code>vwma(data, volume, period=9)</code>","text":"<p>Volume-Weighted Moving Average (VWMA)</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>Input price data</p> required <code>volume</code> <code>ndarray</code> <p>Volume data corresponding to price data</p> required <code>period</code> <code>int</code> <p>Window size for the moving average</p> <code>9</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Volume-weighted moving average values</p>"},{"location":"api/moving_averages/#pypulate.moving_averages.movingaverages.wma","title":"<code>wma(data, period=9)</code>","text":"<p>Weighted Moving Average (WMA)</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>Input price data</p> required <code>period</code> <code>int</code> <p>Window size for the moving average</p> <code>9</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Weighted moving average values</p>"},{"location":"api/moving_averages/#pypulate.moving_averages.movingaverages.zlma","title":"<code>zlma(data, period=9)</code>","text":"<p>Zero-Lag Moving Average (ZLMA)</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>Input price data</p> required <code>period</code> <code>int</code> <p>Window size for the moving average</p> <code>9</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Zero-lag moving average values</p>"},{"location":"api/optimization/","title":"Optimizations Reference","text":"<p>Portfolio Optimization Module</p> <p>This module provides various portfolio optimization methods including Mean-Variance Optimization, Minimum Variance Portfolio, Maximum Sharpe Ratio, Hierarchical Risk Parity, Black-Litterman, Kelly Criterion, and other common portfolio optimization techniques.</p>"},{"location":"api/optimization/#pypulate.allocation.optimization.black_litterman","title":"<code>black_litterman(returns, market_caps, views, view_confidences, tau=0.05, risk_free_rate=0.0)</code>","text":"<p>Implement Black-Litterman portfolio optimization.</p> <p>Parameters:</p> Name Type Description Default <code>returns</code> <code>ndarray</code> <p>Matrix of asset returns where each column represents an asset</p> required <code>market_caps</code> <code>ndarray</code> <p>Array of market capitalizations for each asset</p> required <code>views</code> <code>dict</code> <p>Dictionary mapping asset indices to expected returns</p> required <code>view_confidences</code> <code>dict</code> <p>Dictionary mapping asset indices to confidence levels (0-1)</p> required <code>tau</code> <code>float</code> <p>Uncertainty in the prior distribution</p> <code>0.05</code> <code>risk_free_rate</code> <code>float</code> <p>Risk-free rate</p> <code>0.0</code> <p>Returns:</p> Type Description <code>tuple</code> <p>(optimal_weights, portfolio_return, portfolio_risk)</p>"},{"location":"api/optimization/#pypulate.allocation.optimization.equal_weight_portfolio","title":"<code>equal_weight_portfolio(returns)</code>","text":"<p>Create an equal-weighted portfolio.</p> <p>Parameters:</p> Name Type Description Default <code>returns</code> <code>ndarray</code> <p>Matrix of asset returns where each column represents an asset</p> required <p>Returns:</p> Type Description <code>tuple</code> <p>(weights, portfolio_return, portfolio_risk)</p>"},{"location":"api/optimization/#pypulate.allocation.optimization.hierarchical_risk_parity","title":"<code>hierarchical_risk_parity(returns, linkage_method='single', distance_metric='euclidean')</code>","text":"<p>Implement Hierarchical Risk Parity (HRP) portfolio optimization.</p> <p>Parameters:</p> Name Type Description Default <code>returns</code> <code>ndarray</code> <p>Matrix of asset returns where each column represents an asset</p> required <code>linkage_method</code> <code>str</code> <p>Linkage method for hierarchical clustering ('single', 'complete', 'average', 'ward')</p> <code>'single'</code> <code>distance_metric</code> <code>str</code> <p>Distance metric for clustering ('euclidean', 'correlation')</p> <code>'euclidean'</code> <p>Returns:</p> Type Description <code>tuple</code> <p>(optimal_weights, portfolio_return, portfolio_risk)</p>"},{"location":"api/optimization/#pypulate.allocation.optimization.kelly_criterion_optimization","title":"<code>kelly_criterion_optimization(returns, risk_free_rate=0.0, constraints=None, kelly_fraction=1.0)</code>","text":"<p>Implement Kelly Criterion portfolio optimization.</p> <p>The Kelly Criterion determines the optimal fraction of capital to allocate to each investment to maximize long-term growth rate.</p> <p>Parameters:</p> Name Type Description Default <code>returns</code> <code>ndarray</code> <p>Matrix of asset returns where each column represents an asset</p> required <code>risk_free_rate</code> <code>float</code> <p>Risk-free rate</p> <code>0.0</code> <code>constraints</code> <code>list of dict</code> <p>List of constraints for the optimization problem</p> <code>None</code> <code>kelly_fraction</code> <code>float</code> <p>Fraction of Kelly Criterion to use (e.g., 0.5 for half-Kelly)</p> <code>1.0</code> <p>Returns:</p> Type Description <code>tuple</code> <p>(optimal_weights, portfolio_return, portfolio_risk)</p> Notes <p>The Kelly Criterion maximizes the expected logarithmic growth rate of wealth. The full Kelly Criterion can be aggressive, so practitioners often use a fraction of the Kelly Criterion (e.g., half-Kelly) for more conservative position sizing.</p>"},{"location":"api/optimization/#pypulate.allocation.optimization.market_cap_weight_portfolio","title":"<code>market_cap_weight_portfolio(market_caps)</code>","text":"<p>Create a market-cap weighted portfolio.</p> <p>Parameters:</p> Name Type Description Default <code>market_caps</code> <code>ndarray</code> <p>Array of market capitalizations for each asset</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Market-cap weighted portfolio weights</p>"},{"location":"api/optimization/#pypulate.allocation.optimization.maximum_diversification_portfolio","title":"<code>maximum_diversification_portfolio(returns, constraints=None)</code>","text":"<p>Find the portfolio that maximizes diversification ratio.</p> <p>Parameters:</p> Name Type Description Default <code>returns</code> <code>ndarray</code> <p>Matrix of asset returns where each column represents an asset</p> required <code>constraints</code> <code>list of dict</code> <p>List of constraints for the optimization problem</p> <code>None</code> <p>Returns:</p> Type Description <code>tuple</code> <p>(optimal_weights, portfolio_return, portfolio_risk)</p>"},{"location":"api/optimization/#pypulate.allocation.optimization.maximum_sharpe_ratio","title":"<code>maximum_sharpe_ratio(returns, risk_free_rate=0.0, constraints=None)</code>","text":"<p>Find the portfolio with maximum Sharpe ratio.</p> <p>Parameters:</p> Name Type Description Default <code>returns</code> <code>ndarray</code> <p>Matrix of asset returns where each column represents an asset</p> required <code>risk_free_rate</code> <code>float</code> <p>Risk-free rate for Sharpe ratio calculation</p> <code>0.0</code> <code>constraints</code> <code>list of dict</code> <p>List of constraints for the optimization problem</p> <code>None</code> <p>Returns:</p> Type Description <code>tuple</code> <p>(optimal_weights, portfolio_return, portfolio_risk)</p>"},{"location":"api/optimization/#pypulate.allocation.optimization.mean_variance_optimization","title":"<code>mean_variance_optimization(returns, target_return=None, risk_free_rate=0.0, constraints=None)</code>","text":"<p>Perform Mean-Variance Optimization to find optimal portfolio weights.</p> <p>Parameters:</p> Name Type Description Default <code>returns</code> <code>ndarray</code> <p>Matrix of asset returns where each column represents an asset</p> required <code>target_return</code> <code>float</code> <p>Target portfolio return. If None, maximizes Sharpe ratio</p> <code>None</code> <code>risk_free_rate</code> <code>float</code> <p>Risk-free rate for Sharpe ratio calculation</p> <code>0.0</code> <code>constraints</code> <code>list of dict</code> <p>List of constraints for the optimization problem</p> <code>None</code> <p>Returns:</p> Type Description <code>tuple</code> <p>(optimal_weights, portfolio_return, portfolio_risk)</p>"},{"location":"api/optimization/#pypulate.allocation.optimization.minimum_variance_portfolio","title":"<code>minimum_variance_portfolio(returns, constraints=None)</code>","text":"<p>Find the portfolio with minimum variance.</p> <p>Parameters:</p> Name Type Description Default <code>returns</code> <code>ndarray</code> <p>Matrix of asset returns where each column represents an asset</p> required <code>constraints</code> <code>list of dict</code> <p>List of constraints for the optimization problem</p> <code>None</code> <p>Returns:</p> Type Description <code>tuple</code> <p>(optimal_weights, portfolio_return, portfolio_risk)</p>"},{"location":"api/optimization/#pypulate.allocation.optimization.risk_parity_portfolio","title":"<code>risk_parity_portfolio(returns, constraints=None)</code>","text":"<p>Find the portfolio where risk is equally distributed across assets.</p> <p>Parameters:</p> Name Type Description Default <code>returns</code> <code>ndarray</code> <p>Matrix of asset returns where each column represents an asset</p> required <code>constraints</code> <code>list of dict</code> <p>List of constraints for the optimization problem</p> <code>None</code> <p>Returns:</p> Type Description <code>tuple</code> <p>(optimal_weights, portfolio_return, portfolio_risk)</p>"},{"location":"api/parray/","title":"Parray API Reference","text":"<p>Parray Module</p> <p>This module provides a NumPy array extension that supports method chaining for financial time series analysis, including moving averages and transforms.</p>"},{"location":"api/parray/#pypulate.dtypes.parray.Parray","title":"<code>Parray</code>","text":"<p>               Bases: <code>ndarray</code></p> <p>A wrapper around numpy arrays that provides method chaining for financial analysis.</p> <p>This class allows for fluent method chaining like: data.ema(9).sma(20)</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from pypulate.dtypes import Parray\n&gt;&gt;&gt; data = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n&gt;&gt;&gt; ts = Parray(data)\n&gt;&gt;&gt; result = ts.ema(3).sma(2)\n</code></pre>"},{"location":"api/parray/#pypulate.dtypes.parray.Parray.adaptive_kalman_filter","title":"<code>adaptive_kalman_filter(process_variance_init=1e-05, measurement_variance_init=0.001, adaptation_rate=0.01, window_size=10, initial_state=None, initial_covariance=1.0)</code>","text":"<p>Apply an adaptive Kalman filter to the time series.</p> <p>Parameters:</p> Name Type Description Default <code>process_variance_init</code> <code>float</code> <p>Initial process noise variance (Q)</p> <code>1e-5</code> <code>measurement_variance_init</code> <code>float</code> <p>Initial measurement noise variance (R)</p> <code>1e-3</code> <code>adaptation_rate</code> <code>float</code> <p>Rate at which the filter adapts to changes</p> <code>0.01</code> <code>window_size</code> <code>int</code> <p>Size of the window for innovation estimation</p> <code>10</code> <code>initial_state</code> <code>float</code> <p>Initial state estimate. If None, the first data point is used</p> <code>None</code> <code>initial_covariance</code> <code>float</code> <p>Initial estimate covariance</p> <code>1.0</code> <p>Returns:</p> Type Description <code>Parray</code> <p>Filtered time series</p>"},{"location":"api/parray/#pypulate.dtypes.parray.Parray.adx","title":"<code>adx(period=14)</code>","text":"<p>Calculate Average Directional Index (ADX).</p> <p>ADX measures the strength of a trend.</p> <p>Parameters:</p> Name Type Description Default <code>period</code> <code>int</code> <p>Number of periods for calculation</p> <code>14</code> <p>Returns:</p> Type Description <code>Parray</code> <p>ADX values</p>"},{"location":"api/parray/#pypulate.dtypes.parray.Parray.atr","title":"<code>atr(high=None, low=None, period=14)</code>","text":"<p>Calculate Average True Range (ATR) over a specified period.</p> <p>ATR measures market volatility by decomposing the entire range of an asset price.</p> <p>Parameters:</p> Name Type Description Default <code>high</code> <code>ndarray</code> <p>High prices. If None, assumes self contains close prices and high=low=close</p> <code>None</code> <code>low</code> <code>ndarray</code> <p>Low prices. If None, assumes self contains close prices and high=low=close</p> <code>None</code> <code>period</code> <code>int</code> <p>Number of periods to calculate ATR</p> <code>14</code> <p>Returns:</p> Type Description <code>Parray</code> <p>ATR values</p>"},{"location":"api/parray/#pypulate.dtypes.parray.Parray.bollinger_bands","title":"<code>bollinger_bands(period=20, std_dev=2.0)</code>","text":"<p>Calculate Bollinger Bands over a specified period.</p> <p>Bollinger Bands consist of a middle band (SMA), an upper band (SMA + kstd), and a lower band (SMA - kstd).</p> <p>Parameters:</p> Name Type Description Default <code>period</code> <code>int</code> <p>Number of periods for the moving average</p> <code>20</code> <code>std_dev</code> <code>float</code> <p>Number of standard deviations for the upper and lower bands</p> <code>2.0</code> <p>Returns:</p> Type Description <code>tuple of Parray</code> <p>Tuple containing (upper_band, middle_band, lower_band)</p>"},{"location":"api/parray/#pypulate.dtypes.parray.Parray.butterworth_filter","title":"<code>butterworth_filter(cutoff, order=4, filter_type='lowpass', fs=1.0)</code>","text":"<p>Apply a Butterworth filter to the time series.</p> <p>Parameters:</p> Name Type Description Default <code>cutoff</code> <code>float or tuple of float</code> <p>Cutoff frequency. For lowpass and highpass, this is a scalar. For bandpass and bandstop, this is a tuple of (low, high)</p> required <code>order</code> <code>int</code> <p>Filter order</p> <code>4</code> <code>filter_type</code> <code>str</code> <p>Filter type: 'lowpass', 'highpass', 'bandpass', or 'bandstop'</p> <code>'lowpass'</code> <code>fs</code> <code>float</code> <p>Sampling frequency</p> <code>1.0</code> <p>Returns:</p> Type Description <code>Parray</code> <p>Filtered time series</p>"},{"location":"api/parray/#pypulate.dtypes.parray.Parray.cci","title":"<code>cci(period=20, constant=0.015)</code>","text":"<p>Calculate Commodity Channel Index (CCI).</p> <p>CCI measures the current price level relative to an average price level over a given period.</p> <p>Parameters:</p> Name Type Description Default <code>period</code> <code>int</code> <p>Number of periods for calculation</p> <code>20</code> <code>constant</code> <code>float</code> <p>Scaling constant</p> <code>0.015</code> <p>Returns:</p> Type Description <code>Parray</code> <p>CCI values</p>"},{"location":"api/parray/#pypulate.dtypes.parray.Parray.crossover","title":"<code>crossover(other)</code>","text":"<p>Detect when this series crosses above another series or value.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>array - like or scalar</code> <p>The other series or value to compare against</p> required <p>Returns:</p> Type Description <code>Parray</code> <p>Boolean array where True indicates a crossover (this crosses above other)</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; prices = Parray([10, 11, 12, 11, 10, 9, 10, 11, 12])\n&gt;&gt;&gt; sma = prices.sma(3)\n&gt;&gt;&gt; crossovers = prices.crossover(sma)\n</code></pre>"},{"location":"api/parray/#pypulate.dtypes.parray.Parray.crossunder","title":"<code>crossunder(other)</code>","text":"<p>Detect when this series crosses below another series or value.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>array - like or scalar</code> <p>The other series or value to compare against</p> required <p>Returns:</p> Type Description <code>Parray</code> <p>Boolean array where True indicates a crossunder (this crosses below other)</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; prices = Parray([10, 11, 12, 11, 10, 9, 10, 11, 12])\n&gt;&gt;&gt; sma = prices.sma(3)\n&gt;&gt;&gt; crossunders = prices.crossunder(sma)\n</code></pre>"},{"location":"api/parray/#pypulate.dtypes.parray.Parray.diff","title":"<code>diff(periods=1)</code>","text":"<p>Calculate difference between consecutive values.</p> <p>Parameters:</p> Name Type Description Default <code>periods</code> <code>int</code> <p>Number of periods to calculate difference over</p> <code>1</code> <p>Returns:</p> Type Description <code>Parray</code> <p>Difference values</p>"},{"location":"api/parray/#pypulate.dtypes.parray.Parray.donchian_channels","title":"<code>donchian_channels(high=None, low=None, period=20)</code>","text":"<p>Calculate Donchian Channels over a specified period.</p> <p>Donchian Channels consist of an upper band (highest high), a lower band (lowest low), and a middle band (average of upper and lower).</p> <p>Parameters:</p> Name Type Description Default <code>high</code> <code>ndarray</code> <p>High prices. If None, uses self</p> <code>None</code> <code>low</code> <code>ndarray</code> <p>Low prices. If None, uses self</p> <code>None</code> <code>period</code> <code>int</code> <p>Number of periods for the channels</p> <code>20</code> <p>Returns:</p> Type Description <code>tuple of Parray</code> <p>Tuple containing (upper_channel, middle_channel, lower_channel)</p>"},{"location":"api/parray/#pypulate.dtypes.parray.Parray.ema","title":"<code>ema(period=9, alpha=None)</code>","text":"<p>Apply Exponential Moving Average</p>"},{"location":"api/parray/#pypulate.dtypes.parray.Parray.frama","title":"<code>frama(period=9, fc_period=198)</code>","text":"<p>Apply Fractal Adaptive Moving Average</p>"},{"location":"api/parray/#pypulate.dtypes.parray.Parray.hampel_filter","title":"<code>hampel_filter(window_size=5, n_sigmas=3.0)</code>","text":"<p>Apply a Hampel filter to the time series to remove outliers.</p> <p>Parameters:</p> Name Type Description Default <code>window_size</code> <code>int</code> <p>Size of the window (number of points on each side of the current point)</p> <code>5</code> <code>n_sigmas</code> <code>float</code> <p>Number of standard deviations to use for outlier detection</p> <code>3.0</code> <p>Returns:</p> Type Description <code>Parray</code> <p>Filtered time series</p>"},{"location":"api/parray/#pypulate.dtypes.parray.Parray.historical_volatility","title":"<code>historical_volatility(period=21, annualization_factor=252)</code>","text":"<p>Calculate historical volatility over a specified period.</p> <p>Historical volatility is the standard deviation of log returns, typically annualized.</p> <p>Parameters:</p> Name Type Description Default <code>period</code> <code>int</code> <p>Number of periods to calculate volatility</p> <code>21</code> <code>annualization_factor</code> <code>int</code> <p>Factor to annualize volatility (252 for daily data, 52 for weekly, 12 for monthly)</p> <code>252</code> <p>Returns:</p> Type Description <code>Parray</code> <p>Historical volatility values as percentage</p>"},{"location":"api/parray/#pypulate.dtypes.parray.Parray.hma","title":"<code>hma(period=9)</code>","text":"<p>Apply Hull Moving Average</p>"},{"location":"api/parray/#pypulate.dtypes.parray.Parray.hodrick_prescott_filter","title":"<code>hodrick_prescott_filter(lambda_param=1600.0)</code>","text":"<p>Apply the Hodrick-Prescott filter to decompose the time series into trend and cycle components.</p> <p>Parameters:</p> Name Type Description Default <code>lambda_param</code> <code>float</code> <p>Smoothing parameter. The larger the value, the smoother the trend component</p> <code>1600.0</code> <p>Returns:</p> Type Description <code>tuple of Parray</code> <p>Tuple containing (trend, cycle) components</p>"},{"location":"api/parray/#pypulate.dtypes.parray.Parray.kalman_filter","title":"<code>kalman_filter(process_variance=1e-05, measurement_variance=0.001, initial_state=None, initial_covariance=1.0)</code>","text":"<p>Apply a standard Kalman filter to the time series.</p> <p>Parameters:</p> Name Type Description Default <code>process_variance</code> <code>float</code> <p>Process noise variance (Q)</p> <code>1e-5</code> <code>measurement_variance</code> <code>float</code> <p>Measurement noise variance (R)</p> <code>1e-3</code> <code>initial_state</code> <code>float</code> <p>Initial state estimate. If None, the first data point is used</p> <code>None</code> <code>initial_covariance</code> <code>float</code> <p>Initial estimate covariance</p> <code>1.0</code> <p>Returns:</p> Type Description <code>Parray</code> <p>Filtered time series</p>"},{"location":"api/parray/#pypulate.dtypes.parray.Parray.kama","title":"<code>kama(period=9, fast_period=2, slow_period=30)</code>","text":"<p>Apply Kaufman Adaptive Moving Average</p>"},{"location":"api/parray/#pypulate.dtypes.parray.Parray.keltner_channels","title":"<code>keltner_channels(high=None, low=None, period=20, atr_period=10, multiplier=2.0)</code>","text":"<p>Calculate Keltner Channels over a specified period.</p> <p>Keltner Channels consist of a middle band (EMA), an upper band (EMA + kATR), and a lower band (EMA - kATR).</p> <p>Parameters:</p> Name Type Description Default <code>high</code> <code>ndarray</code> <p>High prices. If None, assumes self contains close prices and high=low=close</p> <code>None</code> <code>low</code> <code>ndarray</code> <p>Low prices. If None, assumes self contains close prices and high=low=close</p> <code>None</code> <code>period</code> <code>int</code> <p>Number of periods for the EMA</p> <code>20</code> <code>atr_period</code> <code>int</code> <p>Number of periods for the ATR</p> <code>10</code> <code>multiplier</code> <code>float</code> <p>Multiplier for the ATR</p> <code>2.0</code> <p>Returns:</p> Type Description <code>tuple of Parray</code> <p>Tuple containing (upper_channel, middle_channel, lower_channel)</p>"},{"location":"api/parray/#pypulate.dtypes.parray.Parray.log","title":"<code>log()</code>","text":"<p>Calculate the natural logarithm of the time series.</p> <p>Returns:</p> Type Description <code>Parray</code> <p>Natural logarithm of the time series</p>"},{"location":"api/parray/#pypulate.dtypes.parray.Parray.macd","title":"<code>macd(fast_period=12, slow_period=26, signal_period=9)</code>","text":"<p>Calculate Moving Average Convergence Divergence (MACD).</p> <p>MACD is a trend-following momentum indicator that shows the relationship between two moving averages of a security's price.</p> <p>Parameters:</p> Name Type Description Default <code>fast_period</code> <code>int</code> <p>Period for the fast EMA</p> <code>12</code> <code>slow_period</code> <code>int</code> <p>Period for the slow EMA</p> <code>26</code> <code>signal_period</code> <code>int</code> <p>Period for the signal line (EMA of MACD line)</p> <code>9</code> <p>Returns:</p> Type Description <code>tuple of Parray</code> <p>Tuple containing (macd_line, signal_line, histogram)</p>"},{"location":"api/parray/#pypulate.dtypes.parray.Parray.mcginley_dynamic","title":"<code>mcginley_dynamic(period=9, k=0.6)</code>","text":"<p>Apply McGinley Dynamic Indicator</p>"},{"location":"api/parray/#pypulate.dtypes.parray.Parray.median_filter","title":"<code>median_filter(kernel_size=3)</code>","text":"<p>Apply a median filter to the time series.</p> <p>Parameters:</p> Name Type Description Default <code>kernel_size</code> <code>int</code> <p>Size of the filter kernel</p> <code>3</code> <p>Returns:</p> Type Description <code>Parray</code> <p>Filtered time series</p>"},{"location":"api/parray/#pypulate.dtypes.parray.Parray.momentum","title":"<code>momentum(period=14)</code>","text":"<p>Calculate momentum over a specified period.</p> <p>Momentum measures the amount that a price has changed over a given period.</p> <p>Parameters:</p> Name Type Description Default <code>period</code> <code>int</code> <p>Number of periods to calculate momentum</p> <code>14</code> <p>Returns:</p> Type Description <code>Parray</code> <p>Momentum values</p>"},{"location":"api/parray/#pypulate.dtypes.parray.Parray.percent_change","title":"<code>percent_change(periods=1)</code>","text":"<p>Calculate percentage change between consecutive periods.</p> <p>Parameters:</p> Name Type Description Default <code>periods</code> <code>int</code> <p>Number of periods to calculate change over</p> <code>1</code> <p>Returns:</p> Type Description <code>Parray</code> <p>Percentage change values</p>"},{"location":"api/parray/#pypulate.dtypes.parray.Parray.roc","title":"<code>roc(period=14)</code>","text":"<p>Calculate Rate of Change (ROC) over a specified period.</p> <p>ROC measures the percentage change in price over a given period.</p> <p>Parameters:</p> Name Type Description Default <code>period</code> <code>int</code> <p>Number of periods to calculate ROC</p> <code>14</code> <p>Returns:</p> Type Description <code>Parray</code> <p>ROC values in percentage</p>"},{"location":"api/parray/#pypulate.dtypes.parray.Parray.rolling_max","title":"<code>rolling_max(period=14)</code>","text":"<p>Calculate rolling maximum over a specified period.</p> <p>Parameters:</p> Name Type Description Default <code>period</code> <code>int</code> <p>Window size for rolling maximum</p> <code>14</code> <p>Returns:</p> Type Description <code>Parray</code> <p>Rolling maximum values</p>"},{"location":"api/parray/#pypulate.dtypes.parray.Parray.rolling_min","title":"<code>rolling_min(period=14)</code>","text":"<p>Calculate rolling minimum over a specified period.</p> <p>Parameters:</p> Name Type Description Default <code>period</code> <code>int</code> <p>Window size for rolling minimum</p> <code>14</code> <p>Returns:</p> Type Description <code>Parray</code> <p>Rolling minimum values</p>"},{"location":"api/parray/#pypulate.dtypes.parray.Parray.rolling_std","title":"<code>rolling_std(period=14)</code>","text":"<p>Calculate rolling standard deviation over a specified period.</p> <p>Parameters:</p> Name Type Description Default <code>period</code> <code>int</code> <p>Window size for rolling standard deviation</p> <code>14</code> <p>Returns:</p> Type Description <code>Parray</code> <p>Rolling standard deviation values</p>"},{"location":"api/parray/#pypulate.dtypes.parray.Parray.rolling_var","title":"<code>rolling_var(period=14)</code>","text":"<p>Calculate rolling variance over a specified period.</p> <p>Parameters:</p> Name Type Description Default <code>period</code> <code>int</code> <p>Window size for rolling variance</p> <code>14</code> <p>Returns:</p> Type Description <code>Parray</code> <p>Rolling variance values</p>"},{"location":"api/parray/#pypulate.dtypes.parray.Parray.rsi","title":"<code>rsi(period=14, smoothing_type='sma')</code>","text":"<p>Calculate Relative Strength Index (RSI) over a specified period.</p> <p>RSI measures the speed and change of price movements, indicating overbought (&gt;70) or oversold (&lt;30) conditions.</p> <p>Parameters:</p> Name Type Description Default <code>period</code> <code>int</code> <p>Number of periods to calculate RSI</p> <code>14</code> <code>smoothing_type</code> <code>str</code> <p>Type of smoothing to use: 'sma' (Simple Moving Average) or  'ema' (Exponential Moving Average)</p> <code>'sma'</code> <p>Returns:</p> Type Description <code>Parray</code> <p>RSI values (0-100)</p>"},{"location":"api/parray/#pypulate.dtypes.parray.Parray.savitzky_golay_filter","title":"<code>savitzky_golay_filter(window_length=11, polyorder=3, deriv=0, delta=1.0)</code>","text":"<p>Apply a Savitzky-Golay filter to the time series.</p> <p>Parameters:</p> Name Type Description Default <code>window_length</code> <code>int</code> <p>Length of the filter window (must be odd)</p> <code>11</code> <code>polyorder</code> <code>int</code> <p>Order of the polynomial used to fit the samples</p> <code>3</code> <code>deriv</code> <code>int</code> <p>Order of the derivative to compute</p> <code>0</code> <code>delta</code> <code>float</code> <p>Spacing of the samples to which the filter is applied</p> <code>1.0</code> <p>Returns:</p> Type Description <code>Parray</code> <p>Filtered time series</p>"},{"location":"api/parray/#pypulate.dtypes.parray.Parray.slope","title":"<code>slope(period=5)</code>","text":"<p>Calculate the slope of the time series over a specified period.</p> <p>This method uses linear regression to calculate the slope of the line that best fits the data over the specified period.</p> <p>Parameters:</p> Name Type Description Default <code>period</code> <code>int</code> <p>Number of points to use for slope calculation</p> <code>5</code> <p>Returns:</p> Type Description <code>Parray</code> <p>Slope values for each point in the time series</p>"},{"location":"api/parray/#pypulate.dtypes.parray.Parray.sma","title":"<code>sma(period=9)</code>","text":"<p>Apply Simple Moving Average</p>"},{"location":"api/parray/#pypulate.dtypes.parray.Parray.smma","title":"<code>smma(period=9)</code>","text":"<p>Apply Smoothed Moving Average</p>"},{"location":"api/parray/#pypulate.dtypes.parray.Parray.stochastic_oscillator","title":"<code>stochastic_oscillator(high, low, k_period=14, d_period=3)</code>","text":"<p>Calculate Stochastic Oscillator.</p> <p>The Stochastic Oscillator is a momentum indicator that shows the location of the close relative to the high-low range over a set number of periods.</p> <p>Parameters:</p> Name Type Description Default <code>high</code> <code>ndarray</code> <p>High prices. If None, assumes self contains close prices and high=low=self</p> required <code>low</code> <code>ndarray</code> <p>Low prices. If None, assumes self contains close prices and high=low=self</p> required <code>k_period</code> <code>int</code> <p>Number of periods for %K</p> <code>14</code> <code>d_period</code> <code>int</code> <p>Number of periods for %D (moving average of %K)</p> <code>3</code> <p>Returns:</p> Type Description <code>tuple of Parray</code> <p>Tuple containing (%K, %D)</p>"},{"location":"api/parray/#pypulate.dtypes.parray.Parray.t3","title":"<code>t3(period=9, vfactor=0.7)</code>","text":"<p>Apply Tillson T3 Moving Average</p>"},{"location":"api/parray/#pypulate.dtypes.parray.Parray.tma","title":"<code>tma(period=9)</code>","text":"<p>Apply Triangular Moving Average</p>"},{"location":"api/parray/#pypulate.dtypes.parray.Parray.tsi","title":"<code>tsi(long_period=25, short_period=13, signal_period=7)</code>","text":"<p>Calculate True Strength Index (TSI).</p> <p>TSI is a momentum oscillator that helps identify trends and reversals.</p> <p>Parameters:</p> Name Type Description Default <code>long_period</code> <code>int</code> <p>Long period for double smoothing</p> <code>25</code> <code>short_period</code> <code>int</code> <p>Short period for double smoothing</p> <code>13</code> <code>signal_period</code> <code>int</code> <p>Period for the signal line</p> <code>7</code> <p>Returns:</p> Type Description <code>tuple of Parray</code> <p>Tuple containing (tsi_line, signal_line)</p>"},{"location":"api/parray/#pypulate.dtypes.parray.Parray.typical_price","title":"<code>typical_price(high, low)</code>","text":"<p>Calculate the typical price from close, high, and low prices.</p> <p>Parameters:</p> Name Type Description Default <code>high</code> <code>ndarray</code> <p>High prices. If None, uses self</p> required <code>low</code> <code>ndarray</code> <p>Low prices. If None, uses self</p> required <p>Returns:</p> Type Description <code>Parray</code> <p>Typical price values</p>"},{"location":"api/parray/#pypulate.dtypes.parray.Parray.volatility_ratio","title":"<code>volatility_ratio(period=21, smooth_period=5)</code>","text":"<p>Calculate Volatility Ratio over a specified period.</p> <p>Volatility Ratio compares recent volatility to historical volatility. Values above 1 indicate increasing volatility, values below 1 indicate decreasing volatility.</p> <p>Parameters:</p> Name Type Description Default <code>period</code> <code>int</code> <p>Number of periods for historical volatility</p> <code>21</code> <code>smooth_period</code> <code>int</code> <p>Number of periods to smooth the ratio</p> <code>5</code> <p>Returns:</p> Type Description <code>Parray</code> <p>Volatility Ratio values</p>"},{"location":"api/parray/#pypulate.dtypes.parray.Parray.williams_r","title":"<code>williams_r(high=None, low=None, period=14)</code>","text":"<p>Calculate Williams %R.</p> <p>Williams %R is a momentum indicator that measures overbought and oversold levels.</p> <p>Parameters:</p> Name Type Description Default <code>high</code> <code>ndarray</code> <p>High prices. If None, assumes self contains close prices and high=low=self</p> <code>None</code> <code>low</code> <code>ndarray</code> <p>Low prices. If None, assumes self contains close prices and high=low=self</p> <code>None</code> <code>period</code> <code>int</code> <p>Number of periods for calculation</p> <code>14</code> <p>Returns:</p> Type Description <code>Parray</code> <p>Williams %R values (-100 to 0)</p>"},{"location":"api/parray/#pypulate.dtypes.parray.Parray.wma","title":"<code>wma(period=9)</code>","text":"<p>Apply Weighted Moving Average</p>"},{"location":"api/parray/#pypulate.dtypes.parray.Parray.zigzag","title":"<code>zigzag(threshold=0.03)</code>","text":"<p>Extract zigzag pivot points from price data based on a percentage threshold.</p> <p>Parameters:</p> Name Type Description Default <code>threshold</code> <code>float</code> <p>Minimum percentage change required to identify a new pivot point (0.03 = 3%)</p> <code>0.03</code> <p>Returns:</p> Type Description <code>Parray</code> <p>2D array of zigzag points with shape (n, 2), where each row contains [index, price]</p> Notes <p>The algorithm identifies significant price movements while filtering out minor fluctuations. It marks pivot points where the price changes direction by at least the specified threshold percentage.</p>"},{"location":"api/parray/#pypulate.dtypes.parray.Parray.zlma","title":"<code>zlma(period=9)</code>","text":"<p>Apply Zero-Lag Moving Average</p>"},{"location":"api/parray/#pypulate.dtypes.parray.Parray.zscore","title":"<code>zscore(period=14)</code>","text":"<p>Calculate rolling z-score over a specified period.</p> <p>Parameters:</p> Name Type Description Default <code>period</code> <code>int</code> <p>Window size for rolling z-score calculation</p> <code>14</code> <p>Returns:</p> Type Description <code>Parray</code> <p>Rolling z-score values</p>"},{"location":"api/portfolio/","title":"Portfolio API Reference","text":"<p>Portfolio Module</p> <p>This module provides a class for calculating various portfolio metrics including returns, risk-adjusted performance, and risk measurements.</p>"},{"location":"api/portfolio/#pypulate.dtypes.portfolio.Portfolio","title":"<code>Portfolio</code>","text":"<p>A class for calculating various portfolio metrics and assessing portfolio health.</p> <p>This class provides methods for calculating portfolio returns, risk-adjusted performance metrics, and risk measurements, while maintaining state to assess overall portfolio health.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from pypulate.dtypes import Portfolio\n&gt;&gt;&gt; portfolio = Portfolio()\n&gt;&gt;&gt; returns = portfolio.simple_return(105, 100)\n&gt;&gt;&gt; sharpe = portfolio.sharpe_ratio([0.01, 0.02, -0.01, 0.03, 0.01])\n&gt;&gt;&gt; health = portfolio.health\n</code></pre>"},{"location":"api/portfolio/#pypulate.dtypes.portfolio.Portfolio.health","title":"<code>health</code>  <code>property</code>","text":"<p>Calculate and return the overall health of the portfolio based on stored metrics.</p> <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary containing: - overall_score: Float between 0 and 100 - status: String indicating health status - components: Dictionary of component scores and metrics     - returns: Return metrics and score     - risk_adjusted: Risk-adjusted performance metrics and score     - risk: Risk metrics and score</p>"},{"location":"api/portfolio/#pypulate.dtypes.portfolio.Portfolio.__init__","title":"<code>__init__()</code>","text":"<p>Initialize the Portfolio class with empty state.</p>"},{"location":"api/portfolio/#pypulate.dtypes.portfolio.Portfolio.annualized_return","title":"<code>annualized_return(total_return, years)</code>","text":"<p>Calculate the annualized return from a total return over a period of years.</p> <p>Parameters:</p> Name Type Description Default <code>total_return</code> <code>float or array - like</code> <p>The total return over the entire period as a decimal</p> required <code>years</code> <code>float or array - like</code> <p>The number of years in the period</p> required <p>Returns:</p> Type Description <code>float or ndarray</code> <p>The annualized return as a decimal If array inputs are provided, returns an array of annualized returns</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; annualized_return(0.2, 2)\n0.09544511501033215\n&gt;&gt;&gt; annualized_return([0.2, 0.3, 0.15], [2, 3, 1.5])\n[0.09544512, 0.09139288, 0.0976534 ]\n&gt;&gt;&gt; annualized_return(np.array([0.4, 0.5]), 2)\n[0.18321596, 0.22474487]\n</code></pre>"},{"location":"api/portfolio/#pypulate.dtypes.portfolio.Portfolio.arithmetic_return","title":"<code>arithmetic_return(prices)</code>","text":"<p>Calculate the arithmetic average return from a series of prices.</p> <p>Parameters:</p> Name Type Description Default <code>prices</code> <code>array - like</code> <p>Array or list of prices</p> required <p>Returns:</p> Type Description <code>float</code> <p>The arithmetic average return as a decimal</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; arithmetic_return([100, 105, 103, 108, 110])\n0.024503647197821957\n</code></pre>"},{"location":"api/portfolio/#pypulate.dtypes.portfolio.Portfolio.benchmark_alpha","title":"<code>benchmark_alpha(returns, benchmark_returns)</code>","text":"<p>Calculate the benchmark alpha, which is the difference between portfolio return and benchmark return.</p> <p>Parameters:</p> Name Type Description Default <code>returns</code> <code>array - like</code> <p>Array of portfolio returns</p> required <code>benchmark_returns</code> <code>array - like</code> <p>Array of benchmark returns for the same periods</p> required <p>Returns:</p> Type Description <code>float</code> <p>The benchmark alpha (difference in mean returns)</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; benchmark_alpha([0.01, 0.02, -0.01, 0.03, 0.01], [0.005, 0.01, -0.005, 0.02, 0.005])\n0.005\n</code></pre>"},{"location":"api/portfolio/#pypulate.dtypes.portfolio.Portfolio.beta_adjusted_return","title":"<code>beta_adjusted_return(portfolio_return, benchmark_return, portfolio_beta)</code>","text":"<p>Calculate the beta-adjusted return (alpha) of a portfolio.</p> <p>Parameters:</p> Name Type Description Default <code>portfolio_return</code> <code>float or array - like</code> <p>The return of the portfolio as a decimal</p> required <code>benchmark_return</code> <code>float or array - like</code> <p>The return of the benchmark as a decimal</p> required <code>portfolio_beta</code> <code>float or array - like</code> <p>The beta of the portfolio relative to the benchmark</p> required <p>Returns:</p> Type Description <code>float or ndarray</code> <p>The beta-adjusted return (alpha) as a decimal If array inputs are provided, returns an array of beta-adjusted returns</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; beta_adjusted_return(0.12, 0.10, 1.2)\n0.0\n&gt;&gt;&gt; beta_adjusted_return([0.12, 0.15], [0.10, 0.08], 1.2)\n[0.   , 0.054]\n&gt;&gt;&gt; beta_adjusted_return(0.12, 0.10, [1.2, 1.5])\n[ 0.  , -0.03]\n</code></pre>"},{"location":"api/portfolio/#pypulate.dtypes.portfolio.Portfolio.calmar_ratio","title":"<code>calmar_ratio(returns, max_drawdown=None, annualization_factor=1.0)</code>","text":"<p>Calculate the Calmar ratio, which measures return relative to maximum drawdown.</p> <p>Parameters:</p> Name Type Description Default <code>returns</code> <code>array - like</code> <p>Array of portfolio returns</p> required <code>max_drawdown</code> <code>float</code> <p>Maximum drawdown as a positive decimal. If None, it will be calculated from returns.</p> <code>None</code> <code>annualization_factor</code> <code>float</code> <p>Factor to annualize returns</p> <code>1.0</code> <p>Returns:</p> Type Description <code>float</code> <p>The Calmar ratio</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; calmar_ratio([0.01, 0.02, -0.01, 0.03, 0.01], 0.15, 252)\n0.8\n</code></pre>"},{"location":"api/portfolio/#pypulate.dtypes.portfolio.Portfolio.capm_alpha","title":"<code>capm_alpha(returns, benchmark_returns, risk_free_rate=0.0)</code>","text":"<p>Calculate the CAPM alpha (Jensen's alpha) and related statistics.</p> <p>Parameters:</p> Name Type Description Default <code>returns</code> <code>array - like</code> <p>Array of portfolio returns</p> required <code>benchmark_returns</code> <code>array - like</code> <p>Array of benchmark returns for the same periods</p> required <code>risk_free_rate</code> <code>float or array - like</code> <p>Risk-free rate for the same period as returns</p> <code>0.0</code> <p>Returns:</p> Type Description <code>tuple</code> <p>(alpha, beta, r_squared, p_value, std_err) - alpha: The CAPM alpha (intercept) - beta: The CAPM beta (slope) - r_squared: The R-squared of the regression - p_value: The p-value for alpha - std_err: The standard error of alpha</p>"},{"location":"api/portfolio/#pypulate.dtypes.portfolio.Portfolio.capm_beta","title":"<code>capm_beta(portfolio_returns, market_returns)</code>","text":"<p>Calculate the CAPM beta of a portfolio.</p> <p>Parameters:</p> Name Type Description Default <code>portfolio_returns</code> <code>list or ndarray</code> <p>Array or list of portfolio returns</p> required <code>market_returns</code> <code>list or ndarray</code> <p>Array or list of market returns</p> required <p>Returns:</p> Type Description <code>float</code> <p>CAPM beta</p> Notes <p>Beta measures the sensitivity of portfolio returns to market returns. It is the covariance of portfolio returns and market returns divided by the variance of market returns.</p>"},{"location":"api/portfolio/#pypulate.dtypes.portfolio.Portfolio.conditional_value_at_risk","title":"<code>conditional_value_at_risk(returns, confidence_level=0.95, method='historical', current_value=1.0)</code>","text":"<p>Calculate the Conditional Value-at-Risk (CVaR) of a portfolio.</p> <p>Parameters:</p> Name Type Description Default <code>returns</code> <code>list or ndarray</code> <p>Array or list of returns</p> required <code>confidence_level</code> <code>float</code> <p>Confidence level for CVaR calculation (e.g., 0.95 for 95% confidence)</p> <code>0.95</code> <code>method</code> <code>str</code> <p>Method for calculating CVaR ('historical' or 'parametric')</p> <code>'historical'</code> <code>current_value</code> <code>float</code> <p>Current value of the portfolio</p> <code>1.0</code> <p>Returns:</p> Type Description <code>float</code> <p>Conditional Value-at-Risk (CVaR) as a positive number representing the potential loss</p> Notes <p>CVaR, also known as Expected Shortfall, measures the expected loss given that the loss exceeds the VaR threshold. It provides a more conservative risk measure than VaR.</p>"},{"location":"api/portfolio/#pypulate.dtypes.portfolio.Portfolio.correlation_matrix","title":"<code>correlation_matrix(returns_matrix)</code>","text":"<p>Calculate the correlation matrix of returns.</p> <p>Parameters:</p> Name Type Description Default <code>returns_matrix</code> <code>list of lists or np.ndarray</code> <p>Matrix of returns where each column represents an asset</p> required <p>Returns:</p> Type Description <code>np.ndarray or list of lists</code> <p>Correlation matrix</p> Notes <p>The correlation matrix measures the strength of the relationship between returns of different assets, normalized to be between -1 and 1.</p>"},{"location":"api/portfolio/#pypulate.dtypes.portfolio.Portfolio.covariance_matrix","title":"<code>covariance_matrix(returns_matrix)</code>","text":"<p>Calculate the covariance matrix of returns.</p> <p>Parameters:</p> Name Type Description Default <code>returns_matrix</code> <code>list of lists or np.ndarray</code> <p>Matrix of returns where each column represents an asset</p> required <p>Returns:</p> Type Description <code>np.ndarray or list of lists</code> <p>Covariance matrix</p> Notes <p>The covariance matrix measures how returns of different assets move together.</p>"},{"location":"api/portfolio/#pypulate.dtypes.portfolio.Portfolio.dollar_weighted_return","title":"<code>dollar_weighted_return(cash_flows, cash_flow_dates, end_value)</code>","text":"<p>Calculate the dollar-weighted return (internal rate of return) for a series of cash flows.</p> <p>Parameters:</p> Name Type Description Default <code>cash_flows</code> <code>array - like</code> <p>Array or list of cash flows (positive for inflows, negative for outflows)</p> required <code>cash_flow_dates</code> <code>array - like</code> <p>Array or list of dates (in days) when each cash flow occurs</p> required <code>end_value</code> <code>float</code> <p>The final value of the investment</p> required <p>Returns:</p> Type Description <code>float</code> <p>The dollar-weighted return as a decimal</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; dollar_weighted_return([-1000, -500, 200], [0, 30, 60], 1400)\n0.36174448410245186\n</code></pre>"},{"location":"api/portfolio/#pypulate.dtypes.portfolio.Portfolio.drawdown","title":"<code>drawdown(returns, as_list=False)</code>","text":"<p>Calculate drawdown metrics.</p>"},{"location":"api/portfolio/#pypulate.dtypes.portfolio.Portfolio.geometric_return","title":"<code>geometric_return(prices)</code>","text":"<p>Calculate the geometric average return from a series of prices.</p> <p>Parameters:</p> Name Type Description Default <code>prices</code> <code>array - like</code> <p>Array or list of prices</p> required <p>Returns:</p> Type Description <code>float</code> <p>The geometric average return as a decimal</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; geometric_return([100, 105, 103, 108, 110])\n0.02411368908444511\n</code></pre>"},{"location":"api/portfolio/#pypulate.dtypes.portfolio.Portfolio.holding_period_return","title":"<code>holding_period_return(prices, dividends=None)</code>","text":"<p>Calculate the holding period return for a series of prices and optional dividends.</p> <p>Parameters:</p> Name Type Description Default <code>prices</code> <code>array - like</code> <p>Array or list of prices over the holding period</p> required <code>dividends</code> <code>array - like</code> <p>Array or list of dividends paid during the holding period</p> <code>None</code> <p>Returns:</p> Type Description <code>float</code> <p>The holding period return as a decimal</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; holding_period_return([100, 102, 105, 103, 106])\n0.06\n&gt;&gt;&gt; holding_period_return([100, 102, 105, 103, 106], [0, 1, 0, 2, 0])\n0.09\n</code></pre>"},{"location":"api/portfolio/#pypulate.dtypes.portfolio.Portfolio.information_ratio","title":"<code>information_ratio(returns, benchmark_returns, annualization_factor=1.0)</code>","text":"<p>Calculate the Information ratio, which measures excess return per unit of tracking error.</p> <p>Parameters:</p> Name Type Description Default <code>returns</code> <code>array - like</code> <p>Array of portfolio returns</p> required <code>benchmark_returns</code> <code>array - like</code> <p>Array of benchmark returns for the same periods</p> required <code>annualization_factor</code> <code>float</code> <p>Factor to annualize the Information ratio (e.g., 252 for daily returns to annual)</p> <code>1.0</code> <p>Returns:</p> Type Description <code>float</code> <p>The Information ratio</p>"},{"location":"api/portfolio/#pypulate.dtypes.portfolio.Portfolio.leveraged_return","title":"<code>leveraged_return(unleveraged_return, leverage_ratio, borrowing_rate)</code>","text":"<p>Calculate the return of a leveraged portfolio.</p> <p>Parameters:</p> Name Type Description Default <code>unleveraged_return</code> <code>float or array - like</code> <p>The return of the unleveraged portfolio as a decimal</p> required <code>leverage_ratio</code> <code>float or array - like</code> <p>The leverage ratio (e.g., 2.0 for 2:1 leverage)</p> required <code>borrowing_rate</code> <code>float or array - like</code> <p>The borrowing rate as a decimal</p> required <p>Returns:</p> Type Description <code>float or ndarray</code> <p>The leveraged return as a decimal If array inputs are provided, returns an array of leveraged returns</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; leveraged_return(0.10, 2.0, 0.05)\n0.15\n&gt;&gt;&gt; leveraged_return([0.10, 0.15], [2.0, 1.5], 0.05)\n[0.15, 0.2 ]\n&gt;&gt;&gt; leveraged_return(0.10, [2.0, 3.0], [0.05, 0.06])\n[0.15, 0.18]\n</code></pre>"},{"location":"api/portfolio/#pypulate.dtypes.portfolio.Portfolio.linked_modified_dietz_return","title":"<code>linked_modified_dietz_return(period_returns)</code>","text":"<p>Calculate the linked Modified Dietz return over multiple periods.</p> <p>Parameters:</p> Name Type Description Default <code>period_returns</code> <code>array - like</code> <p>Array or list of Modified Dietz returns for each period</p> required <p>Returns:</p> Type Description <code>float</code> <p>The linked Modified Dietz return as a decimal</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; linked_modified_dietz_return([0.05, -0.02, 0.03, 0.04])\n0.10226479999999993\n</code></pre>"},{"location":"api/portfolio/#pypulate.dtypes.portfolio.Portfolio.log_return","title":"<code>log_return(end_value, start_value)</code>","text":"<p>Calculate the logarithmic (continuously compounded) return between two values.</p> <p>Parameters:</p> Name Type Description Default <code>end_value</code> <code>float or array - like</code> <p>The ending value(s) of the investment</p> required <code>start_value</code> <code>float or array - like</code> <p>The starting value(s) of the investment</p> required <p>Returns:</p> Type Description <code>float or ndarray</code> <p>The logarithmic return If array inputs are provided, returns an array of logarithmic returns</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; log_return(105, 100)\n0.04879016416929972\n&gt;&gt;&gt; log_return([105, 110, 108], [100, 100, 100])\narray([0.04879016, 0.09531018, 0.07696104])\n&gt;&gt;&gt; log_return(np.array([105, 110]), np.array([100, 100]))\narray([0.04879016, 0.09531018])\n</code></pre>"},{"location":"api/portfolio/#pypulate.dtypes.portfolio.Portfolio.long_short_equity_return","title":"<code>long_short_equity_return(long_portfolio_return, short_portfolio_return, long_exposure, short_exposure, risk_free_rate=0.0, short_rebate=0.0)</code>","text":"<p>Calculate the return of a long-short equity portfolio.</p> <p>Parameters:</p> Name Type Description Default <code>long_portfolio_return</code> <code>float or array - like</code> <p>The return of the long portfolio as a decimal</p> required <code>short_portfolio_return</code> <code>float or array - like</code> <p>The return of the short portfolio as a decimal</p> required <code>long_exposure</code> <code>float or array - like</code> <p>The exposure of the long portfolio as a decimal of NAV</p> required <code>short_exposure</code> <code>float or array - like</code> <p>The exposure of the short portfolio as a decimal of NAV</p> required <code>risk_free_rate</code> <code>float or array - like</code> <p>The risk-free rate as a decimal</p> <code>0.0</code> <code>short_rebate</code> <code>float or array - like</code> <p>The rebate received on short proceeds as a decimal</p> <code>0.0</code> <p>Returns:</p> Type Description <code>float or ndarray</code> <p>The return of the long-short equity portfolio as a decimal If array inputs are provided, returns an array of long-short equity returns</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; long_short_equity_return(0.10, -0.05, 1.0, 0.5, 0.02, 0.01)\n0.14\n&gt;&gt;&gt; long_short_equity_return([0.10, 0.12], [-0.05, -0.03], 1.0, 0.5, 0.02, 0.01)\n[0.14, 0.15]\n&gt;&gt;&gt; long_short_equity_return(0.10, -0.05, [1.0, 0.8], [0.5, 0.4], [0.02, 0.03], 0.01)\n[0.14 , 0.122]\n</code></pre>"},{"location":"api/portfolio/#pypulate.dtypes.portfolio.Portfolio.market_neutral_return","title":"<code>market_neutral_return(long_return, short_return, long_weight=0.5, short_weight=0.5, short_borrowing_cost=0.0)</code>","text":"<p>Calculate the return of a market-neutral portfolio with long and short positions.</p> <p>Parameters:</p> Name Type Description Default <code>long_return</code> <code>float or array - like</code> <p>The return of the long portfolio as a decimal</p> required <code>short_return</code> <code>float or array - like</code> <p>The return of the short portfolio as a decimal</p> required <code>long_weight</code> <code>float or array - like</code> <p>The weight of the long portfolio</p> <code>0.5</code> <code>short_weight</code> <code>float or array - like</code> <p>The weight of the short portfolio</p> <code>0.5</code> <code>short_borrowing_cost</code> <code>float or array - like</code> <p>The cost of borrowing for the short position as a decimal</p> <code>0.0</code> <p>Returns:</p> Type Description <code>float or ndarray</code> <p>The market-neutral return as a decimal If array inputs are provided, returns an array of market-neutral returns</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; market_neutral_return(0.08, -0.05, 0.6, 0.4, 0.01)\n0.064\n&gt;&gt;&gt; market_neutral_return([0.08, 0.10], [-0.05, -0.03], 0.6, 0.4, 0.01)\n[0.064, 0.068]\n&gt;&gt;&gt; market_neutral_return(0.08, -0.05, [0.6, 0.7], [0.4, 0.3], [0.01, 0.02])\n[0.064, 0.065]\n</code></pre>"},{"location":"api/portfolio/#pypulate.dtypes.portfolio.Portfolio.modified_dietz_return","title":"<code>modified_dietz_return(start_value, end_value, cash_flows, cash_flow_days, total_days)</code>","text":"<p>Calculate the Modified Dietz return, which approximates the money-weighted return.</p> <p>Parameters:</p> Name Type Description Default <code>start_value</code> <code>float</code> <p>The starting value of the investment</p> required <code>end_value</code> <code>float</code> <p>The ending value of the investment</p> required <code>cash_flows</code> <code>array - like</code> <p>Array or list of cash flows (positive for inflows, negative for outflows)</p> required <code>cash_flow_days</code> <code>array - like</code> <p>Array or list of days when each cash flow occurs (day 0 is the start)</p> required <code>total_days</code> <code>int</code> <p>Total number of days in the period</p> required <p>Returns:</p> Type Description <code>float</code> <p>The Modified Dietz return as a decimal</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; modified_dietz_return(1000, 1200, [100, -50], [10, 20], 30)\n0.14285714285714285\n</code></pre>"},{"location":"api/portfolio/#pypulate.dtypes.portfolio.Portfolio.money_weighted_return","title":"<code>money_weighted_return(cash_flows, cash_flow_times, final_value, initial_value=0, max_iterations=100, tolerance=1e-06)</code>","text":"<p>Calculate the money-weighted return (internal rate of return) for a series of cash flows.</p> <p>Parameters:</p> Name Type Description Default <code>cash_flows</code> <code>array - like</code> <p>Array or list of cash flows (positive for inflows, negative for outflows)</p> required <code>cash_flow_times</code> <code>array - like</code> <p>Array or list of times (in years) when each cash flow occurs</p> required <code>final_value</code> <code>float</code> <p>The final value of the investment</p> required <code>initial_value</code> <code>float</code> <p>The initial value of the investment</p> <code>0</code> <code>max_iterations</code> <code>int</code> <p>Maximum number of iterations for the numerical solver</p> <code>100</code> <code>tolerance</code> <code>float</code> <p>Convergence tolerance for the numerical solver</p> <code>1e-6</code> <p>Returns:</p> Type Description <code>float</code> <p>The money-weighted return (IRR) as a decimal</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; money_weighted_return([-1000, -500, 1700], [0, 0.5, 1], 0)\n0.16120409753798307\n</code></pre>"},{"location":"api/portfolio/#pypulate.dtypes.portfolio.Portfolio.multifactor_alpha","title":"<code>multifactor_alpha(returns, factor_returns, risk_free_rate=0.0)</code>","text":"<p>Calculate the alpha from a multifactor model (e.g., Fama-French).</p> <p>Parameters:</p> Name Type Description Default <code>returns</code> <code>array - like</code> <p>Array of portfolio returns</p> required <code>factor_returns</code> <code>array - like</code> <p>2D array where each column represents returns for a factor</p> required <code>risk_free_rate</code> <code>float or array - like</code> <p>Risk-free rate for the same period as returns</p> <code>0.0</code> <p>Returns:</p> Type Description <code>tuple</code> <p>(alpha, betas, r_squared, p_value, std_err) - alpha: The multifactor alpha (intercept) - betas: Array of factor betas (coefficients) - r_squared: The R-squared of the regression - p_value: The p-value for alpha - std_err: The standard error of alpha</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Example with market, size, and value factors\n&gt;&gt;&gt; portfolio_returns = [0.01, 0.02, -0.01, 0.03, 0.01]\n&gt;&gt;&gt; factor_returns = [\n...     [0.005, 0.01, -0.005, 0.02, 0.005],  # Market\n...     [0.002, 0.003, -0.001, 0.004, 0.001],  # Size\n...     [0.001, 0.002, -0.002, 0.003, 0.002]   # Value\n... ]\n&gt;&gt;&gt; multifactor_alpha(portfolio_returns, factor_returns, 0.001)\n(0.0032, array([0.9, 0.5, 0.3]), 0.92, 0.04, 0.0015)  # Example values\n</code></pre>"},{"location":"api/portfolio/#pypulate.dtypes.portfolio.Portfolio.omega_ratio","title":"<code>omega_ratio(returns, threshold=0.0, annualization_factor=1.0)</code>","text":"<p>Calculate the Omega ratio, which measures the probability-weighted ratio of gains versus losses.</p> <p>Parameters:</p> Name Type Description Default <code>returns</code> <code>array - like</code> <p>Array of portfolio returns</p> required <code>threshold</code> <code>float</code> <p>The threshold return</p> <code>0.0</code> <code>annualization_factor</code> <code>float</code> <p>Factor to annualize the threshold</p> <code>1.0</code> <p>Returns:</p> Type Description <code>float</code> <p>The Omega ratio</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; omega_ratio([0.01, 0.02, -0.01, 0.03, 0.01], 0.005)\n2.0\n</code></pre>"},{"location":"api/portfolio/#pypulate.dtypes.portfolio.Portfolio.semi_standard_deviation","title":"<code>semi_standard_deviation(returns, threshold=0.0, annualize=False, periods_per_year=252)</code>","text":"<p>Calculate the semi-standard deviation of returns below a threshold.</p> <p>Parameters:</p> Name Type Description Default <code>returns</code> <code>list or ndarray</code> <p>Array or list of returns</p> required <code>threshold</code> <code>float</code> <p>Threshold below which to calculate semi-standard deviation</p> <code>0.0</code> <code>annualize</code> <code>bool</code> <p>Whether to annualize the semi-standard deviation</p> <code>False</code> <code>periods_per_year</code> <code>int</code> <p>Number of periods in a year (252 for daily returns, 12 for monthly, 4 for quarterly)</p> <code>252</code> <p>Returns:</p> Type Description <code>float</code> <p>Semi-standard deviation of returns</p> Notes <p>Semi-standard deviation only considers returns below the threshold (typically 0), making it a measure of downside risk.</p>"},{"location":"api/portfolio/#pypulate.dtypes.portfolio.Portfolio.sharpe_ratio","title":"<code>sharpe_ratio(returns, risk_free_rate=0.0, annualization_factor=1.0)</code>","text":"<p>Calculate the Sharpe ratio, which measures excess return per unit of risk.</p> <p>Parameters:</p> Name Type Description Default <code>returns</code> <code>array - like</code> <p>Array of portfolio returns</p> required <code>risk_free_rate</code> <code>float or array - like</code> <p>Risk-free rate for the same period as returns</p> <code>0.0</code> <code>annualization_factor</code> <code>float</code> <p>Factor to annualize the Sharpe ratio (e.g., 252 for daily returns to annual)</p> <code>1.0</code> <p>Returns:</p> Type Description <code>float or ndarray</code> <p>The Sharpe ratio</p>"},{"location":"api/portfolio/#pypulate.dtypes.portfolio.Portfolio.simple_return","title":"<code>simple_return(end_value, start_value)</code>","text":"<p>Calculate the simple return (percentage change) between two values.</p> <p>Parameters:</p> Name Type Description Default <code>end_value</code> <code>float or array - like</code> <p>The ending value(s) of the investment</p> required <code>start_value</code> <code>float or array - like</code> <p>The starting value(s) of the investment</p> required <p>Returns:</p> Type Description <code>float or ndarray</code> <p>The simple return as a decimal (e.g., 0.05 for 5%) If array inputs are provided, returns an array of simple returns</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; simple_return(105, 100)\n0.05\n&gt;&gt;&gt; simple_return([105, 110, 108], [100, 100, 100])\narray([0.05, 0.1 , 0.08])\n&gt;&gt;&gt; simple_return(np.array([105, 110]), np.array([100, 100]))\narray([0.05, 0.1 ])\n</code></pre>"},{"location":"api/portfolio/#pypulate.dtypes.portfolio.Portfolio.sortino_ratio","title":"<code>sortino_ratio(returns, risk_free_rate=0.0, target_return=0.0, annualization_factor=1.0)</code>","text":"<p>Calculate the Sortino ratio, which measures excess return per unit of downside risk.</p> <p>Parameters:</p> Name Type Description Default <code>returns</code> <code>array - like</code> <p>Array of portfolio returns</p> required <code>risk_free_rate</code> <code>float or array - like</code> <p>Risk-free rate for the same period as returns</p> <code>0.0</code> <code>target_return</code> <code>float</code> <p>Minimum acceptable return</p> <code>0.0</code> <code>annualization_factor</code> <code>float</code> <p>Factor to annualize the Sortino ratio</p> <code>1.0</code> <p>Returns:</p> Type Description <code>float</code> <p>The Sortino ratio</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; sortino_ratio([0.01, 0.02, -0.01, 0.03, 0.01], 0.001, 0.0, 252)\n3.7947331922020545\n</code></pre>"},{"location":"api/portfolio/#pypulate.dtypes.portfolio.Portfolio.standard_deviation","title":"<code>standard_deviation(returns, annualize=False, periods_per_year=252)</code>","text":"<p>Calculate the standard deviation of returns.</p> <p>Parameters:</p> Name Type Description Default <code>returns</code> <code>list or ndarray</code> <p>Array or list of returns</p> required <code>annualize</code> <code>bool</code> <p>Whether to annualize the standard deviation</p> <code>False</code> <code>periods_per_year</code> <code>int</code> <p>Number of periods in a year (252 for daily returns, 12 for monthly, 4 for quarterly)</p> <code>252</code> <p>Returns:</p> Type Description <code>float</code> <p>Standard deviation of returns</p> Notes <p>Standard deviation measures the dispersion of returns around the mean. It is the square root of the variance.</p>"},{"location":"api/portfolio/#pypulate.dtypes.portfolio.Portfolio.time_weighted_return","title":"<code>time_weighted_return(period_returns)</code>","text":"<p>Calculate the time-weighted return from a series of period returns.</p> <p>Parameters:</p> Name Type Description Default <code>period_returns</code> <code>array - like</code> <p>Array or list of returns for each period</p> required <p>Returns:</p> Type Description <code>float</code> <p>The time-weighted return as a decimal</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; time_weighted_return([0.05, -0.02, 0.03, 0.04])\n0.10226479999999993\n</code></pre>"},{"location":"api/portfolio/#pypulate.dtypes.portfolio.Portfolio.total_return_index","title":"<code>total_return_index(prices, dividends=None)</code>","text":"<p>Calculate the total return index from a series of prices and optional dividends.</p> <p>Parameters:</p> Name Type Description Default <code>prices</code> <code>array - like</code> <p>Array or list of prices</p> required <code>dividends</code> <code>array - like</code> <p>Array or list of dividends paid</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The total return index</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; total_return_index([100, 102, 105, 103, 106])\n[100., 102., 105., 103., 106.]\n&gt;&gt;&gt; total_return_index([100, 102, 105, 103, 106], [0, 1, 0, 2, 0])\n[100.        , 103.        , 106.02941176, 106.02941176,\n109.11764706]\n</code></pre>"},{"location":"api/portfolio/#pypulate.dtypes.portfolio.Portfolio.tracking_error","title":"<code>tracking_error(portfolio_returns, benchmark_returns, annualize=False, periods_per_year=252)</code>","text":"<p>Calculate the tracking error between portfolio returns and benchmark returns.</p> <p>Parameters:</p> Name Type Description Default <code>portfolio_returns</code> <code>list or ndarray</code> <p>Array or list of portfolio returns</p> required <code>benchmark_returns</code> <code>list or ndarray</code> <p>Array or list of benchmark returns</p> required <code>annualize</code> <code>bool</code> <p>Whether to annualize the tracking error</p> <code>False</code> <code>periods_per_year</code> <code>int</code> <p>Number of periods in a year (252 for daily returns, 12 for monthly, 4 for quarterly)</p> <code>252</code> <p>Returns:</p> Type Description <code>float</code> <p>Tracking error</p> Notes <p>Tracking error measures how closely a portfolio follows its benchmark. It is the standard deviation of the difference between portfolio and benchmark returns.</p>"},{"location":"api/portfolio/#pypulate.dtypes.portfolio.Portfolio.treynor_ratio","title":"<code>treynor_ratio(returns, benchmark_returns, risk_free_rate=0.0, annualization_factor=1.0)</code>","text":"<p>Calculate the Treynor ratio, which measures excess return per unit of systematic risk.</p> <p>Parameters:</p> Name Type Description Default <code>returns</code> <code>array - like</code> <p>Array of portfolio returns</p> required <code>benchmark_returns</code> <code>array - like</code> <p>Array of benchmark returns for the same periods</p> required <code>risk_free_rate</code> <code>float or array - like</code> <p>Risk-free rate for the same period as returns</p> <code>0.0</code> <code>annualization_factor</code> <code>float</code> <p>Factor to annualize the Treynor ratio</p> <code>1.0</code> <p>Returns:</p> Type Description <code>float</code> <p>The Treynor ratio</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; treynor_ratio([0.01, 0.02, -0.01, 0.03, 0.01], [0.005, 0.01, -0.005, 0.02, 0.005], 0.001, 252)\n0.0378\n</code></pre>"},{"location":"api/portfolio/#pypulate.dtypes.portfolio.Portfolio.value_at_risk","title":"<code>value_at_risk(returns, confidence_level=0.95, method='historical', parametric_mean=None, parametric_std=None, current_value=1.0)</code>","text":"<p>Calculate the Value-at-Risk (VaR) of a portfolio.</p> <p>Parameters:</p> Name Type Description Default <code>returns</code> <code>list or ndarray</code> <p>Array or list of returns</p> required <code>confidence_level</code> <code>float</code> <p>Confidence level for VaR calculation (e.g., 0.95 for 95% confidence)</p> <code>0.95</code> <code>method</code> <code>str</code> <p>Method for calculating VaR ('historical', 'parametric', or 'monte_carlo')</p> <code>'historical'</code> <code>parametric_mean</code> <code>float</code> <p>Mean for parametric VaR calculation (if None, calculated from returns)</p> <code>None</code> <code>parametric_std</code> <code>float</code> <p>Standard deviation for parametric VaR calculation (if None, calculated from returns)</p> <code>None</code> <code>current_value</code> <code>float</code> <p>Current value of the portfolio</p> <code>1.0</code> <p>Returns:</p> Type Description <code>float</code> <p>Value-at-Risk (VaR) as a positive number representing the potential loss</p> Notes <p>VaR measures the potential loss in value of a portfolio over a defined period for a given confidence interval.</p>"},{"location":"api/transforms/","title":"sransforms API Reference","text":"<p>Wave and zigzag transforms for financial time series data.</p> <p>This module provides functions for extracting wave points and zigzag patterns from financial time series data, which are useful for technical analysis.</p>"},{"location":"api/transforms/#pypulate.transforms.wave.wave","title":"<code>wave(open, high, low, close)</code>","text":"<p>Extract wave points from OHLC financial data.</p> <p>This function processes OHLC data to extract price points based on candlestick patterns, and removes consecutive points that follow the same trend direction.</p> <p>Parameters:</p> Name Type Description Default <code>open</code> <code>ndarray</code> <p>Array of opening prices</p> required <code>high</code> <code>ndarray</code> <p>Array of high prices</p> required <code>low</code> <code>ndarray</code> <p>Array of low prices</p> required <code>close</code> <code>ndarray</code> <p>Array of closing prices</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>2D array of wave points with shape (n, 2), where each row contains [index, price]</p> Notes <p>The algorithm works as follows: 1. For each candle:    - If close &gt; open: adds low then high to the price list    - If close &lt; open: adds high then low to the price list 2. Removes intermediate points where three consecutive points form a consistent trend    (either all increasing or all decreasing)</p>"},{"location":"api/transforms/#pypulate.transforms.wave.zigzag","title":"<code>zigzag(prices, threshold=0.03)</code>","text":"<p>Extract zigzag pivot points from price data based on a percentage threshold.</p> <p>Parameters:</p> Name Type Description Default <code>prices</code> <code>ndarray or list</code> <p>1D array/list of price values or 2D array/list of [index, price] points</p> required <code>threshold</code> <code>float</code> <p>Minimum percentage change required to identify a new pivot point (0.03 = 3%)</p> <code>0.03</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>2D array of zigzag points with shape (n, 2), where each row contains [index, price]</p> Notes <p>The algorithm identifies significant price movements while filtering out minor fluctuations. It marks pivot points where the price changes direction by at least the specified threshold percentage.</p>"},{"location":"api/credit/altman_z_score/","title":"Altman Z-Score API Reference","text":"<p>This page documents the API for the Altman Z-Score function in Pypulate.</p> <p>Altman Z-Score for bankruptcy prediction.</p>"},{"location":"api/credit/altman_z_score/#pypulate.credit.altman_z_score.altman_z_score","title":"<code>altman_z_score(working_capital, retained_earnings, ebit, market_value_equity, sales, total_assets, total_liabilities)</code>","text":"<p>Calculate Altman Z-Score for predicting bankruptcy risk.</p> <p>Z-Score = 1.2X1 + 1.4X2 + 3.3X3 + 0.6X4 + 0.999*X5</p> <p>Parameters:</p> Name Type Description Default <code>working_capital</code> <code>float</code> <p>Working capital</p> required <code>retained_earnings</code> <code>float</code> <p>Retained earnings</p> required <code>ebit</code> <code>float</code> <p>Earnings before interest and taxes</p> required <code>market_value_equity</code> <code>float</code> <p>Market value of equity</p> required <code>sales</code> <code>float</code> <p>Sales</p> required <code>total_assets</code> <code>float</code> <p>Total assets</p> required <code>total_liabilities</code> <code>float</code> <p>Total liabilities</p> required <p>Returns:</p> Type Description <code>dict</code> <p>Z-score value and risk interpretation</p>"},{"location":"api/credit/create_scorecard/","title":"Create Scorecard API Reference","text":"<p>This page documents the API for the Create Scorecard function in Pypulate.</p> <p>Scorecard creation for credit scoring.</p>"},{"location":"api/credit/create_scorecard/#pypulate.credit.create_scorecard.create_scorecard","title":"<code>create_scorecard(features, weights, offsets=None, scaling_factor=100.0, base_score=600)</code>","text":"<p>Create a points-based scorecard for credit scoring.</p> <p>Parameters:</p> Name Type Description Default <code>features</code> <code>dict</code> <p>Dictionary of feature names and their values (e.g., {\"income\": 75000, \"age\": 35}).</p> required <code>weights</code> <code>dict</code> <p>Dictionary of feature names and their weights (e.g., {\"income\": 0.3, \"age\": 0.5}).</p> required <code>offsets</code> <code>dict</code> <p>Dictionary of feature names and offset values (default is 0 for each feature if None).</p> <code>None</code> <code>scaling_factor</code> <code>float</code> <p>Scaling factor to divide the points, controlling the score range (default is 100.0).</p> <code>100.0</code> <code>base_score</code> <code>float</code> <p>Base score to which feature points are added (default is 600).</p> <code>600</code> <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary containing the total score, points breakdown, and risk category.</p>"},{"location":"api/credit/debt_service_coverage_ratio/","title":"Debt Service Coverage Ratio API Reference","text":"<p>This page documents the API for the Debt Service Coverage Ratio function in Pypulate.</p> <p>Debt Service Coverage Ratio (DSCR) calculation.</p>"},{"location":"api/credit/debt_service_coverage_ratio/#pypulate.credit.debt_service_coverage_ratio.debt_service_coverage_ratio","title":"<code>debt_service_coverage_ratio(net_operating_income, total_debt_service)</code>","text":"<p>Calculate Debt Service Coverage Ratio (DSCR).</p> <p>DSCR = Net Operating Income / Total Debt Service</p> <p>Parameters:</p> Name Type Description Default <code>net_operating_income</code> <code>float</code> <p>Net operating income</p> required <code>total_debt_service</code> <code>float</code> <p>Total debt service</p> required <p>Returns:</p> Type Description <code>dict</code> <p>DSCR value and interpretation</p>"},{"location":"api/credit/expected_credit_loss/","title":"Expected Credit Loss API Reference","text":"<p>This page documents the API for the Expected Credit Loss function in Pypulate.</p> <p>Expected Credit Loss (ECL) calculation.</p>"},{"location":"api/credit/expected_credit_loss/#pypulate.credit.expected_credit_loss.expected_credit_loss","title":"<code>expected_credit_loss(pd, lgd, ead, time_horizon=1.0, discount_rate=0.0)</code>","text":"<p>Calculate expected credit loss.</p> <p>ECL = PD \u00d7 LGD \u00d7 EAD \u00d7 Discount Factor</p> <p>Parameters:</p> Name Type Description Default <code>pd</code> <code>float</code> <p>Probability of default</p> required <code>lgd</code> <code>float</code> <p>Loss given default (as a decimal)</p> required <code>ead</code> <code>float</code> <p>Exposure at default</p> required <code>time_horizon</code> <code>float</code> <p>Time horizon in years</p> <code>1.0</code> <code>discount_rate</code> <code>float</code> <p>Discount rate for future losses</p> <code>0.0</code> <p>Returns:</p> Type Description <code>dict</code> <p>ECL and components</p>"},{"location":"api/credit/exposure_at_default/","title":"Exposure at Default API Reference","text":"<p>This page documents the API for the Exposure at Default function in Pypulate.</p> <p>Exposure at Default (EAD) calculation.</p>"},{"location":"api/credit/exposure_at_default/#pypulate.credit.exposure_at_default.exposure_at_default","title":"<code>exposure_at_default(current_balance, undrawn_amount, credit_conversion_factor=0.5)</code>","text":"<p>Calculate exposure at default for credit facilities.</p> <p>Parameters:</p> Name Type Description Default <code>current_balance</code> <code>float</code> <p>Current drawn balance</p> required <code>undrawn_amount</code> <code>float</code> <p>Undrawn commitment</p> required <code>credit_conversion_factor</code> <code>float</code> <p>Factor to convert undrawn amounts to exposure</p> <code>0.5</code> <p>Returns:</p> Type Description <code>dict</code> <p>EAD and components</p>"},{"location":"api/credit/financial_ratios/","title":"Financial Ratios API Reference","text":"<p>This page documents the API for the Financial Ratios function in Pypulate.</p> <p>Financial ratios calculation for credit assessment.</p>"},{"location":"api/credit/financial_ratios/#pypulate.credit.financial_ratios.financial_ratios","title":"<code>financial_ratios(current_assets, current_liabilities, total_assets, total_liabilities, ebit, interest_expense, net_income, total_equity, sales)</code>","text":"<p>Calculate key financial ratios for credit assessment.</p> <p>Parameters:</p> Name Type Description Default <code>current_assets</code> <code>float</code> <p>Current assets</p> required <code>current_liabilities</code> <code>float</code> <p>Current liabilities</p> required <code>total_assets</code> <code>float</code> <p>Total assets</p> required <code>total_liabilities</code> <code>float</code> <p>Total liabilities</p> required <code>ebit</code> <code>float</code> <p>Earnings before interest and taxes</p> required <code>interest_expense</code> <code>float</code> <p>Interest expense</p> required <code>net_income</code> <code>float</code> <p>Net income</p> required <code>total_equity</code> <code>float</code> <p>Total equity</p> required <code>sales</code> <code>float</code> <p>Sales</p> required <p>Returns:</p> Type Description <code>dict</code> <p>Financial ratios and assessments</p>"},{"location":"api/credit/loan_pricing/","title":"Loan Pricing API Reference","text":"<p>This page documents the API for the Risk-Based Loan Pricing function in Pypulate.</p> <p>Risk-based loan pricing model.</p>"},{"location":"api/credit/loan_pricing/#pypulate.credit.loan_pricing.loan_pricing","title":"<code>loan_pricing(loan_amount, term, pd, lgd, funding_cost, operating_cost, capital_requirement, target_roe)</code>","text":"<p>Calculate risk-based loan pricing.</p> <p>Parameters:</p> Name Type Description Default <code>loan_amount</code> <code>float</code> <p>Loan amount</p> required <code>term</code> <code>float</code> <p>Loan term in years</p> required <code>pd</code> <code>float</code> <p>Probability of default (annual)</p> required <code>lgd</code> <code>float</code> <p>Loss given default (as a decimal)</p> required <code>funding_cost</code> <code>float</code> <p>Cost of funds (annual rate)</p> required <code>operating_cost</code> <code>float</code> <p>Operating costs (as percentage of loan amount)</p> required <code>capital_requirement</code> <code>float</code> <p>Capital requirement as percentage of loan amount</p> required <code>target_roe</code> <code>float</code> <p>Target return on equity (annual rate)</p> required <p>Returns:</p> Type Description <code>dict</code> <p>Recommended interest rate and components</p>"},{"location":"api/credit/logistic_regression_score/","title":"Logistic Regression Score API Reference","text":"<p>This page documents the API for the Logistic Regression Score function in Pypulate.</p> <p>Logistic regression scoring for credit risk assessment.</p>"},{"location":"api/credit/logistic_regression_score/#pypulate.credit.logistic_regression_score.logistic_regression_score","title":"<code>logistic_regression_score(coefficients, features, intercept=0)</code>","text":"<p>Calculate credit score using logistic regression coefficients.</p> <p>Parameters:</p> Name Type Description Default <code>coefficients</code> <code>array_like</code> <p>Coefficients for each feature</p> required <code>features</code> <code>array_like</code> <p>Feature values</p> required <code>intercept</code> <code>float</code> <p>Intercept term</p> <code>0</code> <p>Returns:</p> Type Description <code>dict</code> <p>Probability of default and score</p>"},{"location":"api/credit/loss_given_default/","title":"Loss Given Default API Reference","text":"<p>This page documents the API for the Loss Given Default function in Pypulate.</p> <p>Loss Given Default (LGD) estimation.</p>"},{"location":"api/credit/loss_given_default/#pypulate.credit.loss_given_default.loss_given_default","title":"<code>loss_given_default(collateral_value, loan_amount, recovery_rate=None, liquidation_costs=0.1, time_to_recovery=1.0)</code>","text":"<p>Estimate the loss given default for a loan.</p> <p>Parameters:</p> Name Type Description Default <code>collateral_value</code> <code>float</code> <p>Value of collateral</p> required <code>loan_amount</code> <code>float</code> <p>Outstanding loan amount</p> required <code>recovery_rate</code> <code>float</code> <p>Historical recovery rate for similar loans</p> <code>None</code> <code>liquidation_costs</code> <code>float</code> <p>Costs associated with liquidating collateral</p> <code>0.1</code> <code>time_to_recovery</code> <code>float</code> <p>Expected time to recovery in years</p> <code>1.0</code> <p>Returns:</p> Type Description <code>dict</code> <p>LGD estimate and components</p>"},{"location":"api/credit/merton_model/","title":"Merton Model API Reference","text":"<p>This page documents the API for the Merton Model function in Pypulate.</p> <p>Merton model for default probability calculation.</p>"},{"location":"api/credit/merton_model/#pypulate.credit.merton_model.merton_model","title":"<code>merton_model(asset_value, debt_face_value, asset_volatility, risk_free_rate, time_to_maturity)</code>","text":"<p>Calculate default probability using the Merton model.</p> <p>Parameters:</p> Name Type Description Default <code>asset_value</code> <code>float</code> <p>Market value of assets</p> required <code>debt_face_value</code> <code>float</code> <p>Face value of debt</p> required <code>asset_volatility</code> <code>float</code> <p>Volatility of assets (annualized)</p> required <code>risk_free_rate</code> <code>float</code> <p>Risk-free interest rate</p> required <code>time_to_maturity</code> <code>float</code> <p>Time to maturity in years</p> required <p>Returns:</p> Type Description <code>dict</code> <p>Default probability and distance to default</p>"},{"location":"api/credit/scoring_model_validation/","title":"Scoring Model Validation API Reference","text":"<p>This page documents the API for the Scoring Model Validation function in Pypulate.</p> <p>Credit scoring model validation.</p>"},{"location":"api/credit/scoring_model_validation/#pypulate.credit.scoring_model_validation.scoring_model_validation","title":"<code>scoring_model_validation(predicted_scores, actual_defaults, score_bins=10)</code>","text":"<p>Validate credit scoring model performance.</p> <p>Parameters:</p> Name Type Description Default <code>predicted_scores</code> <code>array_like</code> <p>Predicted credit scores</p> required <code>actual_defaults</code> <code>array_like</code> <p>Actual default outcomes (0/1)</p> required <code>score_bins</code> <code>int</code> <p>Number of score bins for analysis</p> <code>10</code> <p>Returns:</p> Type Description <code>dict</code> <p>Validation metrics (Gini, KS, AUC, etc.)</p>"},{"location":"api/credit/transition_matrix/","title":"Transition Matrix API Reference","text":"<p>This page documents the API for the Credit Rating Transition Matrix function in Pypulate.</p> <p>Credit rating transition matrix calculation.</p>"},{"location":"api/credit/transition_matrix/#pypulate.credit.transition_matrix.transition_matrix","title":"<code>transition_matrix(ratings_t0, ratings_t1)</code>","text":"<p>Calculate credit rating transition matrix.</p> <p>Parameters:</p> Name Type Description Default <code>ratings_t0</code> <code>array_like</code> <p>Ratings at time 0</p> required <code>ratings_t1</code> <code>array_like</code> <p>Ratings at time 1</p> required <p>Returns:</p> Type Description <code>dict</code> <p>Transition matrix and probabilities</p>"},{"location":"api/credit/weight_of_evidence/","title":"Weight of Evidence API Reference","text":"<p>This page documents the API for the Weight of Evidence function in Pypulate.</p> <p>Weight of Evidence (WOE) and Information Value (IV) calculation.</p>"},{"location":"api/credit/weight_of_evidence/#pypulate.credit.weight_of_evidence.weight_of_evidence","title":"<code>weight_of_evidence(good_count, bad_count, min_samples=0.01, adjustment=0.5)</code>","text":"<p>Calculate Weight of Evidence (WOE) and Information Value (IV).</p> <p>WOE = ln(Distribution of Good / Distribution of Bad)</p> <p>Parameters:</p> Name Type Description Default <code>good_count</code> <code>array_like</code> <p>Count of good cases in each bin</p> required <code>bad_count</code> <code>array_like</code> <p>Count of bad cases in each bin</p> required <code>min_samples</code> <code>float</code> <p>Minimum percentage of samples required in a bin</p> <code>0.01</code> <code>adjustment</code> <code>float</code> <p>Adjustment factor for zero counts</p> <code>0.5</code> <p>Returns:</p> Type Description <code>dict</code> <p>WOE values, IV, and distributions</p>"},{"location":"api/portfolio/return_measurement/","title":"Return Measurement API","text":"<p>Return measurement functions for portfolio analysis.</p> <p>This module provides functions for measuring returns in various portfolio scenarios, including portfolios with no cash flows, portfolios with inflows and outflows, and market-neutral and leveraged portfolios.</p> <p>All functions support both Python lists and NumPy arrays as inputs.</p>"},{"location":"api/portfolio/return_measurement/#pypulate.portfolio.return_measurement.annualized_return","title":"<code>annualized_return(total_return, years)</code>","text":"<p>Calculate the annualized return from a total return over a period of years.</p> <p>Parameters:</p> Name Type Description Default <code>total_return</code> <code>float or array - like</code> <p>The total return over the entire period as a decimal</p> required <code>years</code> <code>float or array - like</code> <p>The number of years in the period</p> required <p>Returns:</p> Type Description <code>float or ndarray</code> <p>The annualized return as a decimal If array inputs are provided, returns an array of annualized returns</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; annualized_return(0.2, 2)\n0.09544511501033215\n&gt;&gt;&gt; annualized_return([0.2, 0.3, 0.15], [2, 3, 1.5])\n[0.09544512, 0.09139288, 0.0976534 ]\n&gt;&gt;&gt; annualized_return(np.array([0.4, 0.5]), 2)\n[0.18321596, 0.22474487]\n</code></pre>"},{"location":"api/portfolio/return_measurement/#pypulate.portfolio.return_measurement.arithmetic_return","title":"<code>arithmetic_return(prices)</code>","text":"<p>Calculate the arithmetic average return from a series of prices.</p> <p>Parameters:</p> Name Type Description Default <code>prices</code> <code>array - like</code> <p>Array or list of prices</p> required <p>Returns:</p> Type Description <code>float</code> <p>The arithmetic average return as a decimal</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; arithmetic_return([100, 105, 103, 108, 110])\n0.024503647197821957\n</code></pre>"},{"location":"api/portfolio/return_measurement/#pypulate.portfolio.return_measurement.beta_adjusted_return","title":"<code>beta_adjusted_return(portfolio_return, benchmark_return, portfolio_beta)</code>","text":"<p>Calculate the beta-adjusted return (alpha) of a portfolio.</p> <p>Parameters:</p> Name Type Description Default <code>portfolio_return</code> <code>float or array - like</code> <p>The return of the portfolio as a decimal</p> required <code>benchmark_return</code> <code>float or array - like</code> <p>The return of the benchmark as a decimal</p> required <code>portfolio_beta</code> <code>float or array - like</code> <p>The beta of the portfolio relative to the benchmark</p> required <p>Returns:</p> Type Description <code>float or ndarray</code> <p>The beta-adjusted return (alpha) as a decimal If array inputs are provided, returns an array of beta-adjusted returns</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; beta_adjusted_return(0.12, 0.10, 1.2)\n0.0\n&gt;&gt;&gt; beta_adjusted_return([0.12, 0.15], [0.10, 0.08], 1.2)\n[0.   , 0.054]\n&gt;&gt;&gt; beta_adjusted_return(0.12, 0.10, [1.2, 1.5])\n[ 0.  , -0.03]\n</code></pre>"},{"location":"api/portfolio/return_measurement/#pypulate.portfolio.return_measurement.dollar_weighted_return","title":"<code>dollar_weighted_return(cash_flows, cash_flow_dates, end_value)</code>","text":"<p>Calculate the dollar-weighted return (internal rate of return) for a series of cash flows.</p> <p>Parameters:</p> Name Type Description Default <code>cash_flows</code> <code>array - like</code> <p>Array or list of cash flows (positive for inflows, negative for outflows)</p> required <code>cash_flow_dates</code> <code>array - like</code> <p>Array or list of dates (in days) when each cash flow occurs</p> required <code>end_value</code> <code>float</code> <p>The final value of the investment</p> required <p>Returns:</p> Type Description <code>float</code> <p>The dollar-weighted return as a decimal</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; dollar_weighted_return([-1000, -500, 200], [0, 30, 60], 1400)\n0.36174448410245186\n</code></pre>"},{"location":"api/portfolio/return_measurement/#pypulate.portfolio.return_measurement.geometric_return","title":"<code>geometric_return(prices)</code>","text":"<p>Calculate the geometric average return from a series of prices.</p> <p>Parameters:</p> Name Type Description Default <code>prices</code> <code>array - like</code> <p>Array or list of prices</p> required <p>Returns:</p> Type Description <code>float</code> <p>The geometric average return as a decimal</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; geometric_return([100, 105, 103, 108, 110])\n0.02411368908444511\n</code></pre>"},{"location":"api/portfolio/return_measurement/#pypulate.portfolio.return_measurement.holding_period_return","title":"<code>holding_period_return(prices, dividends=None)</code>","text":"<p>Calculate the holding period return for a series of prices and optional dividends.</p> <p>Parameters:</p> Name Type Description Default <code>prices</code> <code>array - like</code> <p>Array or list of prices over the holding period</p> required <code>dividends</code> <code>array - like</code> <p>Array or list of dividends paid during the holding period</p> <code>None</code> <p>Returns:</p> Type Description <code>float</code> <p>The holding period return as a decimal</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; holding_period_return([100, 102, 105, 103, 106])\n0.06\n&gt;&gt;&gt; holding_period_return([100, 102, 105, 103, 106], [0, 1, 0, 2, 0])\n0.09\n</code></pre>"},{"location":"api/portfolio/return_measurement/#pypulate.portfolio.return_measurement.leveraged_return","title":"<code>leveraged_return(unleveraged_return, leverage_ratio, borrowing_rate)</code>","text":"<p>Calculate the return of a leveraged portfolio.</p> <p>Parameters:</p> Name Type Description Default <code>unleveraged_return</code> <code>float or array - like</code> <p>The return of the unleveraged portfolio as a decimal</p> required <code>leverage_ratio</code> <code>float or array - like</code> <p>The leverage ratio (e.g., 2.0 for 2:1 leverage)</p> required <code>borrowing_rate</code> <code>float or array - like</code> <p>The borrowing rate as a decimal</p> required <p>Returns:</p> Type Description <code>float or ndarray</code> <p>The leveraged return as a decimal If array inputs are provided, returns an array of leveraged returns</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; leveraged_return(0.10, 2.0, 0.05)\n0.15\n&gt;&gt;&gt; leveraged_return([0.10, 0.15], [2.0, 1.5], 0.05)\n[0.15, 0.2 ]\n&gt;&gt;&gt; leveraged_return(0.10, [2.0, 3.0], [0.05, 0.06])\n[0.15, 0.18]\n</code></pre>"},{"location":"api/portfolio/return_measurement/#pypulate.portfolio.return_measurement.linked_modified_dietz_return","title":"<code>linked_modified_dietz_return(period_returns)</code>","text":"<p>Calculate the linked Modified Dietz return over multiple periods.</p> <p>Parameters:</p> Name Type Description Default <code>period_returns</code> <code>array - like</code> <p>Array or list of Modified Dietz returns for each period</p> required <p>Returns:</p> Type Description <code>float</code> <p>The linked Modified Dietz return as a decimal</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; linked_modified_dietz_return([0.05, -0.02, 0.03, 0.04])\n0.10226479999999993\n</code></pre>"},{"location":"api/portfolio/return_measurement/#pypulate.portfolio.return_measurement.log_return","title":"<code>log_return(end_value, start_value)</code>","text":"<p>Calculate the logarithmic (continuously compounded) return between two values.</p> <p>Parameters:</p> Name Type Description Default <code>end_value</code> <code>float or array - like</code> <p>The ending value(s) of the investment</p> required <code>start_value</code> <code>float or array - like</code> <p>The starting value(s) of the investment</p> required <p>Returns:</p> Type Description <code>float or ndarray</code> <p>The logarithmic return If array inputs are provided, returns an array of logarithmic returns</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; log_return(105, 100)\n0.04879016416929972\n&gt;&gt;&gt; log_return([105, 110, 108], [100, 100, 100])\narray([0.04879016, 0.09531018, 0.07696104])\n&gt;&gt;&gt; log_return(np.array([105, 110]), np.array([100, 100]))\narray([0.04879016, 0.09531018])\n</code></pre>"},{"location":"api/portfolio/return_measurement/#pypulate.portfolio.return_measurement.long_short_equity_return","title":"<code>long_short_equity_return(long_portfolio_return, short_portfolio_return, long_exposure, short_exposure, risk_free_rate=0.0, short_rebate=0.0)</code>","text":"<p>Calculate the return of a long-short equity portfolio.</p> <p>Parameters:</p> Name Type Description Default <code>long_portfolio_return</code> <code>float or array - like</code> <p>The return of the long portfolio as a decimal</p> required <code>short_portfolio_return</code> <code>float or array - like</code> <p>The return of the short portfolio as a decimal</p> required <code>long_exposure</code> <code>float or array - like</code> <p>The exposure of the long portfolio as a decimal of NAV</p> required <code>short_exposure</code> <code>float or array - like</code> <p>The exposure of the short portfolio as a decimal of NAV</p> required <code>risk_free_rate</code> <code>float or array - like</code> <p>The risk-free rate as a decimal</p> <code>0.0</code> <code>short_rebate</code> <code>float or array - like</code> <p>The rebate received on short proceeds as a decimal</p> <code>0.0</code> <p>Returns:</p> Type Description <code>float or ndarray</code> <p>The return of the long-short equity portfolio as a decimal If array inputs are provided, returns an array of long-short equity returns</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; long_short_equity_return(0.10, -0.05, 1.0, 0.5, 0.02, 0.01)\n0.14\n&gt;&gt;&gt; long_short_equity_return([0.10, 0.12], [-0.05, -0.03], 1.0, 0.5, 0.02, 0.01)\n[0.14, 0.15]\n&gt;&gt;&gt; long_short_equity_return(0.10, -0.05, [1.0, 0.8], [0.5, 0.4], [0.02, 0.03], 0.01)\n[0.14 , 0.122]\n</code></pre>"},{"location":"api/portfolio/return_measurement/#pypulate.portfolio.return_measurement.market_neutral_return","title":"<code>market_neutral_return(long_return, short_return, long_weight=0.5, short_weight=0.5, short_borrowing_cost=0.0)</code>","text":"<p>Calculate the return of a market-neutral portfolio with long and short positions.</p> <p>Parameters:</p> Name Type Description Default <code>long_return</code> <code>float or array - like</code> <p>The return of the long portfolio as a decimal</p> required <code>short_return</code> <code>float or array - like</code> <p>The return of the short portfolio as a decimal</p> required <code>long_weight</code> <code>float or array - like</code> <p>The weight of the long portfolio</p> <code>0.5</code> <code>short_weight</code> <code>float or array - like</code> <p>The weight of the short portfolio</p> <code>0.5</code> <code>short_borrowing_cost</code> <code>float or array - like</code> <p>The cost of borrowing for the short position as a decimal</p> <code>0.0</code> <p>Returns:</p> Type Description <code>float or ndarray</code> <p>The market-neutral return as a decimal If array inputs are provided, returns an array of market-neutral returns</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; market_neutral_return(0.08, -0.05, 0.6, 0.4, 0.01)\n0.064\n&gt;&gt;&gt; market_neutral_return([0.08, 0.10], [-0.05, -0.03], 0.6, 0.4, 0.01)\n[0.064, 0.068]\n&gt;&gt;&gt; market_neutral_return(0.08, -0.05, [0.6, 0.7], [0.4, 0.3], [0.01, 0.02])\n[0.064, 0.065]\n</code></pre>"},{"location":"api/portfolio/return_measurement/#pypulate.portfolio.return_measurement.modified_dietz_return","title":"<code>modified_dietz_return(start_value, end_value, cash_flows, cash_flow_days, total_days)</code>","text":"<p>Calculate the Modified Dietz return, which approximates the money-weighted return.</p> <p>Parameters:</p> Name Type Description Default <code>start_value</code> <code>float</code> <p>The starting value of the investment</p> required <code>end_value</code> <code>float</code> <p>The ending value of the investment</p> required <code>cash_flows</code> <code>array - like</code> <p>Array or list of cash flows (positive for inflows, negative for outflows)</p> required <code>cash_flow_days</code> <code>array - like</code> <p>Array or list of days when each cash flow occurs (day 0 is the start)</p> required <code>total_days</code> <code>int</code> <p>Total number of days in the period</p> required <p>Returns:</p> Type Description <code>float</code> <p>The Modified Dietz return as a decimal</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; modified_dietz_return(1000, 1200, [100, -50], [10, 20], 30)\n0.14285714285714285\n</code></pre>"},{"location":"api/portfolio/return_measurement/#pypulate.portfolio.return_measurement.money_weighted_return","title":"<code>money_weighted_return(cash_flows, cash_flow_times, final_value, initial_value=0, max_iterations=100, tolerance=1e-06)</code>","text":"<p>Calculate the money-weighted return (internal rate of return) for a series of cash flows.</p> <p>Parameters:</p> Name Type Description Default <code>cash_flows</code> <code>array - like</code> <p>Array or list of cash flows (positive for inflows, negative for outflows)</p> required <code>cash_flow_times</code> <code>array - like</code> <p>Array or list of times (in years) when each cash flow occurs</p> required <code>final_value</code> <code>float</code> <p>The final value of the investment</p> required <code>initial_value</code> <code>float</code> <p>The initial value of the investment</p> <code>0</code> <code>max_iterations</code> <code>int</code> <p>Maximum number of iterations for the numerical solver</p> <code>100</code> <code>tolerance</code> <code>float</code> <p>Convergence tolerance for the numerical solver</p> <code>1e-6</code> <p>Returns:</p> Type Description <code>float</code> <p>The money-weighted return (IRR) as a decimal</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; money_weighted_return([-1000, -500, 1700], [0, 0.5, 1], 0)\n0.16120409753798307\n</code></pre>"},{"location":"api/portfolio/return_measurement/#pypulate.portfolio.return_measurement.simple_return","title":"<code>simple_return(end_value, start_value)</code>","text":"<p>Calculate the simple return (percentage change) between two values.</p> <p>Parameters:</p> Name Type Description Default <code>end_value</code> <code>float or array - like</code> <p>The ending value(s) of the investment</p> required <code>start_value</code> <code>float or array - like</code> <p>The starting value(s) of the investment</p> required <p>Returns:</p> Type Description <code>float or ndarray</code> <p>The simple return as a decimal (e.g., 0.05 for 5%) If array inputs are provided, returns an array of simple returns</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; simple_return(105, 100)\n0.05\n&gt;&gt;&gt; simple_return([105, 110, 108], [100, 100, 100])\narray([0.05, 0.1 , 0.08])\n&gt;&gt;&gt; simple_return(np.array([105, 110]), np.array([100, 100]))\narray([0.05, 0.1 ])\n</code></pre>"},{"location":"api/portfolio/return_measurement/#pypulate.portfolio.return_measurement.time_weighted_return","title":"<code>time_weighted_return(period_returns)</code>","text":"<p>Calculate the time-weighted return from a series of period returns.</p> <p>Parameters:</p> Name Type Description Default <code>period_returns</code> <code>array - like</code> <p>Array or list of returns for each period</p> required <p>Returns:</p> Type Description <code>float</code> <p>The time-weighted return as a decimal</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; time_weighted_return([0.05, -0.02, 0.03, 0.04])\n0.10226479999999993\n</code></pre>"},{"location":"api/portfolio/return_measurement/#pypulate.portfolio.return_measurement.total_return_index","title":"<code>total_return_index(prices, dividends=None)</code>","text":"<p>Calculate the total return index from a series of prices and optional dividends.</p> <p>Parameters:</p> Name Type Description Default <code>prices</code> <code>array - like</code> <p>Array or list of prices</p> required <code>dividends</code> <code>array - like</code> <p>Array or list of dividends paid</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The total return index</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; total_return_index([100, 102, 105, 103, 106])\n[100., 102., 105., 103., 106.]\n&gt;&gt;&gt; total_return_index([100, 102, 105, 103, 106], [0, 1, 0, 2, 0])\n[100.        , 103.        , 106.02941176, 106.02941176,\n   109.11764706]\n</code></pre>"},{"location":"api/portfolio/risk_adjusted/","title":"Risk-Adjusted Performance API","text":"<p>Risk-adjusted performance measurement functions for portfolio analysis.</p> <p>This module provides functions for measuring risk-adjusted performance metrics including Sharpe ratio, Information ratio, CAPM alpha, and multifactor models.</p> <p>All functions support both Python lists and NumPy arrays as inputs.</p>"},{"location":"api/portfolio/risk_adjusted/#pypulate.portfolio.risk_adjusted.benchmark_alpha","title":"<code>benchmark_alpha(returns, benchmark_returns)</code>","text":"<p>Calculate the benchmark alpha, which is the difference between portfolio return and benchmark return.</p> <p>Parameters:</p> Name Type Description Default <code>returns</code> <code>array - like</code> <p>Array of portfolio returns</p> required <code>benchmark_returns</code> <code>array - like</code> <p>Array of benchmark returns for the same periods</p> required <p>Returns:</p> Type Description <code>float</code> <p>The benchmark alpha (difference in mean returns)</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; benchmark_alpha([0.01, 0.02, -0.01, 0.03, 0.01], [0.005, 0.01, -0.005, 0.02, 0.005])\n0.005\n</code></pre>"},{"location":"api/portfolio/risk_adjusted/#pypulate.portfolio.risk_adjusted.calmar_ratio","title":"<code>calmar_ratio(returns, max_drawdown=None, annualization_factor=1.0)</code>","text":"<p>Calculate the Calmar ratio, which measures return relative to maximum drawdown.</p> <p>Parameters:</p> Name Type Description Default <code>returns</code> <code>array - like</code> <p>Array of portfolio returns</p> required <code>max_drawdown</code> <code>float</code> <p>Maximum drawdown as a positive decimal. If None, it will be calculated from returns.</p> <code>None</code> <code>annualization_factor</code> <code>float</code> <p>Factor to annualize returns</p> <code>1.0</code> <p>Returns:</p> Type Description <code>float</code> <p>The Calmar ratio</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; calmar_ratio([0.01, 0.02, -0.01, 0.03, 0.01], 0.15, 252)\n0.8\n</code></pre>"},{"location":"api/portfolio/risk_adjusted/#pypulate.portfolio.risk_adjusted.capm_alpha","title":"<code>capm_alpha(returns, benchmark_returns, risk_free_rate=0.0)</code>","text":"<p>Calculate the CAPM alpha (Jensen's alpha) and related statistics.</p> <p>Parameters:</p> Name Type Description Default <code>returns</code> <code>array - like</code> <p>Array of portfolio returns</p> required <code>benchmark_returns</code> <code>array - like</code> <p>Array of benchmark returns for the same periods</p> required <code>risk_free_rate</code> <code>float or array - like</code> <p>Risk-free rate for the same period as returns</p> <code>0.0</code> <p>Returns:</p> Type Description <code>tuple</code> <p>(alpha, beta, r_squared, p_value, std_err) - alpha: The CAPM alpha (intercept) - beta: The CAPM beta (slope) - r_squared: The R-squared of the regression - p_value: The p-value for alpha - std_err: The standard error of alpha</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; capm_alpha([0.01, 0.02, -0.01, 0.03, 0.01], [0.005, 0.01, -0.005, 0.02, 0.005], 0.001)\n(0.0046, 1.2, 0.9, 0.0023, 0.0012)\n</code></pre>"},{"location":"api/portfolio/risk_adjusted/#pypulate.portfolio.risk_adjusted.information_ratio","title":"<code>information_ratio(returns, benchmark_returns, annualization_factor=1.0)</code>","text":"<p>Calculate the Information ratio, which measures active return per unit of active risk.</p> <p>Parameters:</p> Name Type Description Default <code>returns</code> <code>array - like</code> <p>Array of portfolio returns</p> required <code>benchmark_returns</code> <code>array - like</code> <p>Array of benchmark returns for the same periods</p> required <code>annualization_factor</code> <code>float</code> <p>Factor to annualize the Information ratio (e.g., 252 for daily returns to annual)</p> <code>1.0</code> <p>Returns:</p> Type Description <code>float</code> <p>The Information ratio</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; information_ratio([0.01, 0.02, -0.01, 0.03, 0.01], [0.005, 0.01, -0.005, 0.02, 0.005], 252)\n2.8284271247461903\n</code></pre>"},{"location":"api/portfolio/risk_adjusted/#pypulate.portfolio.risk_adjusted.multifactor_alpha","title":"<code>multifactor_alpha(returns, factor_returns, risk_free_rate=0.0)</code>","text":"<p>Calculate the alpha from a multifactor model (e.g., Fama-French).</p> <p>Parameters:</p> Name Type Description Default <code>returns</code> <code>array - like</code> <p>Array of portfolio returns</p> required <code>factor_returns</code> <code>array - like</code> <p>2D array where each column represents returns for a factor</p> required <code>risk_free_rate</code> <code>float or array - like</code> <p>Risk-free rate for the same period as returns</p> <code>0.0</code> <p>Returns:</p> Type Description <code>tuple</code> <p>(alpha, betas, r_squared, p_value, std_err) - alpha: The multifactor alpha (intercept) - betas: Array of factor betas (coefficients) - r_squared: The R-squared of the regression - p_value: The p-value for alpha - std_err: The standard error of alpha</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Example with market, size, and value factors\n&gt;&gt;&gt; portfolio_returns = [0.01, 0.02, -0.01, 0.03, 0.01]\n&gt;&gt;&gt; factor_returns = [\n...     [0.005, 0.01, -0.005, 0.02, 0.005],  # Market\n...     [0.002, 0.003, -0.001, 0.004, 0.001],  # Size\n...     [0.001, 0.002, -0.002, 0.003, 0.002]   # Value\n... ]\n&gt;&gt;&gt; multifactor_alpha(portfolio_returns, factor_returns, 0.001)\n(0.0032, array([0.9, 0.5, 0.3]), 0.92, 0.04, 0.0015)  # Example values\n</code></pre>"},{"location":"api/portfolio/risk_adjusted/#pypulate.portfolio.risk_adjusted.omega_ratio","title":"<code>omega_ratio(returns, threshold=0.0, annualization_factor=1.0)</code>","text":"<p>Calculate the Omega ratio, which measures the probability-weighted ratio of gains versus losses.</p> <p>Parameters:</p> Name Type Description Default <code>returns</code> <code>array - like</code> <p>Array of portfolio returns</p> required <code>threshold</code> <code>float</code> <p>The threshold return</p> <code>0.0</code> <code>annualization_factor</code> <code>float</code> <p>Factor to annualize the threshold</p> <code>1.0</code> <p>Returns:</p> Type Description <code>float</code> <p>The Omega ratio</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; omega_ratio([0.01, 0.02, -0.01, 0.03, 0.01], 0.005)\n2.0\n</code></pre>"},{"location":"api/portfolio/risk_adjusted/#pypulate.portfolio.risk_adjusted.sharpe_ratio","title":"<code>sharpe_ratio(returns, risk_free_rate=0.0, annualization_factor=1.0)</code>","text":"<p>Calculate the Sharpe ratio, which measures excess return per unit of risk.</p> <p>Parameters:</p> Name Type Description Default <code>returns</code> <code>array - like</code> <p>Array of periodic returns</p> required <code>risk_free_rate</code> <code>float or array - like</code> <p>Risk-free rate for the same period as returns</p> <code>0.0</code> <code>annualization_factor</code> <code>float</code> <p>Factor to annualize the Sharpe ratio (e.g., 252 for daily returns to annual)</p> <code>1.0</code> <p>Returns:</p> Type Description <code>float or ndarray</code> <p>The Sharpe ratio If array input is provided for risk_free_rate, returns an array of Sharpe ratios</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; sharpe_ratio([0.01, 0.02, -0.01, 0.03, 0.01], 0.001, 252)\n2.5298221281347035\n&gt;&gt;&gt; sharpe_ratio([0.01, 0.02, -0.01, 0.03, 0.01], [0.001, 0.002], 252)\narray([2.52982213, 2.26684001])\n</code></pre>"},{"location":"api/portfolio/risk_adjusted/#pypulate.portfolio.risk_adjusted.sortino_ratio","title":"<code>sortino_ratio(returns, risk_free_rate=0.0, target_return=0.0, annualization_factor=1.0)</code>","text":"<p>Calculate the Sortino ratio, which measures excess return per unit of downside risk.</p> <p>Parameters:</p> Name Type Description Default <code>returns</code> <code>array - like</code> <p>Array of portfolio returns</p> required <code>risk_free_rate</code> <code>float or array - like</code> <p>Risk-free rate for the same period as returns</p> <code>0.0</code> <code>target_return</code> <code>float</code> <p>Minimum acceptable return</p> <code>0.0</code> <code>annualization_factor</code> <code>float</code> <p>Factor to annualize the Sortino ratio</p> <code>1.0</code> <p>Returns:</p> Type Description <code>float</code> <p>The Sortino ratio</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; sortino_ratio([0.01, 0.02, -0.01, 0.03, 0.01], 0.001, 0.0, 252)\n3.7947331922020545\n</code></pre>"},{"location":"api/portfolio/risk_adjusted/#pypulate.portfolio.risk_adjusted.treynor_ratio","title":"<code>treynor_ratio(returns, benchmark_returns, risk_free_rate=0.0, annualization_factor=1.0)</code>","text":"<p>Calculate the Treynor ratio, which measures excess return per unit of systematic risk.</p> <p>Parameters:</p> Name Type Description Default <code>returns</code> <code>array - like</code> <p>Array of portfolio returns</p> required <code>benchmark_returns</code> <code>array - like</code> <p>Array of benchmark returns for the same periods</p> required <code>risk_free_rate</code> <code>float or array - like</code> <p>Risk-free rate for the same period as returns</p> <code>0.0</code> <code>annualization_factor</code> <code>float</code> <p>Factor to annualize the Treynor ratio</p> <code>1.0</code> <p>Returns:</p> Type Description <code>float</code> <p>The Treynor ratio</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; treynor_ratio([0.01, 0.02, -0.01, 0.03, 0.01], [0.005, 0.01, -0.005, 0.02, 0.005], 0.001, 252)\n0.0378\n</code></pre>"},{"location":"api/portfolio/risk_measurement/","title":"Risk Measurement API","text":"<p>Risk measurement functions for portfolio analysis.</p> <p>This module provides various risk metrics used in portfolio management and financial analysis.</p>"},{"location":"api/portfolio/risk_measurement/#pypulate.portfolio.risk_measurement.capm_beta","title":"<code>capm_beta(portfolio_returns, market_returns)</code>","text":"<p>Calculate the CAPM beta of a portfolio.</p> <p>Parameters:</p> Name Type Description Default <code>portfolio_returns</code> <code>list or ndarray</code> <p>Array or list of portfolio returns</p> required <code>market_returns</code> <code>list or ndarray</code> <p>Array or list of market returns</p> required <p>Returns:</p> Type Description <code>float</code> <p>CAPM beta</p> Notes <p>Beta measures the sensitivity of portfolio returns to market returns. It is the covariance of portfolio returns and market returns divided by the variance of market returns.</p>"},{"location":"api/portfolio/risk_measurement/#pypulate.portfolio.risk_measurement.conditional_value_at_risk","title":"<code>conditional_value_at_risk(returns, confidence_level=0.95, method='historical', current_value=1.0)</code>","text":"<p>Calculate the Conditional Value-at-Risk (CVaR) of a portfolio.</p> <p>Parameters:</p> Name Type Description Default <code>returns</code> <code>list or ndarray</code> <p>Array or list of returns</p> required <code>confidence_level</code> <code>float</code> <p>Confidence level for CVaR calculation (e.g., 0.95 for 95% confidence)</p> <code>0.95</code> <code>method</code> <code>str</code> <p>Method for calculating CVaR ('historical' or 'parametric')</p> <code>'historical'</code> <code>current_value</code> <code>float</code> <p>Current value of the portfolio</p> <code>1.0</code> <p>Returns:</p> Type Description <code>float</code> <p>Conditional Value-at-Risk (CVaR) as a positive number representing the potential loss</p> Notes <p>CVaR, also known as Expected Shortfall, measures the expected loss given that the loss exceeds the VaR threshold. It provides a more conservative risk measure than VaR.</p>"},{"location":"api/portfolio/risk_measurement/#pypulate.portfolio.risk_measurement.correlation_matrix","title":"<code>correlation_matrix(returns_matrix)</code>","text":"<p>Calculate the correlation matrix of returns.</p> <p>Parameters:</p> Name Type Description Default <code>returns_matrix</code> <code>list of lists or np.ndarray</code> <p>Matrix of returns where each column represents an asset</p> required <p>Returns:</p> Type Description <code>np.ndarray or list of lists</code> <p>Correlation matrix</p> Notes <p>The correlation matrix measures the strength of the relationship between returns of different assets, normalized to be between -1 and 1.</p>"},{"location":"api/portfolio/risk_measurement/#pypulate.portfolio.risk_measurement.covariance_matrix","title":"<code>covariance_matrix(returns_matrix)</code>","text":"<p>Calculate the covariance matrix of returns.</p> <p>Parameters:</p> Name Type Description Default <code>returns_matrix</code> <code>list of lists or np.ndarray</code> <p>Matrix of returns where each column represents an asset</p> required <p>Returns:</p> Type Description <code>np.ndarray or list of lists</code> <p>Covariance matrix</p> Notes <p>The covariance matrix measures how returns of different assets move together.</p>"},{"location":"api/portfolio/risk_measurement/#pypulate.portfolio.risk_measurement.drawdown","title":"<code>drawdown(returns, as_list=False)</code>","text":"<p>Calculate the drawdown, maximum drawdown, and drawdown duration of returns.</p> <p>Parameters:</p> Name Type Description Default <code>returns</code> <code>list or ndarray</code> <p>Array or list of returns</p> required <code>as_list</code> <code>bool</code> <p>If True, returns the drawdowns as a list instead of numpy array</p> <code>False</code> <p>Returns:</p> Type Description <code>Tuple containing:</code> <ul> <li>Array or list of drawdowns</li> <li>Maximum drawdown (as a positive number)</li> <li>Start index of maximum drawdown</li> <li>End index of maximum drawdown</li> </ul> Notes <p>Drawdown measures the decline from a historical peak in cumulative returns.</p>"},{"location":"api/portfolio/risk_measurement/#pypulate.portfolio.risk_measurement.semi_standard_deviation","title":"<code>semi_standard_deviation(returns, threshold=0.0, annualize=False, periods_per_year=252)</code>","text":"<p>Calculate the semi-standard deviation of returns below a threshold.</p> <p>Parameters:</p> Name Type Description Default <code>returns</code> <code>list or ndarray</code> <p>Array or list of returns</p> required <code>threshold</code> <code>float</code> <p>Threshold below which to calculate semi-standard deviation</p> <code>0.0</code> <code>annualize</code> <code>bool</code> <p>Whether to annualize the semi-standard deviation</p> <code>False</code> <code>periods_per_year</code> <code>int</code> <p>Number of periods in a year (252 for daily returns, 12 for monthly, 4 for quarterly)</p> <code>252</code> <p>Returns:</p> Type Description <code>float</code> <p>Semi-standard deviation of returns</p> Notes <p>Semi-standard deviation only considers returns below the threshold (typically 0), making it a measure of downside risk.</p>"},{"location":"api/portfolio/risk_measurement/#pypulate.portfolio.risk_measurement.standard_deviation","title":"<code>standard_deviation(returns, annualize=False, periods_per_year=252)</code>","text":"<p>Calculate the standard deviation of returns.</p> <p>Parameters:</p> Name Type Description Default <code>returns</code> <code>list or ndarray</code> <p>Array or list of returns</p> required <code>annualize</code> <code>bool</code> <p>Whether to annualize the standard deviation</p> <code>False</code> <code>periods_per_year</code> <code>int</code> <p>Number of periods in a year (252 for daily returns, 12 for monthly, 4 for quarterly)</p> <code>252</code> <p>Returns:</p> Type Description <code>float</code> <p>Standard deviation of returns</p> Notes <p>Standard deviation measures the dispersion of returns around the mean. It is the square root of the variance.</p>"},{"location":"api/portfolio/risk_measurement/#pypulate.portfolio.risk_measurement.tracking_error","title":"<code>tracking_error(portfolio_returns, benchmark_returns, annualize=False, periods_per_year=252)</code>","text":"<p>Calculate the tracking error between portfolio returns and benchmark returns.</p> <p>Parameters:</p> Name Type Description Default <code>portfolio_returns</code> <code>list or ndarray</code> <p>Array or list of portfolio returns</p> required <code>benchmark_returns</code> <code>list or ndarray</code> <p>Array or list of benchmark returns</p> required <code>annualize</code> <code>bool</code> <p>Whether to annualize the tracking error</p> <code>False</code> <code>periods_per_year</code> <code>int</code> <p>Number of periods in a year (252 for daily returns, 12 for monthly, 4 for quarterly)</p> <code>252</code> <p>Returns:</p> Type Description <code>float</code> <p>Tracking error</p> Notes <p>Tracking error measures how closely a portfolio follows its benchmark. It is the standard deviation of the difference between portfolio and benchmark returns.</p>"},{"location":"api/portfolio/risk_measurement/#pypulate.portfolio.risk_measurement.value_at_risk","title":"<code>value_at_risk(returns, confidence_level=0.95, method='historical', parametric_mean=None, parametric_std=None, current_value=1.0)</code>","text":"<p>Calculate the Value-at-Risk (VaR) of a portfolio.</p> <p>Parameters:</p> Name Type Description Default <code>returns</code> <code>list or ndarray</code> <p>Array or list of returns</p> required <code>confidence_level</code> <code>float</code> <p>Confidence level for VaR calculation (e.g., 0.95 for 95% confidence)</p> <code>0.95</code> <code>method</code> <code>str</code> <p>Method for calculating VaR ('historical', 'parametric', or 'monte_carlo')</p> <code>'historical'</code> <code>parametric_mean</code> <code>float</code> <p>Mean for parametric VaR calculation (if None, calculated from returns)</p> <code>None</code> <code>parametric_std</code> <code>float</code> <p>Standard deviation for parametric VaR calculation (if None, calculated from returns)</p> <code>None</code> <code>current_value</code> <code>float</code> <p>Current value of the portfolio</p> <code>1.0</code> <p>Returns:</p> Type Description <code>float</code> <p>Value-at-Risk (VaR) as a positive number representing the potential loss</p> Notes <p>VaR measures the potential loss in value of a portfolio over a defined period for a given confidence interval.</p>"},{"location":"api/service-pricing/bundle-pricing/","title":"Bundle Pricing API Reference","text":"<p>This page documents the API for the bundle pricing module in Pypulate.</p>"},{"location":"api/service-pricing/bundle-pricing/#pypulate.pricing.bundle_pricing.calculate_bundle_price","title":"<code>calculate_bundle_price(items, item_prices, bundle_discounts, minimum_bundle_size=2)</code>","text":"<p>Calculate price for bundled items with discounts.</p> <p>Parameters:</p> Name Type Description Default <code>items</code> <code>list</code> <p>List of items in the bundle</p> required <code>item_prices</code> <code>dict</code> <p>Individual prices for each item</p> required <code>bundle_discounts</code> <code>dict</code> <p>Discount rates for different bundle combinations</p> required <code>minimum_bundle_size</code> <code>int</code> <p>Minimum items required for bundle pricing</p> <code>2</code> <p>Returns:</p> Type Description <code>float</code> <p>Total price for the bundle</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; items = ['item1', 'item2', 'item3']\n&gt;&gt;&gt; item_prices = {'item1': 10, 'item2': 20, 'item3': 30}\n&gt;&gt;&gt; bundle_discounts = {'item1+item2': 0.10, 'item1+item2+item3': 0.20}\n&gt;&gt;&gt; calculate_bundle_price(items, item_prices, bundle_discounts)\n48.0\n</code></pre>"},{"location":"api/service-pricing/dynamic-pricing/","title":"Dynamic Pricing API Reference","text":"<p>This page documents the API for the business KPIs module in Pypulate.</p> <p>Dynamic Pricing Module</p> <p>This module provides functions for calculating dynamic pricing adjustments.</p>"},{"location":"api/service-pricing/dynamic-pricing/#pypulate.pricing.dynamic_pricing.PricingRule","title":"<code>PricingRule</code>","text":"<p>A class for managing custom pricing rules.</p> <p>This class provides methods for: - Adding custom pricing rules - Applying custom pricing rules - Managing rule metadata</p>"},{"location":"api/service-pricing/dynamic-pricing/#pypulate.pricing.dynamic_pricing.PricingRule.__init__","title":"<code>__init__()</code>","text":"<p>Initialize the PricingRule class.</p>"},{"location":"api/service-pricing/dynamic-pricing/#pypulate.pricing.dynamic_pricing.PricingRule.add_rule","title":"<code>add_rule(rule_name, calculation_function, description='')</code>","text":"<p>Add a custom pricing rule.</p> <p>Parameters:</p> Name Type Description Default <code>rule_name</code> <code>str</code> <p>Name of the custom pricing rule</p> required <code>calculation_function</code> <code>callable</code> <p>Function that implements the custom pricing logic</p> required <code>description</code> <code>str</code> <p>Description of the pricing rule</p> <code>''</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; def holiday_pricing(base_price, holiday_multiplier):\n...     return base_price * holiday_multiplier\n&gt;&gt;&gt; rules = PricingRule()\n&gt;&gt;&gt; rules.add_rule('holiday', holiday_pricing, 'Apply holiday pricing multiplier')\n</code></pre>"},{"location":"api/service-pricing/dynamic-pricing/#pypulate.pricing.dynamic_pricing.PricingRule.apply_rule","title":"<code>apply_rule(rule_name, *args, **kwargs)</code>","text":"<p>Apply a custom pricing rule.</p> <p>Parameters:</p> Name Type Description Default <code>rule_name</code> <code>str</code> <p>Name of the custom pricing rule</p> required <code>*args</code> <p>Arguments to pass to the custom pricing function</p> <code>()</code> <code>**kwargs</code> <p>Arguments to pass to the custom pricing function</p> <code>()</code> <p>Returns:</p> Type Description <code>float</code> <p>Price calculated using the custom rule</p> <p>Raises:</p> Type Description <code>KeyError</code> <p>If the specified rule_name doesn't exist</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; rules = PricingRule()\n&gt;&gt;&gt; rules.add_rule('holiday', lambda price, mult: price * mult)\n&gt;&gt;&gt; rules.apply_rule('holiday', 100.0, 1.2)\n120.0\n</code></pre>"},{"location":"api/service-pricing/dynamic-pricing/#pypulate.pricing.dynamic_pricing.PricingRule.get_rule_description","title":"<code>get_rule_description(rule_name)</code>","text":"<p>Get the description of a pricing rule.</p> <p>Parameters:</p> Name Type Description Default <code>rule_name</code> <code>str</code> <p>Name of the pricing rule</p> required <p>Returns:</p> Type Description <code>str</code> <p>Description of the pricing rule</p> <p>Raises:</p> Type Description <code>KeyError</code> <p>If the specified rule_name doesn't exist</p>"},{"location":"api/service-pricing/dynamic-pricing/#pypulate.pricing.dynamic_pricing.PricingRule.list_rules","title":"<code>list_rules()</code>","text":"<p>List all available pricing rules and their descriptions.</p> <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary of rule names and their descriptions</p>"},{"location":"api/service-pricing/dynamic-pricing/#pypulate.pricing.dynamic_pricing.apply_dynamic_pricing","title":"<code>apply_dynamic_pricing(base_price, demand_factor, competition_factor, seasonality_factor=1.0, min_price=None, max_price=None)</code>","text":"<p>Calculate dynamically adjusted price based on market factors.</p> <p>Parameters:</p> Name Type Description Default <code>base_price</code> <code>float</code> <p>Base price before adjustments</p> required <code>demand_factor</code> <code>float</code> <p>Demand multiplier (1.0 is neutral)</p> required <code>competition_factor</code> <code>float</code> <p>Competition multiplier (1.0 is neutral)</p> required <code>seasonality_factor</code> <code>float</code> <p>Seasonal adjustment factor</p> <code>1.0</code> <code>min_price</code> <code>float</code> <p>Minimum price floor</p> <code>None</code> <code>max_price</code> <code>float</code> <p>Maximum price ceiling</p> <code>None</code> <p>Returns:</p> Type Description <code>float</code> <p>Dynamically adjusted price</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; apply_dynamic_pricing(100.0, 1.2, 0.9, 1.1)\n118.8  # 100.0 * 1.2 * 0.9 * 1.1\n&gt;&gt;&gt; apply_dynamic_pricing(100.0, 1.5, 0.8, min_price=90.0, max_price=150.0)\n120.0  # 100.0 * 1.5 * 0.8, bounded by min/max\n</code></pre>"},{"location":"api/service-pricing/freemium-pricing/","title":"Freemium Pricing API Reference","text":"<p>This page documents the API for the freemium pricing module in Pypulate.</p>"},{"location":"api/service-pricing/freemium-pricing/#pypulate.pricing.freemium_pricing.calculate_freemium_price","title":"<code>calculate_freemium_price(base_features, premium_features, feature_usage, free_limits, overage_rates)</code>","text":"<p>Calculate price for freemium model with usage limits.</p> <p>Parameters:</p> Name Type Description Default <code>base_features</code> <code>list</code> <p>List of free features</p> required <code>premium_features</code> <code>list</code> <p>List of premium features</p> required <code>feature_usage</code> <code>dict</code> <p>Usage metrics for each feature</p> required <code>free_limits</code> <code>dict</code> <p>Usage limits for free tier</p> required <code>overage_rates</code> <code>dict</code> <p>Rates for usage beyond free limits</p> required <p>Returns:</p> Type Description <code>float</code> <p>Calculated price</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; base_features = ['feature1', 'feature2']\n&gt;&gt;&gt; premium_features = ['feature3', 'feature4']\n&gt;&gt;&gt; feature_usage = {'feature1': 10, 'feature2': 5, 'feature3': 3, 'feature4': 2}\n&gt;&gt;&gt; free_limits = {'feature1': 10, 'feature2': 5}\n&gt;&gt;&gt; overage_rates = {'feature1': 1.0, 'feature2': 0.5, 'feature3': 2.0, 'feature4': 1.5}\n&gt;&gt;&gt; calculate_freemium_price(base_features, premium_features, feature_usage, free_limits, overage_rates)\n9.0\n</code></pre>"},{"location":"api/service-pricing/loyalty-based-pricing/","title":"Loyalty-Based Pricing API Reference","text":"<p>This page documents the API for the loyalty-based pricing module in Pypulate.</p>"},{"location":"api/service-pricing/loyalty-based-pricing/#pypulate.pricing.loyalty_based_pricing.calculate_loyalty_price","title":"<code>calculate_loyalty_price(base_price, customer_tenure, loyalty_tiers, additional_benefits={})</code>","text":"<p>Calculate price with loyalty discounts and benefits.</p> <p>Parameters:</p> Name Type Description Default <code>base_price</code> <code>float</code> <p>Base price before loyalty benefits</p> required <code>customer_tenure</code> <code>int</code> <p>Customer's tenure in months</p> required <code>loyalty_tiers</code> <code>dict</code> <p>Discount rates for different tenure levels</p> required <code>additional_benefits</code> <code>dict</code> <p>Additional benefits for loyal customers</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary containing: - loyalty_price: final price after discount - loyalty_tier: the applicable tier - loyalty_discount: discount amount - additional_benefits: benefits dictionary</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; loyalty_tiers = {1: 0.10, 3: 0.15, 6: 0.20}\n&gt;&gt;&gt; calculate_loyalty_price(100, 2, loyalty_tiers)\n{'loyalty_price': 90.0, 'loyalty_tier': 1, 'loyalty_discount': 10.0, 'additional_benefits': {}}\n</code></pre>"},{"location":"api/service-pricing/peak-pricing/","title":"Peak Pricing API Reference","text":"<p>This page documents the API for the peak pricing module in Pypulate.</p>"},{"location":"api/service-pricing/peak-pricing/#pypulate.pricing.peak_pricing.calculate_peak_pricing","title":"<code>calculate_peak_pricing(base_price, usage_time, peak_hours, peak_multiplier=1.5, off_peak_multiplier=0.8)</code>","text":"<p>Calculate price based on peak/off-peak hours.</p> <p>Parameters:</p> Name Type Description Default <code>base_price</code> <code>float</code> <p>Base price per unit</p> required <code>usage_time</code> <code>str</code> <p>Time of usage (format: \"HH:MM\")</p> required <code>peak_hours</code> <code>dict</code> <p>Dictionary of weekdays and their peak hours Format: {\"monday\": (\"09:00\", \"17:00\")}</p> required <code>peak_multiplier</code> <code>float</code> <p>Price multiplier during peak hours</p> <code>1.5</code> <code>off_peak_multiplier</code> <code>float</code> <p>Price multiplier during off-peak hours</p> <code>0.8</code> <p>Returns:</p> Type Description <code>float</code> <p>Calculated price</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; calculate_peak_pricing(100, \"10:00\", {\"monday\": (\"09:00\", \"17:00\")})\n150.0  # $100 * 1.5\n</code></pre>"},{"location":"api/service-pricing/subscription-pricing/","title":"Subscription Based Pricing API Reference","text":"<p>This page documents the API for the business KPIs module in Pypulate.</p> <p>Subscription Pricing Module</p> <p>This module provides functions for calculating subscription-based pricing.</p>"},{"location":"api/service-pricing/subscription-pricing/#pypulate.pricing.subscription_pricing.calculate_subscription_price","title":"<code>calculate_subscription_price(base_price, features, feature_prices, duration_months=1, discount_rate=0.0)</code>","text":"<p>Calculate subscription price including selected features.</p> <p>Parameters:</p> Name Type Description Default <code>base_price</code> <code>float</code> <p>Base subscription price</p> required <code>features</code> <code>list</code> <p>List of selected feature names</p> required <code>feature_prices</code> <code>dict</code> <p>Dictionary of feature names and their prices</p> required <code>duration_months</code> <code>int</code> <p>Subscription duration in months</p> <code>1</code> <code>discount_rate</code> <code>float</code> <p>Annual discount rate for longer subscriptions</p> <code>0.0</code> <p>Returns:</p> Type Description <code>float</code> <p>Total subscription price</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; features = ['premium', 'api_access']\n&gt;&gt;&gt; feature_prices = {'premium': 49.99, 'api_access': 29.99}\n&gt;&gt;&gt; calculate_subscription_price(99.99, features, feature_prices)\n179.97  # 99.99 + 49.99 + 29.99\n&gt;&gt;&gt; calculate_subscription_price(99.99, features, feature_prices, \n...                            duration_months=12, discount_rate=0.10)\n1943.68  # (99.99 + 49.99 + 29.99) * 12 * (1 - 0.10)\n</code></pre>"},{"location":"api/service-pricing/tiered-pricing/","title":"Tiered Pricing API Reference","text":"<p>This page documents the API for the business KPIs module in Pypulate.</p> <p>Tiered Pricing Module</p> <p>This module provides functions for calculating tiered pricing structures.</p>"},{"location":"api/service-pricing/tiered-pricing/#pypulate.pricing.tiered_pricing.calculate_tiered_price","title":"<code>calculate_tiered_price(usage_units, tiers, cumulative=True)</code>","text":"<p>Calculate price based on tiered pricing structure.</p> <p>Parameters:</p> Name Type Description Default <code>usage_units</code> <code>float</code> <p>The number of units consumed</p> required <code>tiers</code> <code>dict</code> <p>Dictionary of tier ranges and their prices Format: {\"0-1000\": 0.10, \"1001-2000\": 0.08, \"2001+\": 0.05}</p> required <code>cumulative</code> <code>bool</code> <p>If True, price is calculated cumulatively across tiers If False, entire usage is priced at the tier it falls into</p> <code>True</code> <p>Returns:</p> Type Description <code>float</code> <p>Total price based on tiered pricing</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; tiers = {\"0-1000\": 0.10, \"1001-2000\": 0.08, \"2001+\": 0.05}\n&gt;&gt;&gt; calculate_tiered_price(1500, tiers)\n140.02\n&gt;&gt;&gt; calculate_tiered_price(1500, tiers, cumulative=False)\n120.0\n</code></pre>"},{"location":"api/service-pricing/time-based-pricing/","title":"Time-Based Pricing API Reference","text":"<p>This page documents the API for the time-based pricing module in Pypulate.</p>"},{"location":"api/service-pricing/time-based-pricing/#pypulate.pricing.time_based_pricing.calculate_time_based_price","title":"<code>calculate_time_based_price(base_price, duration, time_unit='hour', minimum_duration=1.0, rounding_method='up')</code>","text":"<p>Calculate price based on time duration.</p> <p>Parameters:</p> Name Type Description Default <code>base_price</code> <code>float</code> <p>Base price per time unit</p> required <code>duration</code> <code>float</code> <p>Duration of usage</p> required <code>time_unit</code> <code>str</code> <p>Unit of time ('minute', 'hour', 'day')</p> <code>'hour'</code> <code>minimum_duration</code> <code>float</code> <p>Minimum billable duration</p> <code>1.0</code> <code>rounding_method</code> <code>str</code> <p>How to round partial units ('up', 'down', 'nearest')</p> <code>'up'</code> <p>Returns:</p> Type Description <code>float</code> <p>Calculated price</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; calculate_time_based_price(100, 2.5, 'hour')\n250.0  # 2.5 hours at $100/hour\n</code></pre>"},{"location":"api/service-pricing/usage-based-pricing/","title":"Usage Based Pricing API Reference","text":"<p>This page documents the API for the business KPIs module in Pypulate.</p> <p>Usage Pricing Module</p> <p>This module provides functions for calculating usage-based pricing.</p>"},{"location":"api/service-pricing/usage-based-pricing/#pypulate.pricing.usage_pricing.calculate_usage_price","title":"<code>calculate_usage_price(usage_metrics, metric_rates, minimum_charge=0.0, maximum_charge=None)</code>","text":"<p>Calculate price based on usage metrics.</p> <p>Parameters:</p> Name Type Description Default <code>usage_metrics</code> <code>dict</code> <p>Dictionary of metric names and their usage values</p> required <code>metric_rates</code> <code>dict</code> <p>Dictionary of metric names and their per-unit rates</p> required <code>minimum_charge</code> <code>float</code> <p>Minimum charge to apply</p> <code>0.0</code> <code>maximum_charge</code> <code>float</code> <p>Maximum charge cap</p> <code>None</code> <p>Returns:</p> Type Description <code>float</code> <p>Total usage-based price</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; metrics = {'api_calls': 1000, 'storage_gb': 50}\n&gt;&gt;&gt; rates = {'api_calls': 0.001, 'storage_gb': 0.10}\n&gt;&gt;&gt; calculate_usage_price(metrics, rates)\n6.0  # (1000 * 0.001) + (50 * 0.10)\n&gt;&gt;&gt; calculate_usage_price(metrics, rates, minimum_charge=10.0)\n10.0  # Max of calculated price and minimum charge\n</code></pre>"},{"location":"api/service-pricing/usage-based-pricing/#pypulate.pricing.usage_pricing.calculate_volume_discount","title":"<code>calculate_volume_discount(base_price, volume, discount_tiers)</code>","text":"<p>Calculate price with volume-based discounts.</p> <p>Parameters:</p> Name Type Description Default <code>base_price</code> <code>float</code> <p>Base price per unit</p> required <code>volume</code> <code>int</code> <p>Number of units</p> required <code>discount_tiers</code> <code>dict</code> <p>Dictionary of volume thresholds and discount rates Format: {100: 0.05, 500: 0.10, 1000: 0.15}</p> required <p>Returns:</p> Type Description <code>float</code> <p>Total price after volume discount</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; tiers = {100: 0.05, 500: 0.10, 1000: 0.15}\n&gt;&gt;&gt; calculate_volume_discount(10.0, 750, tiers)\n6750.0  # 750 * 10.0 * (1 - 0.10)\n</code></pre>"},{"location":"api/technical/momentum/","title":"Momentum API Reference","text":"<p>Momentum Indicators Module</p> <p>This module provides functions for calculating momentum-based indicators for financial time series analysis.</p>"},{"location":"api/technical/momentum/#pypulate.technical.momentum.adx","title":"<code>adx(data, period=14)</code>","text":"<p>Calculate Average Directional Index (ADX).</p> <p>ADX is a technical indicator used to determine the strength of a trend.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>Input time series data</p> required <code>period</code> <code>int</code> <p>Number of periods for calculation</p> <code>14</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>ADX values</p>"},{"location":"api/technical/momentum/#pypulate.technical.momentum.cci","title":"<code>cci(close, period=20, constant=0.015)</code>","text":"<p>Calculate Commodity Channel Index (CCI) using close prices.</p> <p>CCI measures the current price level relative to an average price level over a given period. This version uses only close prices instead of typical prices for simplified calculation.</p> <p>Parameters:</p> Name Type Description Default <code>close</code> <code>ndarray</code> <p>Close prices</p> required <code>period</code> <code>int</code> <p>Number of periods for calculation</p> <code>20</code> <code>constant</code> <code>float</code> <p>Scaling constant</p> <code>0.015</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>CCI values</p>"},{"location":"api/technical/momentum/#pypulate.technical.momentum.macd","title":"<code>macd(data, fast_period=12, slow_period=26, signal_period=9)</code>","text":"<p>Calculate Moving Average Convergence Divergence (MACD).</p> <p>MACD is a trend-following momentum indicator that shows the relationship between two moving averages of a security's price.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>Input time series data</p> required <code>fast_period</code> <code>int</code> <p>Period for the fast EMA</p> <code>12</code> <code>slow_period</code> <code>int</code> <p>Period for the slow EMA</p> <code>26</code> <code>signal_period</code> <code>int</code> <p>Period for the signal line (EMA of MACD line)</p> <code>9</code> <p>Returns:</p> Type Description <code>tuple of numpy.ndarray</code> <p>Tuple containing (macd_line, signal_line, histogram)</p>"},{"location":"api/technical/momentum/#pypulate.technical.momentum.momentum","title":"<code>momentum(data, period=14)</code>","text":"<p>Calculate momentum over a specified period.</p> <p>Momentum measures the amount that a price has changed over a given period.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>Input time series data</p> required <code>period</code> <code>int</code> <p>Number of periods to calculate momentum</p> <code>14</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Momentum values</p>"},{"location":"api/technical/momentum/#pypulate.technical.momentum.percent_change","title":"<code>percent_change(data, periods=1)</code>","text":"<p>Calculate percentage change between consecutive periods.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>Input time series data</p> required <code>periods</code> <code>int</code> <p>Number of periods to calculate change over</p> <code>1</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Percentage change values</p>"},{"location":"api/technical/momentum/#pypulate.technical.momentum.roc","title":"<code>roc(data, period=14)</code>","text":"<p>Calculate Rate of Change (ROC) over a specified period.</p> <p>ROC measures the percentage change in price over a given period.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>Input time series data</p> required <code>period</code> <code>int</code> <p>Number of periods to calculate ROC</p> <code>14</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>ROC values in percentage</p>"},{"location":"api/technical/momentum/#pypulate.technical.momentum.rsi","title":"<code>rsi(data, period=14, smoothing_type='sma')</code>","text":"<p>Calculate Relative Strength Index (RSI) over a specified period.</p> <p>RSI measures the speed and change of price movements, indicating overbought (&gt;70) or oversold (&lt;30) conditions.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>Input time series data</p> required <code>period</code> <code>int</code> <p>Number of periods to calculate RSI</p> <code>14</code> <code>smoothing_type</code> <code>str</code> <p>Type of smoothing to use: 'sma' (Simple Moving Average) or  'ema' (Exponential Moving Average)</p> <code>'sma'</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>RSI values (0-100)</p>"},{"location":"api/technical/momentum/#pypulate.technical.momentum.stochastic_oscillator","title":"<code>stochastic_oscillator(close, high, low, k_period=14, d_period=3)</code>","text":"<p>Calculate Stochastic Oscillator.</p> <p>The Stochastic Oscillator is a momentum indicator that shows the location of the close relative to the high-low range over a set number of periods.</p> <p>Parameters:</p> Name Type Description Default <code>close</code> <code>ndarray</code> <p>Close prices</p> required <code>high</code> <code>ndarray</code> <p>High prices. If None, assumes close contains close prices and high=low=close</p> required <code>low</code> <code>ndarray</code> <p>Low prices. If None, assumes close contains close prices and high=low=close</p> required <code>k_period</code> <code>int</code> <p>Number of periods for %K</p> <code>14</code> <code>d_period</code> <code>int</code> <p>Number of periods for %D (moving average of %K)</p> <code>3</code> <p>Returns:</p> Type Description <code>tuple of numpy.ndarray</code> <p>Tuple containing (%K, %D)</p>"},{"location":"api/technical/momentum/#pypulate.technical.momentum.tsi","title":"<code>tsi(data, long_period=25, short_period=13, signal_period=7)</code>","text":"<p>Calculate True Strength Index (TSI).</p> <p>TSI is a momentum oscillator that helps identify trends and reversals.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>Input time series data</p> required <code>long_period</code> <code>int</code> <p>Long period for double smoothing</p> <code>25</code> <code>short_period</code> <code>int</code> <p>Short period for double smoothing</p> <code>13</code> <code>signal_period</code> <code>int</code> <p>Period for the signal line</p> <code>7</code> <p>Returns:</p> Type Description <code>tuple of numpy.ndarray</code> <p>Tuple containing (tsi_line, signal_line)</p>"},{"location":"api/technical/momentum/#pypulate.technical.momentum.williams_r","title":"<code>williams_r(close, high=None, low=None, period=14)</code>","text":"<p>Calculate Williams %R.</p> <p>Williams %R is a momentum indicator that measures overbought and oversold levels.</p> <p>Parameters:</p> Name Type Description Default <code>close</code> <code>ndarray</code> <p>Close prices</p> required <code>high</code> <code>ndarray</code> <p>High prices. If None, assumes close contains close prices and high=low=close</p> <code>None</code> <code>low</code> <code>ndarray</code> <p>Low prices. If None, assumes close contains close prices and high=low=close</p> <code>None</code> <code>period</code> <code>int</code> <p>Number of periods for calculation</p> <code>14</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Williams %R values (-100 to 0)</p>"},{"location":"api/technical/utils/","title":"Utils API Reference","text":"<p>KPI Utility Functions</p> <p>This module provides utility functions for calculating Key Performance Indicators (KPIs) for financial time series analysis.</p>"},{"location":"api/technical/utils/#pypulate.technical.utils.diff","title":"<code>diff(data, periods=1)</code>","text":"<p>Calculate difference between consecutive values.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>Input time series data</p> required <code>periods</code> <code>int</code> <p>Number of periods to calculate difference over</p> <code>1</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Difference values</p>"},{"location":"api/technical/utils/#pypulate.technical.utils.log","title":"<code>log(data)</code>","text":"<p>Calculate the natural logarithm of price data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>array - like</code> <p>Input price data as list or numpy array</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Natural logarithm of the input data. Returns NaN for any non-positive values.</p>"},{"location":"api/technical/utils/#pypulate.technical.utils.rolling_kurtosis","title":"<code>rolling_kurtosis(data, period=14)</code>","text":"<p>Calculate rolling kurtosis over a specified period.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>Input time series data</p> required <code>period</code> <code>int</code> <p>Window size for rolling kurtosis</p> <code>14</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Rolling kurtosis values</p>"},{"location":"api/technical/utils/#pypulate.technical.utils.rolling_max","title":"<code>rolling_max(data, period=14)</code>","text":"<p>Calculate rolling maximum over a specified period.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>Input time series data</p> required <code>period</code> <code>int</code> <p>Window size for rolling maximum</p> <code>14</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Rolling maximum values</p>"},{"location":"api/technical/utils/#pypulate.technical.utils.rolling_min","title":"<code>rolling_min(data, period=14)</code>","text":"<p>Calculate rolling minimum over a specified period.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>Input time series data</p> required <code>period</code> <code>int</code> <p>Window size for rolling minimum</p> <code>14</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Rolling minimum values</p>"},{"location":"api/technical/utils/#pypulate.technical.utils.rolling_skew","title":"<code>rolling_skew(data, period=14)</code>","text":"<p>Calculate rolling skewness over a specified period.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>Input time series data</p> required <code>period</code> <code>int</code> <p>Window size for rolling skewness</p> <code>14</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Rolling skewness values</p>"},{"location":"api/technical/utils/#pypulate.technical.utils.rolling_std","title":"<code>rolling_std(data, period=14)</code>","text":"<p>Calculate rolling standard deviation over a specified period.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>Input time series data</p> required <code>period</code> <code>int</code> <p>Window size for rolling standard deviation</p> <code>14</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Rolling standard deviation values</p>"},{"location":"api/technical/utils/#pypulate.technical.utils.rolling_var","title":"<code>rolling_var(data, period=14)</code>","text":"<p>Calculate rolling variance over a specified period.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>Input time series data</p> required <code>period</code> <code>int</code> <p>Window size for rolling variance</p> <code>14</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Rolling variance values</p>"},{"location":"api/technical/utils/#pypulate.technical.utils.slope","title":"<code>slope(data, period=5)</code>","text":"<p>Calculate the slope of the time series over a specified period.</p> <p>This function uses linear regression to calculate the slope of the line that best fits the data over the specified period.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>Input time series data</p> required <code>period</code> <code>int</code> <p>Number of points to use for slope calculation</p> <code>5</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Slope values for each point in the time series</p>"},{"location":"api/technical/utils/#pypulate.technical.utils.typical_price","title":"<code>typical_price(close, high, low)</code>","text":"<p>Calculate the typical price from close, high, and low prices.</p> <p>Parameters:</p> Name Type Description Default <code>close</code> <code>ndarray</code> <p>Close prices</p> required <code>high</code> <code>ndarray</code> <p>High prices</p> required <code>low</code> <code>ndarray</code> <p>Low prices</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Typical price values</p>"},{"location":"api/technical/utils/#pypulate.technical.utils.zscore","title":"<code>zscore(data, period=14)</code>","text":"<p>Calculate rolling Z-score over a specified period.</p> <p>Z-score measures how many standard deviations a data point is from the mean.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>Input time series data</p> required <code>period</code> <code>int</code> <p>Window size for Z-score calculation</p> <code>14</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Z-score values</p>"},{"location":"api/technical/volatility/","title":"Volatility API Reference","text":"<p>Volatility Measurement Functions</p> <p>This module provides functions for measuring volatility in financial time series data.</p>"},{"location":"api/technical/volatility/#pypulate.technical.volatility.atr","title":"<code>atr(close, high, low, period=14)</code>","text":"<p>Calculate Average True Range (ATR) over a specified period.</p> <p>ATR measures market volatility by decomposing the entire range of an asset price.</p> <p>Parameters:</p> Name Type Description Default <code>close</code> <code>ndarray</code> <p>Close prices</p> required <code>high</code> <code>ndarray</code> <p>High prices. If None, assumes close contains close prices and high=low=close</p> required <code>low</code> <code>ndarray</code> <p>Low prices. If None, assumes close contains close prices and high=low=close</p> required <code>period</code> <code>int</code> <p>Number of periods to calculate ATR</p> <code>14</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>ATR values</p>"},{"location":"api/technical/volatility/#pypulate.technical.volatility.bollinger_bands","title":"<code>bollinger_bands(data, period=20, std_dev=2.0)</code>","text":"<p>Calculate Bollinger Bands over a specified period.</p> <p>Bollinger Bands consist of a middle band (SMA), an upper band (SMA + kstd), and a lower band (SMA - kstd).</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>Input time series data</p> required <code>period</code> <code>int</code> <p>Number of periods for the moving average</p> <code>20</code> <code>std_dev</code> <code>float</code> <p>Number of standard deviations for the upper and lower bands</p> <code>2.0</code> <p>Returns:</p> Type Description <code>tuple of numpy.ndarray</code> <p>Tuple containing (upper_band, middle_band, lower_band)</p>"},{"location":"api/technical/volatility/#pypulate.technical.volatility.donchian_channels","title":"<code>donchian_channels(data, high, low, period=20)</code>","text":"<p>Calculate Donchian Channels over a specified period.</p> <p>Donchian Channels consist of an upper band (highest high), a lower band (lowest low), and a middle band (average of upper and lower).</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>Input time series data (typically close prices)</p> required <code>high</code> <code>ndarray</code> <p>High prices. If None, uses data</p> required <code>low</code> <code>ndarray</code> <p>Low prices. If None, uses data</p> required <code>period</code> <code>int</code> <p>Number of periods for the channels</p> <code>20</code> <p>Returns:</p> Type Description <code>tuple of numpy.ndarray</code> <p>Tuple containing (upper_channel, middle_channel, lower_channel)</p>"},{"location":"api/technical/volatility/#pypulate.technical.volatility.historical_volatility","title":"<code>historical_volatility(data, period=21, annualization_factor=252)</code>","text":"<p>Calculate historical volatility over a specified period.</p> <p>Historical volatility is the standard deviation of log returns, typically annualized.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>Input time series data</p> required <code>period</code> <code>int</code> <p>Number of periods to calculate volatility</p> <code>21</code> <code>annualization_factor</code> <code>int</code> <p>Factor to annualize volatility (252 for daily data, 52 for weekly, 12 for monthly)</p> <code>252</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Historical volatility values as percentage</p>"},{"location":"api/technical/volatility/#pypulate.technical.volatility.keltner_channels","title":"<code>keltner_channels(close, high, low, period=20, atr_period=10, multiplier=2.0)</code>","text":"<p>Calculate Keltner Channels over a specified period.</p> <p>Keltner Channels consist of a middle band (EMA), an upper band (EMA + kATR), and a lower band (EMA - kATR).</p> <p>Parameters:</p> Name Type Description Default <code>close</code> <code>ndarray</code> <p>Close prices</p> required <code>high</code> <code>ndarray</code> <p>High prices. If None, assumes close contains close prices and high=low=close</p> required <code>low</code> <code>ndarray</code> <p>Low prices. If None, assumes close contains close prices and high=low=close</p> required <code>period</code> <code>int</code> <p>Number of periods for the EMA</p> <code>20</code> <code>atr_period</code> <code>int</code> <p>Number of periods for the ATR</p> <code>10</code> <code>multiplier</code> <code>float</code> <p>Multiplier for the ATR</p> <code>2.0</code> <p>Returns:</p> Type Description <code>tuple of numpy.ndarray</code> <p>Tuple containing (upper_channel, middle_channel, lower_channel)</p>"},{"location":"api/technical/volatility/#pypulate.technical.volatility.volatility_ratio","title":"<code>volatility_ratio(data, period=21, smooth_period=5)</code>","text":"<p>Calculate Volatility Ratio over a specified period.</p> <p>Volatility Ratio compares recent volatility to historical volatility. Values above 1 indicate increasing volatility, values below 1 indicate decreasing volatility.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>Input time series data</p> required <code>period</code> <code>int</code> <p>Number of periods for historical volatility</p> <code>21</code> <code>smooth_period</code> <code>int</code> <p>Number of periods to smooth the ratio</p> <code>5</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Volatility Ratio values</p>"},{"location":"examples/advanced_techniques/","title":"Advanced Techniques","text":"<p>This guide demonstrates advanced techniques and methods using the <code>pypulate</code> package.</p>"},{"location":"examples/advanced_techniques/#advanced-method-chaining","title":"Advanced Method Chaining","text":""},{"location":"examples/advanced_techniques/#multi-indicator-strategy-with-method-chaining","title":"Multi-Indicator Strategy with Method Chaining","text":"<pre><code>import numpy as np\nfrom pypulate import as_parray\n\n# Create sample price data\nprices = np.array([100, 102, 104, 103, 105, 107, 108, 107, 105, 104, 103, 105, 107, 109, 108])\nhigh = prices + 2\nlow = prices - 2\nvolume = np.array([1000, 1200, 1500, 1300, 1400, 1600, 1700, 1500, 1300, 1200, 1100, 1300, 1500, 1700, 1600])\n\n# Convert to Parray\nts = as_parray(prices)\n\n# Create a complex strategy with method chaining\n# 1. Calculate price-based indicators\nema_short = ts.ema(5)\nema_long = ts.ema(10)\nupper_bb, middle_bb, lower_bb = ts.bollinger_bands(20, 2.0)\n\n# 2. Calculate momentum indicators\nrsi_values = ts.rsi(14)\nmacd_line, signal_line, histogram = ts.macd()\nk, d = ts.stochastic_oscillator(high, low)\n\n# 3. Calculate volatility indicators\natr_values = ts.atr(high, low, 14)\nvolatility = ts.historical_volatility(21)\n\n# 4. Generate complex signals\nbuy_signals = (\n    (ema_short.crossover(ema_long)) &amp;                # Price trend confirmation\n    (rsi_values &gt; 30) &amp; (rsi_values &lt; 70) &amp;          # RSI not extreme\n    (macd_line.crossover(signal_line)) &amp;             # MACD bullish crossover\n    (k.crossover(d)) &amp; (k &lt; 50) &amp;                    # Stochastic bullish crossover from low levels\n    (ts &gt; lower_bb) &amp; (ts &lt; middle_bb) &amp;             # Price between lower and middle BB\n    (volatility &lt; 30)                                # Low volatility environment\n)\n\nsell_signals = (\n    (ema_short.crossunder(ema_long)) &amp;               # Price trend confirmation\n    (rsi_values &gt; 70) &amp;                              # RSI overbought\n    (macd_line.crossunder(signal_line)) &amp;            # MACD bearish crossunder\n    (k.crossunder(d)) &amp; (k &gt; 50) &amp;                   # Stochastic bearish crossunder from high levels\n    (ts &gt; middle_bb) &amp; (ts &lt; upper_bb)               # Price between middle and upper BB\n)\n\nprint(\"Complex buy signals:\", buy_signals)\nprint(\"Complex sell signals:\", sell_signals)\n</code></pre>"},{"location":"examples/advanced_techniques/#custom-indicators","title":"Custom Indicators","text":""},{"location":"examples/advanced_techniques/#creating-a-custom-indicator","title":"Creating a Custom Indicator","text":"<pre><code>import numpy as np\nfrom pypulate import as_parray\n\n# Create a custom indicator function\ndef custom_momentum_oscillator(data, rsi_period=14, macd_fast=12, macd_slow=26, macd_signal=9, weight_rsi=0.5):\n    \"\"\"\n    Custom momentum oscillator combining RSI and MACD\n\n    Parameters\n    ----------\n    data : numpy.ndarray\n        Input price data\n    rsi_period : int\n        Period for RSI calculation\n    macd_fast : int\n        Fast period for MACD\n    macd_slow : int\n        Slow period for MACD\n    macd_signal : int\n        Signal period for MACD\n    weight_rsi : float\n        Weight for RSI component (0-1)\n\n    Returns\n    -------\n    numpy.ndarray\n        Custom momentum oscillator values\n    \"\"\"\n    # Convert to Parray\n    ts = as_parray(data)\n\n    # Calculate RSI (0-100)\n    rsi = ts.rsi(rsi_period)\n\n    # Calculate MACD\n    macd_line, signal_line, histogram = ts.macd(macd_fast, macd_slow, macd_signal)\n\n    # Normalize MACD histogram to 0-100 scale\n    # Find min and max values\n    hist_min = np.nanmin(histogram)\n    hist_max = np.nanmax(histogram)\n\n    # Normalize to 0-100\n    if hist_max - hist_min != 0:\n        normalized_hist = ((histogram - hist_min) / (hist_max - hist_min)) * 100\n    else:\n        normalized_hist = np.full_like(histogram, 50)\n\n    # Combine RSI and normalized MACD histogram\n    weight_macd = 1 - weight_rsi\n    custom_oscillator = (rsi * weight_rsi) + (normalized_hist * weight_macd)\n\n    return custom_oscillator\n\n# Apply the custom indicator\nprices = np.array([100, 102, 104, 103, 105, 107, 108, 107, 105, 104, 103, 105, 107, 109, 108])\ncustom_indicator = custom_momentum_oscillator(prices)\n\nprint(\"Custom Momentum Oscillator:\", custom_indicator)\n\n# Generate signals\noverbought = custom_indicator &gt; 70\noversold = custom_indicator &lt; 30\n\nprint(\"Overbought signals:\", overbought)\nprint(\"Oversold signals:\", oversold)\n</code></pre>"},{"location":"examples/advanced_techniques/#advanced-filtering-techniques","title":"Advanced Filtering Techniques","text":""},{"location":"examples/advanced_techniques/#combining-multiple-filters","title":"Combining Multiple Filters","text":"<pre><code>import numpy as np\nfrom pypulate import as_parray\n\n# Create noisy price data\nnp.random.seed(42)\nbase_prices = np.linspace(100, 150, 100)  # Upward trend\nnoise = np.random.normal(0, 5, 100)       # Random noise\nprices = base_prices + noise\n\n# Convert to Parray\nts = as_parray(prices)\n\n# Apply multiple filters in sequence\nfiltered_prices = (\n    ts\n    .kalman_filter(process_variance=1e-4, measurement_variance=1e-2)  # First pass with Kalman filter\n    .butterworth_filter(cutoff=0.1, order=3, filter_type='lowpass')   # Remove high-frequency noise\n    .savitzky_golay_filter(window_length=11, polyorder=3)             # Smooth the result\n)\n\n# Calculate the noise reduction\noriginal_variance = np.var(prices)\nfiltered_variance = np.var(filtered_prices)\nnoise_reduction_percent = (1 - (filtered_variance / original_variance)) * 100\n\nprint(f\"Original price variance: {original_variance:.2f}\")\nprint(f\"Filtered price variance: {filtered_variance:.2f}\")\nprint(f\"Noise reduction: {noise_reduction_percent:.2f}%\")\n</code></pre>"},{"location":"examples/advanced_techniques/#adaptive-filtering-based-on-volatility","title":"Adaptive Filtering Based on Volatility","text":"<pre><code>import numpy as np\nfrom pypulate import as_parray\n\n# Create price data with varying volatility\nnp.random.seed(42)\nn_points = 200\nbase_prices = np.linspace(100, 200, n_points)  # Upward trend\n\n# Create periods of different volatility\nvolatility = np.ones(n_points) * 2  # Base volatility\nvolatility[50:100] = 5              # Higher volatility in this region\nvolatility[150:] = 8                # Even higher volatility at the end\n\n# Generate prices with varying volatility\nnoise = np.random.normal(0, volatility)\nprices = base_prices + noise\n\n# Convert to Parray\nts = as_parray(prices)\n\n# Calculate historical volatility\nhist_vol = ts.historical_volatility(21)\n\n# Apply adaptive filtering based on volatility\nresult = np.full_like(prices, np.nan)\n\nfor i in range(len(prices)):\n    if i &lt; 21:  # Not enough data for volatility calculation\n        result[i] = prices[i]\n    else:\n        current_vol = hist_vol[i]\n\n        # Choose filter parameters based on volatility\n        if current_vol &lt; 10:  # Low volatility\n            # Light filtering\n            window_size = 3\n            n_sigmas = 2.0\n        elif current_vol &lt; 20:  # Medium volatility\n            # Medium filtering\n            window_size = 5\n            n_sigmas = 2.5\n        else:  # High volatility\n            # Strong filtering\n            window_size = 7\n            n_sigmas = 3.0\n\n        # Apply Hampel filter with adaptive parameters\n        if i &gt;= window_size:\n            window = prices[i-window_size:i+1]\n            median = np.median(window)\n            mad = np.median(np.abs(window - median))\n\n            if mad == 0:  # Avoid division by zero\n                result[i] = prices[i]\n            else:\n                # Scale MAD to estimate standard deviation\n                sigma = 1.4826 * mad\n\n                # Check if the point is an outlier\n                if abs(prices[i] - median) &gt; n_sigmas * sigma:\n                    result[i] = median  # Replace outlier with median\n                else:\n                    result[i] = prices[i]  # Keep original value\n        else:\n            result[i] = prices[i]\n\n# Convert result to Parray for further analysis\nfiltered_ts = as_parray(result)\n\nprint(\"Adaptive filtering complete\")\n</code></pre>"},{"location":"examples/advanced_techniques/#advanced-time-series-decomposition","title":"Advanced Time Series Decomposition","text":""},{"location":"examples/advanced_techniques/#trend-cycle-decomposition-with-hodrick-prescott-filter","title":"Trend-Cycle Decomposition with Hodrick-Prescott Filter","text":"<pre><code>import numpy as np\nimport matplotlib.pyplot as plt\nfrom pypulate import as_parray\n\n# Create sample price data with trend, cycle, and noise\nnp.random.seed(42)\nn_points = 200\n\n# Create trend component\ntrend = np.linspace(100, 200, n_points)\n\n# Create cyclical component (sine wave)\ncycle_period = 40\ncycle = 15 * np.sin(2 * np.pi * np.arange(n_points) / cycle_period)\n\n# Create seasonal component (smaller sine wave)\nseasonal_period = 10\nseasonal = 5 * np.sin(2 * np.pi * np.arange(n_points) / seasonal_period)\n\n# Add random noise\nnoise = np.random.normal(0, 3, n_points)\n\n# Combine components\nprices = trend + cycle + seasonal + noise\n\n# Convert to Parray\nts = as_parray(prices)\n\n# Apply Hodrick-Prescott filter for trend-cycle decomposition\n# Lambda parameter controls smoothness of the trend component\ntrend_component, cycle_component = ts.hodrick_prescott_filter(lambda_param=1600)\n\n# Calculate seasonal and noise components\nseasonal_noise = prices - trend_component\n\nprint(\"Time series decomposition complete\")\n</code></pre>"},{"location":"examples/advanced_techniques/#combining-financial-and-business-metrics","title":"Combining Financial and Business Metrics","text":""},{"location":"examples/advanced_techniques/#integrated-dashboard-for-saas-business","title":"Integrated Dashboard for SaaS Business","text":"<pre><code>import numpy as np\nfrom pypulate import as_parray\nfrom pypulate.kpi import (\n    churn_rate, retention_rate, customer_lifetime_value,\n    customer_acquisition_cost, monthly_recurring_revenue,\n    annual_recurring_revenue, ltv_cac_ratio, payback_period\n)\n\n# Sample data for a SaaS business\nmonths = [\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\"]\n\n# Customer metrics\ncustomers_start = [100, 110, 125, 135, 150, 160]\ncustomers_end = [110, 125, 135, 150, 160, 175]\nnew_customers = [20, 25, 20, 30, 25, 30]\navg_revenue_per_customer = [50, 52, 53, 55, 56, 58]\n\n# Financial metrics\nmarketing_costs = [10000, 12000, 11000, 15000, 14000, 16000]\nsales_costs = [8000, 9000, 8500, 10000, 9500, 11000]\ngross_margin = 70  # 70% gross margin\n\n# Stock price (if public company)\nstock_prices = np.array([25, 26, 28, 27, 30, 32])\n\n# Calculate business KPIs\nbusiness_metrics = {\n    \"Month\": months,\n    \"Churn Rate (%)\": [],\n    \"Retention Rate (%)\": [],\n    \"MRR ($)\": [],\n    \"ARR ($)\": [],\n    \"CAC ($)\": [],\n    \"LTV ($)\": [],\n    \"LTV:CAC Ratio\": [],\n    \"Payback Period (months)\": []\n}\n\nfor i in range(len(months)):\n    # Calculate metrics\n    churn = churn_rate(customers_start[i], customers_end[i], new_customers[i])\n    retention = retention_rate(customers_start[i], customers_end[i], new_customers[i])\n    mrr = monthly_recurring_revenue(customers_end[i], avg_revenue_per_customer[i])\n    arr = annual_recurring_revenue(customers_end[i], avg_revenue_per_customer[i])\n    cac = customer_acquisition_cost(marketing_costs[i], sales_costs[i], new_customers[i])\n    ltv = customer_lifetime_value(avg_revenue_per_customer[i], gross_margin, churn)\n    ratio = ltv_cac_ratio(ltv, cac)\n    payback = payback_period(cac, avg_revenue_per_customer[i], gross_margin)\n\n    # Store metrics\n    business_metrics[\"Churn Rate (%)\"].append(churn)\n    business_metrics[\"Retention Rate (%)\"].append(retention)\n    business_metrics[\"MRR ($)\"].append(mrr)\n    business_metrics[\"ARR ($)\"].append(arr)\n    business_metrics[\"CAC ($)\"].append(cac)\n    business_metrics[\"LTV ($)\"].append(ltv)\n    business_metrics[\"LTV:CAC Ratio\"].append(ratio)\n    business_metrics[\"Payback Period (months)\"].append(payback)\n\n# Convert stock prices to Parray for technical analysis\nstock_ts = as_parray(stock_prices)\n\n# Calculate technical indicators\nstock_sma = stock_ts.sma(3)\nstock_ema = stock_ts.ema(3)\nstock_rsi = stock_ts.rsi(14)\n\n# Print integrated dashboard\nprint(\"=== SaaS Business Dashboard ===\")\nprint(\"\\nBusiness Metrics:\")\nfor i in range(len(months)):\n    print(f\"\\n{months[i]}:\")\n    print(f\"  Churn Rate: {business_metrics['Churn Rate (%)'][i]:.2f}%\")\n    print(f\"  Retention Rate: {business_metrics['Retention Rate (%)'][i]:.2f}%\")\n    print(f\"  MRR: ${business_metrics['MRR ($)'][i]:.2f}\")\n    print(f\"  ARR: ${business_metrics['ARR ($)'][i]:.2f}\")\n    print(f\"  CAC: ${business_metrics['CAC ($)'][i]:.2f}\")\n    print(f\"  LTV: ${business_metrics['LTV ($)'][i]:.2f}\")\n    print(f\"  LTV:CAC Ratio: {business_metrics['LTV:CAC Ratio'][i]:.2f}\")\n    print(f\"  Payback Period: {business_metrics['Payback Period (months)'][i]:.2f} months\")\n\nprint(\"\\nStock Technical Analysis:\")\nfor i in range(len(months)):\n    print(f\"\\n{months[i]}:\")\n    print(f\"  Stock Price: ${stock_prices[i]:.2f}\")\n    if i &gt;= 2:  # Need at least 3 points for SMA\n        print(f\"  SMA(3): ${stock_sma[i]:.2f}\")\n        print(f\"  EMA(3): ${stock_ema[i]:.2f}\")\n    if i &gt;= 13:  # Need at least 14 points for RSI\n        print(f\"  RSI(14): {stock_rsi[i]:.2f}\")\n</code></pre>"},{"location":"examples/basic_usage/","title":"Basic Usage","text":"<p>This guide demonstrates the basic usage of the <code>pypulate</code> package, focusing on the <code>Parray</code> class and various financial analysis methods.</p>"},{"location":"examples/basic_usage/#creating-a-parray","title":"Creating a Parray","text":"<p>The <code>Parray</code> class is a wrapper around NumPy arrays that provides method chaining for financial analysis.</p> <pre><code>import numpy as np\nfrom pypulate import as_parray\n\n# Create sample data\ndata = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n\n# Convert to Parray\nts = as_parray(data)\n</code></pre>"},{"location":"examples/basic_usage/#moving-averages","title":"Moving Averages","text":"<pre><code># Calculate Simple Moving Average\nsma_values = ts.sma(period=3)\n\n# Calculate Exponential Moving Average\nema_values = ts.ema(period=3)\n\n# Chain multiple moving averages\nresult = ts.ema(3).sma(2)\n</code></pre>"},{"location":"examples/basic_usage/#momentum-indicators","title":"Momentum Indicators","text":"<pre><code># Calculate RSI\nrsi_values = ts.rsi(period=14)\n\n# Calculate MACD\nmacd_line, signal_line, histogram = ts.macd()\n\n# Calculate Stochastic Oscillator\nk, d = ts.stochastic_oscillator()\n</code></pre>"},{"location":"examples/basic_usage/#volatility-measurements","title":"Volatility Measurements","text":"<pre><code># Calculate Bollinger Bands\nupper, middle, lower = ts.bollinger_bands(period=20, std_dev=2.0)\n\n# Calculate ATR\natr_values = ts.atr(period=14)\n</code></pre>"},{"location":"examples/basic_usage/#transforms","title":"Transforms","text":"<pre><code># Detect waves\nwaves = ts.wave(min_size=3)\n\n# Apply ZigZag transform\nzigzag_values = ts.zigzag(deviation=5.0, backstep=3)\n</code></pre>"},{"location":"examples/basic_usage/#filters","title":"Filters","text":"<pre><code># Apply Kalman filter\nfiltered_values = ts.kalman_filter()\n\n# Apply Butterworth filter\nfiltered_values = ts.butterworth_filter(cutoff=0.1, order=4, filter_type='lowpass')\n</code></pre>"},{"location":"examples/basic_usage/#utility-functions","title":"Utility Functions","text":"<pre><code># Calculate slope\nslope_values = ts.slope(period=5)\n\n# Calculate rolling statistics\nmax_values = ts.rolling_max(period=14)\nmin_values = ts.rolling_min(period=14)\nstd_values = ts.rolling_std(period=14)\n</code></pre>"},{"location":"examples/basic_usage/#method-chaining","title":"Method Chaining","text":"<p>One of the key features of <code>pypulate</code> is the ability to chain methods together for complex analysis:</p> <pre><code># Chain multiple operations\nresult = (\n    ts\n    .ema(5)                          # Apply 5-period EMA first\n    .rsi(14)                         # Calculate RSI on the EMA\n    .bollinger_bands(20, 2.0)        # Calculate Bollinger Bands on the RSI\n)\n\n# More complex example\nmacd_line, signal, hist = ts.macd()\nstoch_k, stoch_d = ts.stochastic_oscillator()\n\n# Generate signals\nbuy_signals = (\n    (ts.rsi(14) &lt; 30) &amp;                  # RSI oversold\n    (macd_line.crossover(signal)) &amp;      # MACD bullish crossover\n    (stoch_k.crossover(stoch_d))         # Stochastic bullish crossover\n)\n</code></pre>"},{"location":"examples/business_metrics/","title":"Business Metrics Examples","text":"<p>This guide demonstrates various business metrics analysis using the <code>pypulate</code> package.</p>"},{"location":"examples/business_metrics/#customer-metrics","title":"Customer Metrics","text":""},{"location":"examples/business_metrics/#churn-and-retention-analysis","title":"Churn and Retention Analysis","text":"<pre><code>from pypulate.kpi import churn_rate, retention_rate\n\n# Monthly customer data\nmonths = [\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\"]\ncustomers_start = [100, 110, 125, 135, 150, 160]\ncustomers_end = [110, 125, 135, 150, 160, 175]\nnew_customers = [20, 25, 20, 30, 25, 30]\n\n# Calculate churn and retention rates\nchurn_rates = []\nretention_rates = []\n\nfor i in range(len(months)):\n    churn = churn_rate(customers_start[i], customers_end[i], new_customers[i])\n    retention = retention_rate(customers_start[i], customers_end[i], new_customers[i])\n\n    churn_rates.append(churn)\n    retention_rates.append(retention)\n\n    print(f\"{months[i]}: Churn Rate = {churn:.2f}%, Retention Rate = {retention:.2f}%\")\n\n# Average churn and retention\navg_churn = sum(churn_rates) / len(churn_rates)\navg_retention = sum(retention_rates) / len(retention_rates)\n\nprint(f\"Average Churn Rate: {avg_churn:.2f}%\")\nprint(f\"Average Retention Rate: {avg_retention:.2f}%\")\n</code></pre>"},{"location":"examples/business_metrics/#customer-lifetime-value-analysis","title":"Customer Lifetime Value Analysis","text":"<pre><code>from pypulate.kpi import customer_lifetime_value, customer_acquisition_cost, ltv_cac_ratio\n\n# Customer metrics\navg_revenue_per_customer = 100  # $100 per month\ngross_margin = 70               # 70% gross margin\nchurn_rate_value = 5            # 5% monthly churn rate\ndiscount_rate = 10              # 10% annual discount rate\n\n# Marketing and sales costs\nmarketing_costs = 50000         # $50,000 marketing costs\nsales_costs = 30000             # $30,000 sales costs\nnew_customers = 200             # 200 new customers\n\n# Calculate CLV and CAC\nltv = customer_lifetime_value(avg_revenue_per_customer, gross_margin, churn_rate_value, discount_rate)\ncac = customer_acquisition_cost(marketing_costs, sales_costs, new_customers)\nratio = ltv_cac_ratio(ltv, cac)\n\nprint(f\"Customer Lifetime Value (CLV): ${ltv:.2f}\")\nprint(f\"Customer Acquisition Cost (CAC): ${cac:.2f}\")\nprint(f\"LTV:CAC Ratio: {ratio:.2f}\")\n\n# Evaluate business health\nif ratio &gt; 3:\n    print(\"Excellent LTV:CAC ratio (&gt;3)\")\nelif ratio &gt; 1:\n    print(\"Good LTV:CAC ratio (&gt;1)\")\nelse:\n    print(\"Poor LTV:CAC ratio (&lt;1)\")\n</code></pre>"},{"location":"examples/business_metrics/#revenue-metrics","title":"Revenue Metrics","text":""},{"location":"examples/business_metrics/#mrr-and-arr-analysis","title":"MRR and ARR Analysis","text":"<pre><code>from pypulate.kpi import monthly_recurring_revenue, annual_recurring_revenue\n\n# Monthly customer and revenue data\nmonths = [\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\"]\npaying_customers = [100, 110, 125, 135, 150, 160]\navg_revenue = [50, 52, 53, 55, 56, 58]  # Average revenue per customer\n\n# Calculate MRR and ARR\nmrr_values = []\narr_values = []\n\nfor i in range(len(months)):\n    mrr = monthly_recurring_revenue(paying_customers[i], avg_revenue[i])\n    arr = annual_recurring_revenue(paying_customers[i], avg_revenue[i])\n\n    mrr_values.append(mrr)\n    arr_values.append(arr)\n\n    print(f\"{months[i]}: MRR = ${mrr:.2f}, ARR = ${arr:.2f}\")\n\n# MRR growth\nmrr_growth = [(mrr_values[i] - mrr_values[i-1]) / mrr_values[i-1] * 100 for i in range(1, len(mrr_values))]\navg_mrr_growth = sum(mrr_growth) / len(mrr_growth)\n\nprint(f\"Average Monthly MRR Growth: {avg_mrr_growth:.2f}%\")\n</code></pre>"},{"location":"examples/business_metrics/#revenue-churn-and-expansion-analysis","title":"Revenue Churn and Expansion Analysis","text":"<pre><code>from pypulate.kpi import revenue_churn_rate, expansion_revenue_rate\n\n# Monthly revenue data\nmonths = [\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\"]\nrevenue_start = [5000, 5500, 6000, 6600, 7200, 7800]\nrevenue_end = [5500, 6000, 6600, 7200, 7800, 8500]\nnew_revenue = [800, 900, 1000, 1100, 1200, 1300]\nupsell_revenue = [200, 250, 300, 350, 400, 450]\ncross_sell_revenue = [100, 120, 150, 180, 200, 250]\n\n# Calculate revenue churn and expansion rates\nrevenue_churn_rates = []\nexpansion_rates = []\n\nfor i in range(len(months)):\n    rev_churn = revenue_churn_rate(revenue_start[i], revenue_end[i], new_revenue[i])\n    expansion = expansion_revenue_rate(upsell_revenue[i], cross_sell_revenue[i], revenue_start[i])\n\n    revenue_churn_rates.append(rev_churn)\n    expansion_rates.append(expansion)\n\n    print(f\"{months[i]}: Revenue Churn = {rev_churn:.2f}%, Expansion = {expansion:.2f}%\")\n\n# Net revenue retention\nnet_retention = [(revenue_end[i] - new_revenue[i]) / revenue_start[i] * 100 for i in range(len(months))]\navg_net_retention = sum(net_retention) / len(net_retention)\n\nprint(f\"Average Net Revenue Retention: {avg_net_retention:.2f}%\")\n</code></pre>"},{"location":"examples/business_metrics/#user-engagement-metrics","title":"User Engagement Metrics","text":""},{"location":"examples/business_metrics/#customer-satisfaction-and-effort-analysis","title":"Customer Satisfaction and Effort Analysis","text":"<pre><code>from pypulate.kpi import customer_satisfaction_score, customer_effort_score, net_promoter_score\nimport numpy as np\n\n# Sample survey data\ncsat_ratings = np.array([4, 5, 3, 5, 4, 5, 4, 3, 5, 4])  # 1-5 scale\nces_ratings = np.array([2, 3, 1, 2, 4, 2, 3, 2, 1, 2])   # 1-7 scale (lower is better)\n\n# NPS data\npromoters = 70      # Customers who rated 9-10\ndetractors = 10     # Customers who rated 0-6\npassives = 20       # Customers who rated 7-8\ntotal_respondents = promoters + passives + detractors\n\n# Calculate satisfaction metrics\ncsat = customer_satisfaction_score(csat_ratings, max_rating=5)\nces = customer_effort_score(ces_ratings, max_rating=7)\nnps = net_promoter_score(promoters, detractors, total_respondents)\n\nprint(f\"Customer Satisfaction Score (CSAT): {csat:.2f}%\")\nprint(f\"Customer Effort Score (CES): {ces:.2f}\")\nprint(f\"Net Promoter Score (NPS): {nps:.2f}\")\n\n# Evaluate customer satisfaction\nif csat &gt; 80:\n    print(\"Excellent CSAT (&gt;80%)\")\nelif csat &gt; 70:\n    print(\"Good CSAT (&gt;70%)\")\nelse:\n    print(\"Poor CSAT (&lt;70%)\")\n</code></pre>"},{"location":"examples/business_metrics/#user-activity-analysis","title":"User Activity Analysis","text":"<pre><code>from pypulate.kpi import daily_active_users_ratio, monthly_active_users_ratio, stickiness_ratio\n\n# Monthly user activity data\nmonths = [\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\"]\ntotal_users = [2000, 2200, 2500, 2800, 3100, 3500]\nmonthly_active_users = [1500, 1700, 2000, 2300, 2600, 3000]\ndaily_active_users = [500, 600, 700, 800, 900, 1100]\n\n# Calculate user activity metrics\ndau_ratios = []\nmau_ratios = []\nstickiness_ratios = []\n\nfor i in range(len(months)):\n    dau_ratio = daily_active_users_ratio(daily_active_users[i], total_users[i])\n    mau_ratio = monthly_active_users_ratio(monthly_active_users[i], total_users[i])\n    stickiness = stickiness_ratio(daily_active_users[i], monthly_active_users[i])\n\n    dau_ratios.append(dau_ratio)\n    mau_ratios.append(mau_ratio)\n    stickiness_ratios.append(stickiness)\n\n    print(f\"{months[i]}: DAU Ratio = {dau_ratio:.2f}%, MAU Ratio = {mau_ratio:.2f}%, Stickiness = {stickiness:.2f}%\")\n\n# Average stickiness\navg_stickiness = sum(stickiness_ratios) / len(stickiness_ratios)\nprint(f\"Average Stickiness Ratio: {avg_stickiness:.2f}%\")\n</code></pre>"},{"location":"examples/business_metrics/#financial-health-metrics","title":"Financial Health Metrics","text":""},{"location":"examples/business_metrics/#burn-rate-and-runway-analysis","title":"Burn Rate and Runway Analysis","text":"<pre><code>from pypulate.kpi import burn_rate, runway, gross_margin\n\n# Financial data\nstarting_capital = 1000000  # $1,000,000 starting capital\nending_capital = 700000     # $700,000 ending capital\nmonths = 6                  # 6 months period\ncurrent_capital = 700000    # $700,000 current capital\n\n# Revenue and costs\nrevenue = 150000            # $150,000 revenue\ncost_of_goods_sold = 45000  # $45,000 COGS\n\n# Calculate financial health metrics\nmonthly_burn = burn_rate(starting_capital, ending_capital, months)\nrunway_months = runway(current_capital, monthly_burn)\ngm = gross_margin(revenue, cost_of_goods_sold)\n\nprint(f\"Monthly Burn Rate: ${monthly_burn:.2f}\")\nprint(f\"Runway: {runway_months:.2f} months\")\nprint(f\"Gross Margin: {gm:.2f}%\")\n\n# Evaluate financial health\nif runway_months &gt; 18:\n    print(\"Healthy runway (&gt;18 months)\")\nelif runway_months &gt; 12:\n    print(\"Adequate runway (&gt;12 months)\")\nelse:\n    print(\"Concerning runway (&lt;12 months)\")\n</code></pre>"},{"location":"examples/business_metrics/#growth-metrics","title":"Growth Metrics","text":""},{"location":"examples/business_metrics/#conversion-and-virality-analysis","title":"Conversion and Virality Analysis","text":"<pre><code>from pypulate.kpi import conversion_rate, virality_coefficient, feature_adoption_rate\n\n# Growth data\nmonths = [\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\"]\ntotal_visitors = [10000, 12000, 15000, 18000, 22000, 25000]\nconversions = [500, 650, 800, 1000, 1300, 1500]\nnew_users = [400, 500, 600, 800, 1000, 1200]\ninvites_sent = [2000, 2500, 3000, 3500, 4000, 5000]\ntotal_users = [2000, 2400, 2900, 3500, 4300, 5300]\nusers_adopting_feature = [600, 800, 1000, 1400, 1800, 2300]\n\n# Calculate growth metrics\nconversion_rates = []\nvirality_coefficients = []\nfeature_adoption_rates = []\n\nfor i in range(len(months)):\n    conv_rate = conversion_rate(conversions[i], total_visitors[i])\n    virality = virality_coefficient(new_users[i], invites_sent[i], total_users[i])\n    feature_adoption = feature_adoption_rate(users_adopting_feature[i], total_users[i])\n\n    conversion_rates.append(conv_rate)\n    virality_coefficients.append(virality)\n    feature_adoption_rates.append(feature_adoption)\n\n    print(f\"{months[i]}: Conversion = {conv_rate:.2f}%, Virality = {virality:.2f}, Feature Adoption = {feature_adoption:.2f}%\")\n\n# Evaluate virality\navg_virality = sum(virality_coefficients) / len(virality_coefficients)\nif avg_virality &gt; 1:\n    print(\"Viral growth (coefficient &gt; 1)\")\nelse:\n    print(\"Non-viral growth (coefficient &lt; 1)\")\n</code></pre>"},{"location":"examples/financial_analysis/","title":"Financial Analysis Examples","text":"<p>This guide demonstrates various financial analysis strategies using the <code>pypulate</code> package.</p>"},{"location":"examples/financial_analysis/#technical-analysis","title":"Technical Analysis","text":""},{"location":"examples/financial_analysis/#moving-average-crossover-strategy","title":"Moving Average Crossover Strategy","text":"<pre><code>import numpy as np\nfrom pypulate import as_parray\n\n# Create sample price data\nprices = np.array([100, 102, 104, 103, 105, 107, 108, 107, 105, 104, 103, 105, 107, 109, 108])\n\n# Convert to Parray\nts = as_parray(prices)\n\n# Calculate fast and slow moving averages\nfast_ma = ts.ema(5)\nslow_ma = ts.ema(10)\n\n# Generate crossover signals\nbuy_signals = fast_ma.crossover(slow_ma)\nsell_signals = fast_ma.crossunder(slow_ma)\n\nprint(\"Buy signals:\", buy_signals)\nprint(\"Sell signals:\", sell_signals)\n</code></pre>"},{"location":"examples/financial_analysis/#rsi-overboughtoversold-strategy","title":"RSI Overbought/Oversold Strategy","text":"<pre><code># Calculate RSI\nrsi_values = ts.rsi(14)\n\n# Generate signals\nbuy_signals = rsi_values &lt; 30  # Oversold\nsell_signals = rsi_values &gt; 70  # Overbought\n\nprint(\"Buy signals (oversold):\", buy_signals)\nprint(\"Sell signals (overbought):\", sell_signals)\n</code></pre>"},{"location":"examples/financial_analysis/#macd-strategy","title":"MACD Strategy","text":"<pre><code># Calculate MACD\nmacd_line, signal_line, histogram = ts.macd()\n\n# Generate signals\nbuy_signals = macd_line.crossover(signal_line)\nsell_signals = macd_line.crossunder(signal_line)\n\nprint(\"Buy signals (MACD crossover):\", buy_signals)\nprint(\"Sell signals (MACD crossunder):\", sell_signals)\n</code></pre>"},{"location":"examples/financial_analysis/#bollinger-bands-strategy","title":"Bollinger Bands Strategy","text":"<pre><code># Calculate Bollinger Bands\nupper, middle, lower = ts.bollinger_bands(20, 2.0)\n\n# Generate signals\nbuy_signals = ts &lt; lower  # Price below lower band\nsell_signals = ts &gt; upper  # Price above upper band\n\nprint(\"Buy signals (price below lower band):\", buy_signals)\nprint(\"Sell signals (price above upper band):\", sell_signals)\n</code></pre>"},{"location":"examples/financial_analysis/#volatility-analysis","title":"Volatility Analysis","text":""},{"location":"examples/financial_analysis/#atr-based-position-sizing","title":"ATR-Based Position Sizing","text":"<pre><code># Calculate ATR\natr_values = ts.atr(14)\n\n# Define risk parameters\naccount_size = 10000  # $10,000 account\nrisk_percentage = 0.02  # 2% risk per trade\nrisk_amount = account_size * risk_percentage  # $200 risk per trade\n\n# Calculate position size based on ATR\ncurrent_price = prices[-1]\ncurrent_atr = atr_values[-1]\nstop_loss_distance = 2 * current_atr  # 2 ATR units for stop loss\n\n# Position size calculation\nposition_size = risk_amount / stop_loss_distance\nposition_value = position_size * current_price\n\nprint(f\"Current price: ${current_price}\")\nprint(f\"Current ATR: ${current_atr}\")\nprint(f\"Stop loss distance: ${stop_loss_distance}\")\nprint(f\"Position size: {position_size} shares\")\nprint(f\"Position value: ${position_value}\")\n</code></pre>"},{"location":"examples/financial_analysis/#volatility-regime-detection","title":"Volatility Regime Detection","text":"<pre><code># Calculate historical volatility\nhist_vol = ts.historical_volatility(21, 252)\n\n# Define volatility regimes\nlow_vol = hist_vol &lt; 15  # Less than 15% annualized volatility\nmedium_vol = (hist_vol &gt;= 15) &amp; (hist_vol &lt; 30)\nhigh_vol = hist_vol &gt;= 30  # More than 30% annualized volatility\n\nprint(\"Low volatility regime:\", low_vol)\nprint(\"Medium volatility regime:\", medium_vol)\nprint(\"High volatility regime:\", high_vol)\n</code></pre>"},{"location":"examples/financial_analysis/#multi-indicator-strategy","title":"Multi-Indicator Strategy","text":"<pre><code># Create a more complex strategy combining multiple indicators\ncomplex_buy_signals = (\n    (ts.rsi(14) &lt; 30) &amp;                          # RSI oversold\n    (ts.macd()[0].crossover(ts.macd()[1])) &amp;     # MACD bullish crossover\n    (ts &lt; ts.bollinger_bands(20, 2.0)[2])        # Price below lower Bollinger Band\n)\n\ncomplex_sell_signals = (\n    (ts.rsi(14) &gt; 70) &amp;                          # RSI overbought\n    (ts.macd()[0].crossunder(ts.macd()[1])) &amp;    # MACD bearish crossunder\n    (ts &gt; ts.bollinger_bands(20, 2.0)[0])        # Price above upper Bollinger Band\n)\n\nprint(\"Complex buy signals:\", complex_buy_signals)\nprint(\"Complex sell signals:\", complex_sell_signals)\n</code></pre>"},{"location":"examples/financial_analysis/#backtesting-simplified","title":"Backtesting (Simplified)","text":"<pre><code># Simplified backtesting example\ndef simple_backtest(prices, buy_signals, sell_signals):\n    cash = 10000  # Initial cash\n    shares = 0    # Initial shares\n    position_value = 0\n\n    for i in range(len(prices)):\n        if buy_signals[i] and cash &gt; 0:\n            # Buy as many shares as possible\n            shares = cash / prices[i]\n            cash = 0\n            print(f\"Day {i}: BUY at ${prices[i]}, Shares: {shares}\")\n\n        elif sell_signals[i] and shares &gt; 0:\n            # Sell all shares\n            cash = shares * prices[i]\n            shares = 0\n            print(f\"Day {i}: SELL at ${prices[i]}, Cash: ${cash}\")\n\n        # Calculate current position value\n        position_value = cash + (shares * prices[i])\n\n    return position_value\n\n# Generate signals for backtest\nsma_fast = ts.sma(5)\nsma_slow = ts.sma(10)\nbuy_signals = sma_fast.crossover(sma_slow)\nsell_signals = sma_fast.crossunder(sma_slow)\n\n# Run backtest\nfinal_value = simple_backtest(prices, buy_signals, sell_signals)\nprint(f\"Final portfolio value: ${final_value}\")\n</code></pre>"},{"location":"user-guide/allocation/","title":"Portfolio Allocation Examples","text":"<p>This document demonstrates various portfolio optimization methods available in the <code>pypulate</code> library using the <code>Allocation</code> class.</p>"},{"location":"user-guide/allocation/#overview","title":"Overview","text":"<p>The <code>Allocation</code> class provides several portfolio optimization methods:</p> <ol> <li>Mean-Variance Optimization</li> <li>Minimum Variance Portfolio</li> <li>Maximum Sharpe Ratio Portfolio</li> <li>Risk Parity Portfolio</li> <li>Maximum Diversification Portfolio</li> <li>Equal Weight Portfolio</li> <li>Market Cap Weight Portfolio</li> <li>Kelly Criterion Portfolio</li> <li>Black-Litterman Portfolio</li> <li>Hierarchical Risk Parity Portfolio</li> </ol>"},{"location":"user-guide/allocation/#basic-usage","title":"Basic Usage","text":"<p>First, let's import the necessary components:</p> <pre><code>from pypulate import Allocation, Parray\n</code></pre>"},{"location":"user-guide/allocation/#basic-portfolio-optimization","title":"Basic Portfolio Optimization","text":"<p>Let's start with a simple example using 3 assets:</p> <pre><code># Sample returns data (3 assets, 252 days of daily returns)\nreturns = Parray([\n    # Asset 1 (e.g., AAPL)\n    [0.02, -0.01, 0.015, 0.03, -0.005, 0.01, 0.02, -0.015, 0.025, 0.01] + \n    [0.015, -0.02, 0.01, 0.02, -0.01, 0.015, 0.025, -0.01, 0.02, 0.015] * 24 + \n    [0.015, -0.02, 0.01, 0.02, -0.01, 0.015, 0.025, -0.01, 0.02, 0.015],\n\n    # Asset 2 (e.g., MSFT)\n    [0.015, 0.02, -0.01, 0.025, 0.01, -0.015, 0.02, 0.01, -0.02, 0.015] + \n    [0.02, -0.015, 0.015, 0.025, -0.01, 0.02, 0.015, -0.015, 0.02, 0.01] * 24 + \n    [0.02, -0.015, 0.015, 0.025, -0.01, 0.02, 0.015, -0.015, 0.02, 0.01],\n\n    # Asset 3 (e.g., GOOGL)\n    [0.025, -0.02, 0.02, 0.015, -0.015, 0.02, 0.025, -0.02, 0.03, 0.02] + \n    [0.025, -0.02, 0.02, 0.015, -0.015, 0.02, 0.025, -0.02, 0.03, 0.02] * 24 + \n    [0.025, -0.02, 0.02, 0.015, -0.015, 0.02, 0.025, -0.02, 0.03, 0.02]\n]).T\n\n# Initialize the Allocation class\nallocation = Allocation()\n\n# Set risk-free rate (e.g., current 10-year Treasury yield)\nrisk_free_rate = 0.04  # 4% annual rate\n\n# Perform Mean-Variance Optimization\nweights, ret, risk = allocation.mean_variance(\n    returns=returns,\n    target_return=None,  # Maximize Sharpe ratio\n    risk_free_rate=risk_free_rate\n)\n\nprint(f\"Optimal Portfolio Weights: {weights}\")\nprint(f\"Expected Return: {ret:.4f}\")\nprint(f\"Portfolio Risk: {risk:.4f}\")\n</code></pre>"},{"location":"user-guide/allocation/#risk-parity-portfolio","title":"Risk Parity Portfolio","text":"<p>Risk Parity aims to equalize the risk contribution of each asset:</p> <pre><code># Calculate Risk Parity weights\nweights, ret, risk = allocation.risk_parity(returns=returns)\n\nprint(f\"Risk Parity Weights: {weights}\")\nprint(f\"Expected Return: {ret:.4f}\")\nprint(f\"Portfolio Risk: {risk:.4f}\")\n</code></pre>"},{"location":"user-guide/allocation/#kelly-criterion-with-conservative-sizing","title":"Kelly Criterion with Conservative Sizing","text":"<p>The Kelly Criterion can be aggressive, so we often use a fraction of the optimal weights:</p> <pre><code># Calculate Kelly Criterion weights\nweights, ret, risk = allocation.kelly_criterion(\n    returns=returns,\n    risk_free_rate=risk_free_rate\n)\n\n# Use half-Kelly for more conservative position sizing\nhalf_kelly_weights = weights * 0.5\n\nprint(f\"Full Kelly Weights: {weights}\")\nprint(f\"Half-Kelly Weights: {half_kelly_weights}\")\n</code></pre>"},{"location":"user-guide/allocation/#black-litterman-portfolio-with-views","title":"Black-Litterman Portfolio with Views","text":"<p>Black-Litterman allows incorporating market views into the optimization:</p> <pre><code># Market capitalizations\nmarket_caps = Parray([2.5e12, 2.8e12, 1.8e12])  # in USD\n\n# Define views (e.g., AAPL to outperform by 2%, GOOGL to underperform by 1%)\nviews = {0: 0.02, 2: -0.01}  # Asset indices and expected excess returns\nview_confidences = {0: 0.8, 2: 0.7}  # Confidence in views (0-1)\n\n# Calculate Black-Litterman weights\nweights, ret, risk = allocation.black_litterman(\n    returns=returns,\n    market_caps=market_caps,\n    views=views,\n    view_confidences=view_confidences,\n    tau=0.05,  # Uncertainty in the prior distribution\n    risk_free_rate=risk_free_rate\n)\n\nprint(f\"Black-Litterman Weights: {weights}\")\n</code></pre>"},{"location":"user-guide/allocation/#hierarchical-risk-parity","title":"Hierarchical Risk Parity","text":"<p>HRP uses hierarchical clustering to build a more robust portfolio:</p> <pre><code># Calculate HRP weights\nweights, ret, risk = allocation.hierarchical_risk_parity(\n    returns=returns,\n    linkage_method='ward',  # Using Ward linkage for clustering\n    distance_metric='correlation'  # Using correlation-based distance\n)\n\nprint(f\"HRP Weights: {weights}\")\n</code></pre>"},{"location":"user-guide/allocation/#comparing-different-methods","title":"Comparing Different Methods","text":"<p>Here's how to compare the performance of different optimization methods:</p> <pre><code># Define methods to compare\nmethods = [\n    (\"Mean-Variance\", allocation.mean_variance(returns, risk_free_rate=risk_free_rate)),\n    (\"Minimum Variance\", allocation.minimum_variance(returns)),\n    (\"Maximum Sharpe\", allocation.maximum_sharpe(returns, risk_free_rate=risk_free_rate)),\n    (\"Risk Parity\", allocation.risk_parity(returns)),\n    (\"Kelly Criterion\", allocation.kelly_criterion(returns, risk_free_rate=risk_free_rate))\n]\n\n# Compare results\nprint(\"\\nMethod Comparison Summary:\")\nprint(\"-\" * 50)\nprint(f\"{'Method':&lt;25} {'Return':&gt;10} {'Risk':&gt;10} {'Sharpe':&gt;10}\")\nprint(\"-\" * 50)\nfor method_name, (weights, ret, risk) in methods:\n    sharpe = (ret - risk_free_rate) / risk\n    print(f\"{method_name:&lt;25} {ret*100:&gt;9.2f}% {risk*100:&gt;9.2f}% {sharpe:&gt;9.2f}\")\n</code></pre>"},{"location":"user-guide/allocation/#best-practices","title":"Best Practices","text":""},{"location":"user-guide/allocation/#1-data-preparation","title":"1. Data Preparation","text":"<ul> <li>1.1. Data Quality: Use clean, adjusted price data</li> <li>1.2. Missing Values: Handle missing values appropriately</li> <li>1.3. Transaction Costs: Consider transaction costs and liquidity</li> </ul>"},{"location":"user-guide/allocation/#2-risk-management","title":"2. Risk Management","text":"<ul> <li>2.1. Position Sizing: Consider using half-Kelly or quarter-Kelly for more conservative position sizing</li> <li>2.2. Constraints: Implement position limits and constraints</li> <li>2.3. Monitoring: Monitor portfolio turnover and rebalancing needs</li> </ul>"},{"location":"user-guide/allocation/#3-method-selection","title":"3. Method Selection","text":"<ul> <li>3.1. Mean-Variance: Good for traditional portfolio optimization</li> <li>3.2. Risk Parity: Better for risk management</li> <li>3.3. Kelly Criterion: Best for long-term growth</li> <li>3.4. Black-Litterman: Ideal when you have strong market views</li> <li>3.5. HRP: More robust to estimation errors</li> </ul>"},{"location":"user-guide/allocation/#4-portfolio-maintenance","title":"4. Portfolio Maintenance","text":"<ul> <li>4.1. Rebalancing Thresholds: Set appropriate rebalancing thresholds</li> <li>4.2. Cost Management: Consider transaction costs when rebalancing</li> <li>4.3. Tracking Error: Monitor tracking error against benchmarks</li> </ul>"},{"location":"user-guide/allocation/#common-pitfalls","title":"Common Pitfalls","text":""},{"location":"user-guide/allocation/#1-estimation-issues","title":"1. Estimation Issues","text":"<ul> <li>1.1. Overfitting: Use sufficient historical data</li> <li>1.2. Sample Bias: Consider using rolling windows</li> <li>1.3. Validation: Implement out-of-sample testing</li> </ul>"},{"location":"user-guide/allocation/#2-statistical-challenges","title":"2. Statistical Challenges","text":"<ul> <li>2.1. Estimation Error: Use robust estimation methods</li> <li>2.2. Shrinkage: Consider shrinkage estimators</li> <li>2.3. Regularization: Implement proper regularization</li> </ul>"},{"location":"user-guide/allocation/#3-implementation-realities","title":"3. Implementation Realities","text":"<ul> <li>3.1. Bid-Ask Spreads: Account for bid-ask spreads</li> <li>3.2. Market Impact: Consider market impact of trades</li> <li>3.3. Turnover Constraints: Implement turnover constraints</li> </ul>"},{"location":"user-guide/credit-scoring/","title":"Credit Scoring and Risk Assessment","text":"<p>This document demonstrates the credit scoring and risk assessment capabilities available in the <code>pypulate</code> library using the <code>CreditScoring</code> class.</p>"},{"location":"user-guide/credit-scoring/#overview","title":"Overview","text":"<p>The <code>CreditScoring</code> class provides a comprehensive suite of credit risk models and assessment tools:</p> <ol> <li>Altman Z-Score for bankruptcy prediction</li> <li>Merton Model for default probability</li> <li>Debt Service Coverage Ratio (DSCR)</li> <li>Weight of Evidence (WOE) and Information Value (IV)</li> <li>Logistic Regression Scoring</li> <li>Credit Scorecard Creation</li> <li>Credit Rating Transition Matrix</li> <li>Financial Ratios Analysis</li> <li>Expected Credit Loss (ECL) Calculation</li> <li>Risk-Based Loan Pricing</li> <li>Scoring Model Validation</li> <li>Loss Given Default (LGD) Estimation</li> <li>Exposure at Default (EAD) Calculation</li> </ol>"},{"location":"user-guide/credit-scoring/#basic-usage","title":"Basic Usage","text":"<p>First, let's import the necessary components:</p> <pre><code>from pypulate import CreditScoring\n</code></pre>"},{"location":"user-guide/credit-scoring/#corporate-credit-risk-assessment","title":"Corporate Credit Risk Assessment","text":"<p>Let's start with a basic corporate credit risk assessment using the Altman Z-Score model:</p> <pre><code># Initialize the CreditScoring class\ncredit = CreditScoring()\n\n# Company financial data\nworking_capital = 1200000\nretained_earnings = 1500000\nebit = 800000\nmarket_value_equity = 5000000\nsales = 4500000\ntotal_assets = 6000000\ntotal_liabilities = 2500000\n\n# Calculate Altman Z-Score\nz_score_result = credit.altman_z_score(\n    working_capital=working_capital,\n    retained_earnings=retained_earnings,\n    ebit=ebit,\n    market_value_equity=market_value_equity,\n    sales=sales,\n    total_assets=total_assets,\n    total_liabilities=total_liabilities\n)\n\nprint(f\"Altman Z-Score: {z_score_result['z_score']:.2f}\")\nprint(f\"Risk Assessment: {z_score_result['risk_assessment']}\")\n</code></pre>"},{"location":"user-guide/credit-scoring/#default-probability-estimation","title":"Default Probability Estimation","text":"<p>The Merton model provides a structural approach to estimating default probability:</p> <pre><code># Company data for Merton model\nasset_value = 10000000\ndebt_face_value = 5000000\nasset_volatility = 0.25\nrisk_free_rate = 0.03\ntime_to_maturity = 1.0\n\n# Calculate default probability using Merton model\nmerton_result = credit.merton_model(\n    asset_value=asset_value,\n    debt_face_value=debt_face_value,\n    asset_volatility=asset_volatility,\n    risk_free_rate=risk_free_rate,\n    time_to_maturity=time_to_maturity\n)\n\nprint(f\"Probability of Default: {merton_result['probability_of_default']:.2%}\")\nprint(f\"Distance to Default: {merton_result['distance_to_default']:.2f}\")\n</code></pre>"},{"location":"user-guide/credit-scoring/#debt-servicing-capacity","title":"Debt Servicing Capacity","text":"<p>The Debt Service Coverage Ratio helps assess a borrower's ability to service debt:</p> <pre><code># Debt service data\nnet_operating_income = 500000\ntotal_debt_service = 300000\n\n# Calculate DSCR\ndscr_result = credit.debt_service_coverage_ratio(\n    net_operating_income=net_operating_income,\n    total_debt_service=total_debt_service\n)\n\nprint(f\"DSCR: {dscr_result['dscr']:.2f}\")\nprint(f\"Assessment: {dscr_result['assessment']}\")\n</code></pre>"},{"location":"user-guide/credit-scoring/#credit-scorecard-development","title":"Credit Scorecard Development","text":"<p>Create a points-based credit scorecard for retail lending:</p> <pre><code># Applicant features\nfeatures = {\n    \"age\": 35,\n    \"income\": 75000,\n    \"years_employed\": 5,\n    \"debt_to_income\": 0.3,\n    \"previous_defaults\": 0\n}\n\n# Feature weights (derived from statistical analysis)\nweights = {\n    \"age\": 2.5,\n    \"income\": 3.2,\n    \"years_employed\": 4.0,\n    \"debt_to_income\": -5.5,\n    \"previous_defaults\": -25.0\n}\n\n# Feature offsets (reference points)\noffsets = {\n    \"age\": 25,\n    \"income\": 50000,\n    \"years_employed\": 2,\n    \"debt_to_income\": 0.4,\n    \"previous_defaults\": 1\n}\n\n# Create scorecard\nscorecard_result = credit.create_scorecard(\n    features=features,\n    weights=weights,\n    offsets=offsets,\n    scaling_factor=20,\n    base_score=600\n)\n\nprint(f\"Total Credit Score: {scorecard_result['total_score']:.0f}\")\nprint(f\"Risk Category: {scorecard_result['risk_category']}\")\nprint(\"\\nPoints Breakdown:\")\nfor feature, points in scorecard_result['points_breakdown'].items():\n    print(f\"  {feature}: {points:.0f} points\")\n</code></pre>"},{"location":"user-guide/credit-scoring/#expected-credit-loss-calculation","title":"Expected Credit Loss Calculation","text":"<p>Calculate the expected credit loss for a loan:</p> <pre><code># Loan risk parameters\npd = 0.05  # Probability of default\nlgd = 0.4  # Loss given default\nead = 100000  # Exposure at default\ntime_horizon = 1.0  # 1 year\ndiscount_rate = 0.03  # 3% discount rate\n\n# Calculate ECL\necl_result = credit.expected_credit_loss(\n    pd=pd,\n    lgd=lgd,\n    ead=ead,\n    time_horizon=time_horizon,\n    discount_rate=discount_rate\n)\n\nprint(f\"Expected Credit Loss: ${ecl_result['ecl']:.2f}\")\nprint(f\"ECL as % of Exposure: {ecl_result['ecl_percentage']:.2%}\")\n</code></pre>"},{"location":"user-guide/credit-scoring/#risk-based-loan-pricing","title":"Risk-Based Loan Pricing","text":"<p>Determine the appropriate interest rate for a loan based on risk:</p> <pre><code># Loan and risk parameters\nloan_amount = 250000\nterm = 5  # 5 years\npd = 0.03  # Annual probability of default\nlgd = 0.35  # Loss given default\nfunding_cost = 0.04  # Cost of funds\noperating_cost = 0.01  # Operating costs as % of loan\ncapital_requirement = 0.08  # Capital requirement\ntarget_roe = 0.15  # Target return on equity\n\n# Calculate loan pricing\npricing_result = credit.loan_pricing(\n    loan_amount=loan_amount,\n    term=term,\n    pd=pd,\n    lgd=lgd,\n    funding_cost=funding_cost,\n    operating_cost=operating_cost,\n    capital_requirement=capital_requirement,\n    target_roe=target_roe\n)\n\nprint(f\"Recommended Interest Rate: {pricing_result['recommended_rate']:.2%}\")\nprint(f\"Effective Annual Rate: {pricing_result['effective_annual_rate']:.2%}\")\nprint(\"\\nRate Components:\")\nfor component, value in pricing_result['components'].items():\n    print(f\"  {component}: {value:.2%}\")\n</code></pre>"},{"location":"user-guide/credit-scoring/#credit-rating-transition-analysis","title":"Credit Rating Transition Analysis","text":"<p>Analyze how credit ratings migrate over time:</p> <pre><code># Historical credit ratings data\nratings_t0 = ['AAA', 'AA', 'A', 'BBB', 'BB', 'A', 'BBB', 'BB', 'B', 'CCC']  # Initial ratings\nratings_t1 = ['AA', 'A', 'BBB', 'BB', 'B', 'A', 'BBB', 'CCC', 'CCC', 'D']   # Ratings after 1 year\n\n# Calculate transition matrix\ntransition_result = credit.transition_matrix(\n    ratings_t0=ratings_t0,\n    ratings_t1=ratings_t1\n)\n\nprint(\"Credit Rating Transition Matrix (Probabilities):\")\nprob_matrix = transition_result['probability_matrix']\nratings = transition_result['ratings']\n\n# Print the matrix with proper formatting\nprint(f\"{'':5}\", end=\"\")\nfor r in ratings:\n    print(f\"{r:6}\", end=\"\")\nprint()\n\nfor i, row in enumerate(prob_matrix):\n    print(f\"{ratings[i]:5}\", end=\"\")\n    for val in row:\n        print(f\"{val:.2f}  \", end=\"\")\n    print()\n</code></pre>"},{"location":"user-guide/credit-scoring/#financial-ratios-analysis","title":"Financial Ratios Analysis","text":"<p>Analyze a company's financial health through key ratios:</p> <pre><code># Company financial data\ncurrent_assets = 2000000\ncurrent_liabilities = 1200000\ntotal_assets = 8000000\ntotal_liabilities = 4000000\nebit = 1200000\ninterest_expense = 300000\nnet_income = 700000\ntotal_equity = 4000000\nsales = 6000000\n\n# Calculate financial ratios\nratios_result = credit.financial_ratios(\n    current_assets=current_assets,\n    current_liabilities=current_liabilities,\n    total_assets=total_assets,\n    total_liabilities=total_liabilities,\n    ebit=ebit,\n    interest_expense=interest_expense,\n    net_income=net_income,\n    total_equity=total_equity,\n    sales=sales\n)\n\nprint(\"Key Financial Ratios:\")\nfor category, ratios in ratios_result.items():\n    if category != 'overall_assessment':\n        print(f\"\\n{category.replace('_', ' ').title()}:\")\n        for ratio_name, value in ratios.items():\n            if ratio_name != 'assessment':\n                print(f\"  {ratio_name.replace('_', ' ').title()}: {value:.2f}\")\n        print(f\"  Assessment: {ratios['assessment']}\")\n\nprint(f\"\\nOverall Financial Health: {ratios_result['overall_assessment']}\")\n</code></pre>"},{"location":"user-guide/credit-scoring/#scoring-model-validation","title":"Scoring Model Validation","text":"<p>Validate the performance of a credit scoring model:</p> <pre><code>import numpy as np\n\n# Simulated data: predicted scores and actual defaults\nnp.random.seed(42)\nnum_samples = 1000\npredicted_scores = np.random.normal(650, 100, num_samples)\n# Higher scores should correspond to lower default probability\ndefault_probs = 1 / (1 + np.exp((predicted_scores - 600) / 50))\nactual_defaults = np.random.binomial(1, default_probs)\n\n# Validate the scoring model\nvalidation_result = credit.scoring_model_validation(\n    predicted_scores=predicted_scores,\n    actual_defaults=actual_defaults,\n    score_bins=10\n)\n\nprint(f\"Gini Coefficient: {validation_result['gini']:.4f}\")\nprint(f\"KS Statistic: {validation_result['ks']:.4f}\")\nprint(f\"AUC-ROC: {validation_result['auc']:.4f}\")\nprint(f\"Accuracy: {validation_result['accuracy']:.4f}\")\n</code></pre>"},{"location":"user-guide/credit-scoring/#loss-given-default-estimation","title":"Loss Given Default Estimation","text":"<p>Estimate the loss given default for a secured loan:</p> <pre><code># Loan and collateral data\ncollateral_value = 180000\nloan_amount = 200000\nliquidation_costs = 0.15\ntime_to_recovery = 1.5\n\n# Calculate LGD\nlgd_result = credit.loss_given_default(\n    collateral_value=collateral_value,\n    loan_amount=loan_amount,\n    liquidation_costs=liquidation_costs,\n    time_to_recovery=time_to_recovery\n)\n\nprint(f\"Loss Given Default: {lgd_result['lgd']:.2%}\")\nprint(f\"Recovery Rate: {lgd_result['recovery_rate']:.2%}\")\nprint(f\"Expected Loss Amount: ${lgd_result['expected_loss']:.2f}\")\n</code></pre>"},{"location":"user-guide/credit-scoring/#exposure-at-default-calculation","title":"Exposure at Default Calculation","text":"<p>Calculate the exposure at default for a credit facility:</p> <pre><code># Credit facility data\ncurrent_balance = 500000\nundrawn_amount = 300000\ncredit_conversion_factor = 0.6\n\n# Calculate EAD\nead_result = credit.exposure_at_default(\n    current_balance=current_balance,\n    undrawn_amount=undrawn_amount,\n    credit_conversion_factor=credit_conversion_factor\n)\n\nprint(f\"Exposure at Default: ${ead_result['ead']:.2f}\")\nprint(f\"EAD Components:\")\nprint(f\"  Drawn Balance: ${ead_result['drawn_balance']:.2f}\")\nprint(f\"  Expected Draw: ${ead_result['expected_draw']:.2f}\")\n</code></pre>"},{"location":"user-guide/credit-scoring/#tracking-model-usage","title":"Tracking Model Usage","text":"<p>The CreditScoring class maintains a history of all calculations:</p> <pre><code># Get history of calculations\nhistory = credit.get_history()\n\nprint(f\"Number of calculations performed: {len(history)}\")\nprint(\"\\nRecent calculations:\")\nfor i, entry in enumerate(history[-3:]):\n    print(f\"{i+1}. Model: {entry['model']}\")\n</code></pre>"},{"location":"user-guide/credit-scoring/#best-practices","title":"Best Practices","text":""},{"location":"user-guide/credit-scoring/#1-data-quality","title":"1. Data Quality","text":"<ul> <li>Data Cleaning: Ensure financial data is accurate and complete</li> <li>Outlier Treatment: Handle outliers appropriately</li> <li>Missing Values: Develop a consistent approach for missing data</li> </ul>"},{"location":"user-guide/credit-scoring/#2-model-selection","title":"2. Model Selection","text":"<ul> <li>Purpose Fit: Choose models appropriate for the specific credit assessment need</li> <li>Complexity: Balance model complexity with interpretability</li> <li>Validation: Regularly validate model performance</li> </ul>"},{"location":"user-guide/credit-scoring/#3-risk-management","title":"3. Risk Management","text":"<ul> <li>Stress Testing: Test models under adverse scenarios</li> <li>Sensitivity Analysis: Understand how changes in inputs affect outputs</li> <li>Model Limitations: Be aware of each model's limitations</li> </ul>"},{"location":"user-guide/credit-scoring/#4-implementation","title":"4. Implementation","text":"<ul> <li>Documentation: Document assumptions and methodologies</li> <li>Monitoring: Regularly monitor model performance</li> <li>Updating: Update models as economic conditions change</li> </ul>"},{"location":"user-guide/credit-scoring/#common-pitfalls","title":"Common Pitfalls","text":""},{"location":"user-guide/credit-scoring/#1-model-misuse","title":"1. Model Misuse","text":"<ul> <li>Inappropriate Application: Using models outside their intended domain</li> <li>Overreliance: Relying too heavily on quantitative models without qualitative assessment</li> <li>Outdated Models: Using models that haven't been updated for current conditions</li> </ul>"},{"location":"user-guide/credit-scoring/#2-data-issues","title":"2. Data Issues","text":"<ul> <li>Sample Bias: Training on non-representative data</li> <li>Look-ahead Bias: Using information not available at decision time</li> <li>Data Staleness: Using outdated financial information</li> </ul>"},{"location":"user-guide/credit-scoring/#3-implementation-challenges","title":"3. Implementation Challenges","text":"<ul> <li>Parameter Sensitivity: Results highly sensitive to input parameters</li> <li>Model Risk: Risk of model error or misspecification</li> <li>Interpretation Errors: Misinterpreting model outputs </li> </ul>"},{"location":"user-guide/filters/","title":"Filters","text":"<p>Pypulate provides a comprehensive set of filtering techniques for financial time series data. This page explains the different types of filters available and how to use them.</p>"},{"location":"user-guide/filters/#overview","title":"Overview","text":"<p>Filters in Pypulate are designed to clean, smooth, and extract meaningful information from noisy financial time series data. The module includes:</p> <ol> <li>Kalman Filters: Optimal estimators for linear systems</li> <li>Signal Filters: Classical signal processing filters</li> <li>Adaptive Filters: Filters that adapt to changing data characteristics</li> <li>Particle Filters: Monte Carlo methods for non-linear/non-Gaussian systems</li> </ol>"},{"location":"user-guide/filters/#kalman-filters","title":"Kalman Filters","text":"<p>Kalman filters are optimal estimators that infer parameters of interest from indirect, inaccurate, and uncertain observations.</p>"},{"location":"user-guide/filters/#standard-kalman-filter","title":"Standard Kalman Filter","text":"<p>The standard Kalman filter is ideal for linear systems with Gaussian noise:</p> <pre><code>import numpy as np\nfrom pypulate.filters import kalman_filter\n\n# Create noisy data\nx = np.linspace(0, 10, 100)\ntrue_signal = np.sin(x)\nnoisy_signal = true_signal + np.random.normal(0, 0.1, len(x))\n\n# Apply Kalman filter\nfiltered_signal = kalman_filter(\n    noisy_signal,\n    process_variance=1e-5,\n    measurement_variance=1e-3\n)\n</code></pre>"},{"location":"user-guide/filters/#extended-kalman-filter-ekf","title":"Extended Kalman Filter (EKF)","text":"<p>The EKF is used for non-linear systems by linearizing around the current estimate:</p> <pre><code>import numpy as np\nfrom pypulate.filters import extended_kalman_filter\n\n# Define non-linear system\ndef state_transition(x):\n    # Non-linear state transition function\n    return np.array([x[0] + x[1], 0.5 * x[1]])\n\ndef observation(x):\n    # Non-linear observation function\n    return np.array([np.sin(x[0])])\n\ndef process_jacobian(x):\n    # Jacobian of state transition function\n    return np.array([[1, 1], [0, 0.5]])\n\ndef observation_jacobian(x):\n    # Jacobian of observation function\n    return np.array([[np.cos(x[0]), 0]])\n\n# Apply EKF\nQ = np.eye(2) * 0.01  # Process noise covariance\nR = np.array([[0.1]])  # Observation noise covariance\nfiltered_states = extended_kalman_filter(\n    observations, state_transition, observation,\n    process_jacobian, observation_jacobian, Q, R\n)\n</code></pre>"},{"location":"user-guide/filters/#unscented-kalman-filter-ukf","title":"Unscented Kalman Filter (UKF)","text":"<p>The UKF uses sigma points to handle non-linearities without requiring Jacobians:</p> <pre><code>import numpy as np\nfrom pypulate.filters import unscented_kalman_filter\n\n# Define non-linear system\ndef state_transition(x):\n    # Non-linear state transition function\n    return np.array([x[0] + x[1], 0.5 * x[1]])\n\ndef observation(x):\n    # Non-linear observation function\n    return np.array([np.sin(x[0])])\n\n# Apply UKF\nQ = np.eye(2) * 0.01  # Process noise covariance\nR = np.array([[0.1]])  # Observation noise covariance\nfiltered_states = unscented_kalman_filter(\n    observations, state_transition, observation, Q, R\n)\n</code></pre>"},{"location":"user-guide/filters/#signal-filters","title":"Signal Filters","text":"<p>Signal filters are used to remove noise and extract specific frequency components from time series data.</p>"},{"location":"user-guide/filters/#butterworth-filter","title":"Butterworth Filter","text":"<p>The Butterworth filter provides a flat frequency response in the passband:</p> <pre><code>import numpy as np\nfrom pypulate.filters import butterworth_filter\n\n# Create noisy data with multiple frequency components\nx = np.linspace(0, 10, 1000)\nsignal = np.sin(2 * np.pi * 0.05 * x) + 0.5 * np.sin(2 * np.pi * 0.25 * x)\n\n# Apply lowpass filter to remove high frequency component\nfiltered = butterworth_filter(\n    signal,\n    cutoff=0.1,  # Cutoff frequency\n    order=4,     # Filter order\n    filter_type='lowpass'\n)\n</code></pre>"},{"location":"user-guide/filters/#savitzky-golay-filter","title":"Savitzky-Golay Filter","text":"<p>The Savitzky-Golay filter smooths data by fitting successive sub-sets of adjacent data points with a low-degree polynomial:</p> <pre><code>import numpy as np\nfrom pypulate.filters import savitzky_golay_filter\n\n# Create noisy data\nx = np.linspace(0, 10, 100)\nsignal = np.sin(x) + np.random.normal(0, 0.1, len(x))\n\n# Apply Savitzky-Golay filter\nfiltered = savitzky_golay_filter(\n    signal,\n    window_length=11,  # Must be odd\n    polyorder=3        # Polynomial order\n)\n</code></pre>"},{"location":"user-guide/filters/#median-filter","title":"Median Filter","text":"<p>The median filter is excellent for removing outliers:</p> <pre><code>import numpy as np\nfrom pypulate.filters import median_filter\n\n# Create data with outliers\nx = np.linspace(0, 10, 100)\nsignal = np.sin(x)\nsignal[10] = 5  # Add outlier\nsignal[50] = -5  # Add outlier\n\n# Apply median filter\nfiltered = median_filter(signal, kernel_size=5)\n</code></pre>"},{"location":"user-guide/filters/#hampel-filter","title":"Hampel Filter","text":"<p>The Hampel filter is specifically designed for outlier detection and removal:</p> <pre><code>import numpy as np\nfrom pypulate.filters import hampel_filter\n\n# Create data with outliers\nx = np.linspace(0, 10, 100)\nsignal = np.sin(x)\nsignal[10] = 5  # Add outlier\nsignal[50] = -5  # Add outlier\n\n# Apply Hampel filter\nfiltered = hampel_filter(\n    signal,\n    window_size=5,  # Window size\n    n_sigmas=3.0    # Threshold for outlier detection\n)\n</code></pre>"},{"location":"user-guide/filters/#hodrick-prescott-filter","title":"Hodrick-Prescott Filter","text":"<p>The Hodrick-Prescott filter decomposes a time series into trend and cycle components:</p> <pre><code>import numpy as np\nfrom pypulate.filters import hodrick_prescott_filter\n\n# Create data with trend and cycle\nx = np.linspace(0, 10, 100)\ntrend = 0.1 * x**2\ncycle = np.sin(2 * np.pi * 0.1 * x)\ndata = trend + cycle\n\n# Apply Hodrick-Prescott filter\ntrend_component, cycle_component = hodrick_prescott_filter(\n    data,\n    lambda_param=100  # Smoothing parameter\n)\n</code></pre>"},{"location":"user-guide/filters/#adaptive-filters","title":"Adaptive Filters","text":"<p>Adaptive filters automatically adjust their parameters based on the input data.</p>"},{"location":"user-guide/filters/#adaptive-kalman-filter","title":"Adaptive Kalman Filter","text":"<p>The adaptive Kalman filter adjusts its noise parameters based on the observed data:</p> <pre><code>import numpy as np\nfrom pypulate.filters import adaptive_kalman_filter\n\n# Create noisy data with changing dynamics\nx = np.linspace(0, 10, 200)\ntrue_signal = np.sin(x) + 0.1 * x\nnoise_level = 0.1 * (1 + np.sin(x/2))  # Changing noise level\nnoisy_signal = true_signal + noise_level * np.random.randn(len(x))\n\n# Apply adaptive Kalman filter\nfiltered_signal = adaptive_kalman_filter(\n    noisy_signal,\n    adaptation_rate=0.05,  # Rate of adaptation\n    window_size=10         # Window for innovation estimation\n)\n</code></pre>"},{"location":"user-guide/filters/#least-mean-squares-lms-filter","title":"Least Mean Squares (LMS) Filter","text":"<p>The LMS filter is a simple adaptive filter that minimizes the mean square error:</p> <pre><code>import numpy as np\nfrom pypulate.filters import least_mean_squares_filter\n\n# Create noisy data\nx = np.linspace(0, 10, 1000)\nclean_signal = np.sin(2 * np.pi * 0.05 * x)\nnoise = 0.2 * np.random.randn(len(x))\nnoisy_signal = clean_signal + noise\n\n# Apply LMS filter\nfiltered_signal, weights = least_mean_squares_filter(\n    noisy_signal,\n    filter_length=10,  # Filter length\n    mu=0.02            # Step size\n)\n</code></pre>"},{"location":"user-guide/filters/#particle-filters","title":"Particle Filters","text":"<p>Particle filters are Monte Carlo methods that can handle non-linear and non-Gaussian systems.</p>"},{"location":"user-guide/filters/#standard-particle-filter","title":"Standard Particle Filter","text":"<p>The particle filter uses a set of particles to represent the posterior distribution:</p> <pre><code>import numpy as np\nfrom pypulate.filters import particle_filter\n\n# Define model functions\ndef state_transition(particles):\n    # Simple random walk model\n    return particles\n\ndef process_noise(particles):\n    # Add Gaussian noise\n    return particles + np.random.normal(0, 0.1, particles.shape)\n\ndef observation_func(state):\n    # Identity observation model\n    return state\n\ndef observation_likelihood(observation, predicted_observation):\n    # Gaussian likelihood\n    return np.exp(-0.5 * ((observation - predicted_observation) / 0.1) ** 2)\n\ndef initial_state(n):\n    # Initial particles from normal distribution\n    return np.random.normal(0, 1, n)\n\n# Apply particle filter\nfiltered_states, weights = particle_filter(\n    observations,\n    state_transition,\n    observation_func,\n    process_noise,\n    observation_likelihood,\n    n_particles=1000,\n    initial_state_func=initial_state\n)\n</code></pre>"},{"location":"user-guide/filters/#bootstrap-particle-filter","title":"Bootstrap Particle Filter","text":"<p>The bootstrap particle filter is a simplified version that resamples at every step:</p> <pre><code>import numpy as np\nfrom pypulate.filters import bootstrap_particle_filter\n\n# Define model functions\ndef state_transition(particles):\n    # Simple random walk model\n    return particles\n\ndef observation_func(state):\n    # Identity observation model\n    return state\n\n# Apply bootstrap particle filter\nfiltered_states, weights = bootstrap_particle_filter(\n    observations,\n    state_transition,\n    observation_func,\n    process_noise_std=0.1,\n    observation_noise_std=0.1,\n    n_particles=1000\n)\n</code></pre>"},{"location":"user-guide/filters/#choosing-the-right-filter","title":"Choosing the Right Filter","text":"<p>The choice of filter depends on your specific application:</p> <ul> <li>Kalman Filters: Best for linear systems or when you have a good model of the system dynamics</li> <li>Signal Filters: Good for general noise removal and frequency-based filtering</li> <li>Adaptive Filters: Useful when the signal characteristics change over time</li> <li>Particle Filters: Best for highly non-linear systems or non-Gaussian noise</li> </ul> <p>For financial time series, consider:</p> <ul> <li>Kalman/Adaptive Filters: For tracking changing trends</li> <li>Hampel/Median Filters: For removing outliers (e.g., flash crashes)</li> <li>Hodrick-Prescott Filter: For separating trend and cycle components</li> <li>Butterworth Filter: For removing high-frequency noise</li> </ul>"},{"location":"user-guide/filters/#example-combining-filters","title":"Example: Combining Filters","text":"<p>You can combine multiple filters for more sophisticated processing:</p> <pre><code>import numpy as np\nimport matplotlib.pyplot as plt\nfrom pypulate.filters import hampel_filter, kalman_filter\n\n# Create data with outliers and noise\nx = np.linspace(0, 10, 200)\ntrue_signal = np.sin(x) + 0.1 * x\nnoisy_signal = true_signal + 0.1 * np.random.randn(len(x))\nnoisy_signal[20] = 5  # Add outlier\nnoisy_signal[100] = -5  # Add outlier\n\n# First remove outliers with Hampel filter\noutlier_removed = hampel_filter(noisy_signal, window_size=5, n_sigmas=3.0)\n\n# Then smooth with Kalman filter\nfinal_signal = kalman_filter(outlier_removed, process_variance=1e-5, measurement_variance=1e-3)\n\n# Plot results\nplt.figure(figsize=(12, 6))\nplt.plot(x, true_signal, 'k-', label='True Signal')\nplt.plot(x, noisy_signal, 'r.', alpha=0.5, label='Noisy Signal with Outliers')\nplt.plot(x, outlier_removed, 'g-', alpha=0.7, label='After Hampel Filter')\nplt.plot(x, final_signal, 'b-', linewidth=2, label='After Kalman Filter')\nplt.legend()\nplt.title('Multi-stage Filtering')\nplt.grid(True, alpha=0.3)\nplt.show()\n</code></pre> <p>Filters also works with Parray chain methods. You can combine them with other tools easily to make advanced techniques.</p>"},{"location":"user-guide/getting-started/","title":"Getting Started with Pypulate","text":"<p>This guide will help you get started with Pypulate for financial time series analysis, business KPI calculations, and portfolio management.</p>"},{"location":"user-guide/getting-started/#installation","title":"Installation","text":"<pre><code>pip install pypulate\n</code></pre>"},{"location":"user-guide/getting-started/#core-components","title":"Core Components","text":"<p>Pypulate provides powerful classes for financial and business analytics:</p>"},{"location":"user-guide/getting-started/#1-parray-pypulate-array","title":"1. Parray (Pypulate Array)","text":"<p>The <code>Parray</code> class extends NumPy arrays with financial analysis capabilities:</p> <pre><code>from pypulate import Parray\n\n# Create a price array\nprices = Parray([10, 11, 12, 11, 10, 9, 10, 11, 12, 13, 15, 11, 8, 10, 14, 16])\n\n# Technical Analysis with method chaining\nresult = (prices\n    .sma(3)                     # Simple Moving Average\n    .ema(3)                    # Exponential Moving Average\n    .rsi(7)                    # Relative Strength Index\n)\n\n# Signal Detection\nfast_ma = prices.sma(3)\nslow_ma = prices.sma(12)\ngolden_cross = fast_ma.crossover(slow_ma)\ndeath_cross = fast_ma.crossunder(slow_ma)\n</code></pre>"},{"location":"user-guide/getting-started/#2-kpi-key-performance-indicators","title":"2. KPI (Key Performance Indicators)","text":"<p>The <code>KPI</code> class manages business metrics and health assessment:</p> <pre><code>from pypulate import KPI\n\n# Initialize KPI tracker\nkpi = KPI()\n\n# Customer Metrics\nchurn = kpi.churn_rate(\n    customers_start=1000,\n    customers_end=950,\n    new_customers=50\n)\n\n# Financial Metrics\nclv = kpi.customer_lifetime_value(\n    avg_revenue_per_customer=100,\n    gross_margin=70,\n    churn_rate_value=5\n)\n\n# Health Assessment\nhealth = kpi.health\nprint(f\"Business Health Score: {health['overall_score']}\")\nprint(f\"Status: {health['status']}\")\n</code></pre>"},{"location":"user-guide/getting-started/#3-portfolio","title":"3. Portfolio","text":"<p>The <code>Portfolio</code> class handles portfolio analysis and risk management:</p> <pre><code>from pypulate import Portfolio\n\n# Initialize portfolio analyzer\nportfolio = Portfolio()\n\n# Calculate Returns\nreturns = portfolio.simple_return([50, 100, 120], [60, 70, 120])\ntwrr = portfolio.time_weighted_return(\n    [0.02, 0.01, 0.1, 0.003]\n)\n\n# Risk Analysis\nsharpe = portfolio.sharpe_ratio(returns, risk_free_rate=0.02)\nvar = portfolio.value_at_risk(returns, confidence_level=0.95)\n\n# Portfolio Health\nhealth = portfolio.health\nprint(f\"Portfolio Health Score: {health['overall_score']}\")\nprint(f\"Risk Status: {health['components']['risk']['status']}\")\n</code></pre>"},{"location":"user-guide/getting-started/#4-allocation","title":"4. Allocation","text":"<p>The <code>Allocation</code> class provides advanced portfolio optimization and asset allocation methods:</p> <pre><code>from pypulate import Allocation\nimport numpy as np\n\n# Initialize allocation optimizer\nallocation = Allocation()\n\n# Sample returns data (252 days, 5 assets)\nreturns = np.random.normal(0.0001, 0.02, (252, 5))\nrisk_free_rate = 0.04\n\n# Mean-Variance Optimization\nweights, ret, risk = allocation.mean_variance(\n    returns, \n    risk_free_rate=risk_free_rate\n)\nprint(f\"Mean-Variance Portfolio:\")\nprint(f\"Expected Return: {ret:.2%}\")\nprint(f\"Risk: {risk:.2%}\")\nprint(f\"Weights: {weights}\")\n\n# Risk Parity Portfolio\nweights, ret, risk = allocation.risk_parity(returns)\nprint(f\"\\nRisk Parity Portfolio:\")\nprint(f\"Expected Return: {ret:.2%}\")\nprint(f\"Risk: {risk:.2%}\")\nprint(f\"Weights: {weights}\")\n\n# Kelly Criterion (with half-Kelly)\nweights, ret, risk = allocation.kelly_criterion(\n    returns, \n    kelly_fraction=0.5\n)\nprint(f\"\\nHalf-Kelly Portfolio:\")\nprint(f\"Expected Return: {ret:.2%}\")\nprint(f\"Risk: {risk:.2%}\")\nprint(f\"Weights: {weights}\")\n\n# Black-Litterman with views\nviews = {0: 0.15, 1: 0.12}  # Views on first two assets\nview_confidences = {0: 0.8, 1: 0.7}\nmarket_caps = np.array([1000, 800, 600, 400, 200])\nweights, ret, risk = allocation.black_litterman(\n    returns, \n    market_caps, \n    views, \n    view_confidences\n)\nprint(f\"\\nBlack-Litterman Portfolio:\")\nprint(f\"Expected Return: {ret:.2%}\")\nprint(f\"Risk: {risk:.2%}\")\nprint(f\"Weights: {weights}\")\n\n# Hierarchical Risk Parity\nweights, ret, risk = allocation.hierarchical_risk_parity(returns)\nprint(f\"\\nHierarchical Risk Parity Portfolio:\")\nprint(f\"Expected Return: {ret:.2%}\")\nprint(f\"Risk: {risk:.2%}\")\nprint(f\"Weights: {weights}\")\n</code></pre>"},{"location":"user-guide/getting-started/#5-servicepricing","title":"5. ServicePricing","text":"<p>The <code>ServicePricing</code> class provides a unified interface for various pricing models:</p> <pre><code>from pypulate import ServicePricing\n\n# Initialize pricing calculator\npricing = ServicePricing()\n\n# Tiered Pricing\nprice = pricing.calculate_tiered_price(\n    usage_units=1500,\n    tiers={\n        \"0-1000\": 0.10,    # First tier: $0.10 per unit\n        \"1001-2000\": 0.08, # Second tier: $0.08 per unit\n        \"2001+\": 0.05      # Final tier: $0.05 per unit\n    }\n)\nprint(f\"Tiered Price: ${price:.2f}\")  # $140.00 (1000 * 0.10 + 500 * 0.08)\n\n# Subscription with Features\nsub_price = pricing.calculate_subscription_price(\n    base_price=99.99,\n    features=['premium', 'api_access'],\n    feature_prices={'premium': 49.99, 'api_access': 29.99},\n    duration_months=12,\n    discount_rate=0.10\n)\n\n# Track Pricing History\npricing.save_current_pricing()\nhistory = pricing.get_pricing_history()\n</code></pre>"},{"location":"user-guide/getting-started/#6-creditscoring","title":"6. CreditScoring","text":"<p>The <code>CreditScoring</code> class provides comprehensive credit risk assessment and scoring tools:</p> <pre><code>from pypulate.dtypes import CreditScoring\n\n# Initialize credit scoring system\ncredit = CreditScoring()\n\n# Corporate Credit Risk Assessment\nz_score_result = credit.altman_z_score(\n    working_capital=1200000,\n    retained_earnings=1500000,\n    ebit=800000,\n    market_value_equity=5000000,\n    sales=4500000,\n    total_assets=6000000,\n    total_liabilities=2500000\n)\nprint(f\"Altman Z-Score: {z_score_result['z_score']:.2f}\")\nprint(f\"Risk Assessment: {z_score_result['risk_assessment']}\")\n\n# Default Probability Estimation\nmerton_result = credit.merton_model(\n    asset_value=10000000,\n    debt_face_value=5000000,\n    asset_volatility=0.25,\n    risk_free_rate=0.03,\n    time_to_maturity=1.0\n)\nprint(f\"Probability of Default: {merton_result['probability_of_default']:.2%}\")\n\n# Credit Scorecard for Retail Lending\nfeatures = {\n    \"age\": 35,\n    \"income\": 75000,\n    \"years_employed\": 5,\n    \"debt_to_income\": 0.3,\n    \"previous_defaults\": 0\n}\nweights = {\n    \"age\": 2.5,\n    \"income\": 3.2,\n    \"years_employed\": 4.0,\n    \"debt_to_income\": -5.5,\n    \"previous_defaults\": -25.0\n}\nscorecard_result = credit.create_scorecard(\n    features=features,\n    weights=weights,\n    scaling_factor=20,\n    base_score=600\n)\nprint(f\"Credit Score: {scorecard_result['total_score']:.0f}\")\nprint(f\"Risk Category: {scorecard_result['risk_category']}\")\n\n# Expected Credit Loss Calculation\necl_result = credit.expected_credit_loss(\n    pd=0.05,  # Probability of default\n    lgd=0.4,  # Loss given default\n    ead=100000,  # Exposure at default\n    time_horizon=1.0\n)\nprint(f\"Expected Credit Loss: ${ecl_result['ecl']:.2f}\")\n\n# Track Model Usage\nhistory = credit.get_history()\n</code></pre>"},{"location":"user-guide/getting-started/#common-patterns","title":"Common Patterns","text":""},{"location":"user-guide/getting-started/#1-method-chaining","title":"1. Method Chaining","text":"<p>Parray support method chaining for cleaner code:</p> <pre><code># Parray chaining\nsignals = (Parray(prices)\n    .sma(10)\n    .crossover(Parray(prices).sma(20))\n)\n</code></pre>"},{"location":"user-guide/getting-started/#2-health-assessments","title":"2. Health Assessments","text":"<p>Portfolio and KPI classes provide health assessments with consistent scoring:</p> <pre><code># Business Health\nkpi_health = kpi.health  # Business metrics health\n\n# Portfolio Health\nportfolio_health = portfolio.health  # Portfolio performance health\n\n# Health Status Categories\n# - Excellent: \u2265 90\n# - Good: \u2265 75\n# - Fair: \u2265 60\n# - Poor: \u2265 45\n# - Critical: &lt; 45\n</code></pre>"},{"location":"user-guide/getting-started/#3-state-management","title":"3. State Management","text":"<p>All classes maintain state for tracking and analysis:</p> <pre><code># KPI state\nstored_churn = kpi._state['churn_rate']\nstored_retention = kpi._state['retention_rate']\n\n# Portfolio state\nstored_returns = portfolio._state['returns']\nstored_risk = portfolio._state['volatility']\n\n# ServicePricing state\nstored_pricing = pricing._state['current_pricing']\npricing_history = pricing._state['pricing_history']\n\n# CreditScoring state\nmodel_history = credit._history  # History of credit model calculations\n</code></pre>"},{"location":"user-guide/getting-started/#next-steps","title":"Next Steps","text":"<p>Now that you understand the basic components, explore these topics in detail:</p> <ul> <li>Parray Guide: Advanced technical analysis and signal detection</li> <li>KPI Guide: Comprehensive business metrics and health scoring</li> <li>Portfolio Guide: Portfolio analysis and risk management</li> <li>Service Pricing Guide: Pricing models and calculations</li> <li>Credit Scoring Guide: Credit risk assessment and scoring</li> </ul>"},{"location":"user-guide/kpi/","title":"KPI Guide","text":"<p>The <code>KPI</code> class provides a comprehensive suite of methods for calculating and tracking business metrics. It maintains state to provide health assessments and trend analysis.</p>"},{"location":"user-guide/kpi/#basic-usage","title":"Basic Usage","text":"<pre><code>from pypulate import KPI\n\n# Initialize KPI tracker\nkpi = KPI()\n\n# Calculate basic metrics\nchurn = kpi.churn_rate(customers_start=1000, customers_end=950, new_customers=50)\nretention = kpi.retention_rate(customers_start=1000, customers_end=950, new_customers=50)\n\n# Get health assessment\nhealth = kpi.health\n</code></pre>"},{"location":"user-guide/kpi/#customer-metrics","title":"Customer Metrics","text":""},{"location":"user-guide/kpi/#churn-and-retention","title":"Churn and Retention","text":"<pre><code># Calculate churn rate\nchurn = kpi.churn_rate(\n    customers_start=1000,  # Starting customer count\n    customers_end=950,     # Ending customer count\n    new_customers=50       # New customers acquired\n)\n\n# Calculate retention rate\nretention = kpi.retention_rate(\n    customers_start=1000,\n    customers_end=950,\n    new_customers=50\n)\n</code></pre>"},{"location":"user-guide/kpi/#customer-lifetime-value","title":"Customer Lifetime Value","text":"<pre><code>clv = kpi.customer_lifetime_value(\n    avg_revenue_per_customer=100,  # Monthly revenue per customer\n    gross_margin=70,              # Gross margin percentage\n    churn_rate_value=5,          # Monthly churn rate\n    discount_rate=10             # Annual discount rate\n)\n</code></pre>"},{"location":"user-guide/kpi/#financial-metrics","title":"Financial Metrics","text":""},{"location":"user-guide/kpi/#revenue-metrics","title":"Revenue Metrics","text":"<pre><code># Calculate MRR\nmrr = kpi.monthly_recurring_revenue(\n    paying_customers=1000,\n    avg_revenue_per_customer=50\n)\n\n# Calculate ARR\narr = kpi.annual_recurring_revenue(\n    paying_customers=1000,\n    avg_revenue_per_customer=50\n)\n</code></pre>"},{"location":"user-guide/kpi/#cost-metrics","title":"Cost Metrics","text":"<pre><code># Calculate CAC\ncac = kpi.customer_acquisition_cost(\n    marketing_costs=50000,\n    sales_costs=30000,\n    new_customers=100\n)\n\n# Calculate ROI\nroi = kpi.roi(\n    revenue=150000,\n    costs=100000\n)\n</code></pre>"},{"location":"user-guide/kpi/#engagement-metrics","title":"Engagement Metrics","text":""},{"location":"user-guide/kpi/#net-promoter-score","title":"Net Promoter Score","text":"<pre><code>nps = kpi.net_promoter_score(\n    promoters=70,        # Customers rating 9-10\n    detractors=10,       # Customers rating 0-6\n    total_respondents=100\n)\n</code></pre>"},{"location":"user-guide/kpi/#customer-satisfaction","title":"Customer Satisfaction","text":"<pre><code># Calculate CSAT\ncsat = kpi.customer_satisfaction_score(\n    satisfaction_ratings=[4, 5, 3, 5, 4],\n    max_rating=5\n)\n\n# Calculate Customer Effort Score\nces = kpi.customer_effort_score(\n    effort_ratings=[2, 3, 1, 2, 4],\n    max_rating=7\n)\n</code></pre>"},{"location":"user-guide/kpi/#health-assessment","title":"Health Assessment","text":"<p>The <code>health</code> property provides a comprehensive assessment of business health based on all tracked metrics:</p> <pre><code>health = kpi.health\n\n# Health assessment structure\n{\n    'overall_score': 85.5,\n    'status': 'Good',\n    'components': {\n        'churn_rate': {\n            'score': 90.0,\n            'status': 'Excellent'\n        },\n        'retention_rate': {\n            'score': 85.0,\n            'status': 'Good'\n        },\n        # ... other metrics\n    }\n}\n</code></pre>"},{"location":"user-guide/kpi/#health-score-components","title":"Health Score Components","text":"<p>The health score is calculated based on weighted components:</p> <ul> <li>Customer Health (30%)</li> <li>Churn Rate</li> <li>Retention Rate</li> <li> <p>LTV/CAC Ratio</p> </li> <li> <p>Financial Health (30%)</p> </li> <li>Gross Margin</li> <li>ROI</li> <li> <p>Revenue Growth</p> </li> <li> <p>Engagement Health (40%)</p> </li> <li>NPS</li> <li>CSAT</li> <li>Feature Adoption</li> </ul> <p>Each component is scored from 0-100 and assigned a status: - Excellent: \u2265 90 - Good: \u2265 75 - Fair: \u2265 60 - Poor: \u2265 45 - Critical: &lt; 45</p>"},{"location":"user-guide/kpi/#state-management","title":"State Management","text":"<p>The KPI class maintains state for all calculated metrics in the <code>_state</code> dictionary. This allows for: - Trend analysis - Health assessment - Historical comparison - Metric correlation</p> <pre><code># Access stored metrics\nstored_churn = kpi._state['churn_rate']\nstored_retention = kpi._state['retention_rate']\n</code></pre>"},{"location":"user-guide/kpi/#best-practices","title":"Best Practices","text":""},{"location":"user-guide/kpi/#1-data-collection-and-management","title":"1. Data Collection and Management","text":"<ul> <li>1.1. Initialize Early: Create the KPI instance at the start of your analysis</li> <li>1.2. Regular Updates: Update metrics consistently for accurate trending</li> <li>1.3. Store History: Consider saving state for long-term analysis</li> </ul>"},{"location":"user-guide/kpi/#2-analysis-and-monitoring","title":"2. Analysis and Monitoring","text":"<ul> <li>2.1. Monitor Health: Regularly check the health assessment</li> <li>2.2. Validate Inputs: Ensure input data quality for accurate metrics</li> <li>2.3. Compare Trends: Analyze metric changes over time rather than isolated values</li> </ul>"},{"location":"user-guide/kpi/#3-reporting-and-decision-making","title":"3. Reporting and Decision Making","text":"<ul> <li>3.1. Focus on Key Metrics: Prioritize metrics most relevant to your business model</li> <li>3.2. Set Thresholds: Establish alert thresholds for critical metrics</li> <li>3.3. Contextualize Results: Consider market conditions when interpreting metrics ``` </li> </ul>"},{"location":"user-guide/moving-averages/","title":"Moving Averages","text":"<p>Pypulate provides a comprehensive set of moving average functions for financial time series analysis. This  page explains the different types of moving averages available and how to use them.</p>"},{"location":"user-guide/moving-averages/#available-moving-averages","title":"Available Moving Averages","text":""},{"location":"user-guide/moving-averages/#specialized-moving-averages","title":"Specialized Moving Averages","text":"<p>These moving averages are designed for specific use cases:</p> <ul> <li>Volume-Weighted Moving Average (VWMA): Weights price by volume.</li> <li>Kaufman Adaptive Moving Average (KAMA): Adapts to market volatility.</li> <li>Arnaud Legoux Moving Average (ALMA): Reduces lag and noise.</li> <li>Fractal Adaptive Moving Average (FRAMA): Adapts to market fractal dimension.</li> <li>Jurik Moving Average (JMA): Reduces noise and lag.</li> <li>Laguerre Filter: Uses Laguerre polynomials for smoothing.</li> <li>Least Squares Moving Average (LSMA): Uses linear regression.</li> <li>McGinley Dynamic Indicator: Adapts to market speed.</li> <li>Modular Filter: Adjusts smoothing based on phase.</li> <li>Rex Dog Moving Average (RDMA): Average of six SMAs with different periods.</li> <li>Tillson T3: Triple EMA with reduced lag.</li> <li>Volatility-Adjusted Moving Average (VAMA): Adjusts based on volatility.</li> </ul>"},{"location":"user-guide/moving-averages/#using-moving-averages","title":"Using Moving Averages","text":""},{"location":"user-guide/moving-averages/#functional-approach","title":"Functional Approach","text":"<p>You can use moving averages directly by importing the functions:</p> <pre><code>import numpy as np\nfrom pypulate.moving_averages import sma, ema, hma\n\n# Create sample data\ndata = [10, 11, 12, 11, 10, 9, 10, 11, 12, 13]\n\n# Calculate moving averages\nsma_result = sma(data, period=3)\nema_result = ema(data, period=3)\nhma_result = hma(data, period=3)\n</code></pre>"},{"location":"user-guide/moving-averages/#method-chaining-with-parray","title":"Method Chaining with Parray","text":"<p>For a more fluent interface, you can use the <code>Parray</code> class:</p> <pre><code>from pypulate import Parray\n\n# Create sample data\ndata = Parray([10, 11, 12, 11, 10, 9, 10, 11, 12, 13])\n\n# Calculate moving averages using method chaining\nsma_result = Parray.sma(period=3)\nema_result = Parray.ema(period=3)\nhma_result = Parray.hma(period=3)\n</code></pre>"},{"location":"user-guide/moving-averages/#examples","title":"Examples","text":""},{"location":"user-guide/moving-averages/#comparing-different-moving-averages","title":"Comparing Different Moving Averages","text":"<pre><code>import numpy as np\nimport matplotlib.pyplot as plt\nfrom pypulate import Parray\n\n# Generate sample price data\nnp.random.seed(42)\ndays = 100\nprice = np.cumsum(np.random.normal(0, 1, days)) + 100\n\n# Convert to Parray for method chaining\nprice_array = Parray(price)\n\n# Calculate different types of moving averages\nsma = price_array.sma(20)\nema = price_array.ema(20)\nwma = price_array.wma(20)\nhma = price_array.hma(20)\n\n# Plot the results\nplt.figure(figsize=(12, 6))\nplt.plot(price, label='Price', alpha=0.5, color='gray')\nplt.plot(sma, label='SMA(20)')\nplt.plot(ema, label='EMA(20)')\nplt.plot(wma, label='WMA(20)')\nplt.plot(hma, label='HMA(20)')\n\nplt.title('Comparison of Different Moving Averages')\nplt.xlabel('Days')\nplt.ylabel('Price')\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.show()\n</code></pre>"},{"location":"user-guide/moving-averages/#moving-average-crossover-strategy","title":"Moving Average Crossover Strategy","text":"<pre><code>import numpy as np\nimport matplotlib.pyplot as plt\nfrom pypulate import Parray\n\n# Generate sample price data\nnp.random.seed(42)\ndays = 200\nprice = np.cumsum(np.random.normal(0, 1, days)) + 100\n\n# Convert to Parray for method chaining\nprice_array = Parray(price)\n\n# Calculate fast and slow EMAs\nfast_ema = price_array.ema(9)\nslow_ema = price_array.ema(21)\n\n# Generate buy/sell signals\nbuy_signals = fast_ema.crossover(slow_ema)\nsell_signals = fast_ema.crossunder(slow_ema)\n\n# Plot the results\nplt.figure(figsize=(12, 6))\nplt.plot(price, label='Price')\nplt.plot(fast_ema, label='9-day EMA', alpha=0.7)\nplt.plot(slow_ema, label='21-day EMA', alpha=0.7)\n\n# Plot buy signals\nbuy_indices = np.where(buy_signals)[0]\nplt.scatter(buy_indices, price[buy_indices], marker='^', color='green', s=100, label='Buy Signal')\n\n# Plot sell signals\nsell_indices = np.where(sell_signals)[0]\nplt.scatter(sell_indices, price[sell_indices], marker='v', color='red', s=100, label='Sell Signal')\n\nplt.title('Moving Average Crossover Strategy')\nplt.xlabel('Days')\nplt.ylabel('Price')\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.show()\n</code></pre>"},{"location":"user-guide/moving-averages/#choosing-the-right-moving-average","title":"Choosing the Right Moving Average","text":"<p>Different moving averages are suitable for different market conditions:</p> <ul> <li>Trending Markets: SMA, EMA, WMA, HMA</li> <li>Volatile Markets: KAMA, ALMA, FRAMA, JMA</li> <li>Ranging Markets: DEMA, TEMA, T3</li> </ul> <p>Experiment with different types to find the one that works best for your specific use case. </p>"},{"location":"user-guide/parray/","title":"Using the Parray Class","text":"<p>The <code>Parray</code> class is a powerful tool for financial time series analysis in Pypulate. It extends NumPy arrays with financial analysis methods that can be chained together for complex calculations.</p>"},{"location":"user-guide/parray/#introduction","title":"Introduction","text":"<p><code>Parray</code> is designed to make financial time series analysis more intuitive and concise. It inherits from <code>numpy.ndarray</code>, so it has all the functionality of NumPy arrays, plus additional methods for financial analysis.</p>"},{"location":"user-guide/parray/#getting-started","title":"Getting Started","text":""},{"location":"user-guide/parray/#creating-a-parray","title":"Creating a Parray","text":"<p>You can create a <code>Parray</code> object from any array-like object using the <code>Parray</code> class:</p> <pre><code>from pypulate.dtypes import Parray\n\n# From a list\ndata = [1, 2, 3, 4, 5]\np = Parray(data)\n\n# From a NumPy array\ndata = np.array([1, 2, 3, 4, 5])\np = Parray(data)\n</code></pre>"},{"location":"user-guide/parray/#moving-averages","title":"Moving Averages","text":"<p><code>Parray</code> provides methods for calculating various moving averages:</p> <pre><code>from pypulate import Parray\n\ndata = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\np = Parray(data)\n\n# Simple Moving Average\nsma = p.sma(3)  # 3-period SMA\n\n# Exponential Moving Average\nema = p.ema(3)  # 3-period EMA\n\n# Weighted Moving Average\nwma = p.wma(3)  # 3-period WMA\n\n# Hull Moving Average\nhma = p.hma(3)  # 3-period HMA\n</code></pre>"},{"location":"user-guide/parray/#crossover-and-crossunder-detection","title":"Crossover and Crossunder Detection","text":"<p>One of the most useful features of <code>Parray</code> is the ability to detect crossovers and crossunders, which are common signals in technical analysis:</p> <pre><code>from pypulate.dtypes import Parray\n\n# Create sample price data\ndata = Parray([10, 11, 12, 11, 10, 11, 12, 13])\n\n# Find where prices cross above 11\ncrossover_points = data.crossover(11)\n\n# Find where prices cross below 11\ncrossunder_points = data.crossunder(11)\n\n# Find where prices cross above a moving average\nma = data.sma(3)\ncrossover_ma = data.crossover(ma)\n</code></pre>"},{"location":"user-guide/parray/#advanced-technical-analysis","title":"Advanced Technical Analysis","text":""},{"location":"user-guide/parray/#oscillators-and-momentum","title":"Oscillators and Momentum","text":"<pre><code>from pypulate import Parray\n\n# Sample price data\nprices = Parray([\n    100, 102, 104, 103, 105, 107, 106, 108, 110, 109,\n    111, 113, 112, 115, 114, 116, 118, 117, 119, 120\n])\n\n# RSI (Relative Strength Index)\nrsi = prices.rsi(14)  # 14-period RSI\n\n\n# MACD (Moving Average Convergence Divergence)\nmacd_line, signal_line, histogram = prices.macd(6, 12, 6)\n\n# Rate of Change (ROC)\nroc = prices.roc(12)  # 12-period rate of change\n\n# Momentum\nmomentum = prices.momentum(10)  # 10-period momentum\n</code></pre>"},{"location":"user-guide/parray/#volatility-indicators","title":"Volatility Indicators","text":"<pre><code># Sample OHLC data\nhigh = Parray([\n    102, 104, 105, 104, 107, 108, 107, 109, 111, 110,\n    112, 114, 113, 116, 115, 117, 119, 118, 120, 121\n])\nlow = Parray([\n    99, 101, 103, 102, 104, 106, 105, 107, 109, 108,\n    110, 112, 111, 114, 113, 115, 117, 116, 118, 119\n])\nclose = Parray([\n    100, 102, 104, 103, 105, 107, 106, 108, 110, 109,\n    111, 113, 112, 115, 114, 116, 118, 117, 119, 120\n])\n\n# Bollinger Bands (uses close prices)\nupper_band, middle_band, lower_band = close.bollinger_bands(12, 2)  # 12-period, 2 standard deviations\n\n# Average True Range (ATR) - requires high, low, close prices\natr = Parray.atr(high, low, close, 14)  # 14-period ATR\n\n# Keltner Channels (uses high, low, close for ATR calculation)\nk_upper, k_middle, k_lower = Parray.keltner_channels(close, high, low, 12, 2)  # 12-period, 2 ATR multiplier\n\n# Standard Deviation\nstd = close.rolling_std(12)  # 12-period rolling standard deviation\n\n# CCI with typical price\ncci = close.typical_price(high, low).cci(9)\n</code></pre>"},{"location":"user-guide/parray/#trade-strategy","title":"Trade Strategy","text":"<pre><code># Calculate indicators\nadx = close.adx(14)  # 14-period ADX\nma_10 = close.sma(10)  # 10-period SMA\n\n# Generate long position signals\n# Long when: price &gt; MA(10) AND ADX &lt; 30 (weak trend, good for entry)\nlong_signals = (close &gt; ma_10) &amp; (adx &lt; 30)\n\n# Get indices where long_signals is True\nprint(\"Long Entry Points:\", np.where(long_signals)[0])\n</code></pre>"},{"location":"user-guide/parray/#custom-indicators","title":"Custom Indicators","text":"<pre><code># Create custom indicators using method chaining\ncustom_ma = (\n    prices.sma(10) * 0.5 +      # 50% weight to SMA\n    prices.ema(10) * 0.3 +      # 30% weight to EMA\n    prices.wma(10) * 0.2        # 20% weight to WMA\n)\n\n# Custom momentum indicator\ncustom_momentum = (\n    prices.roc(10) * 0.4 +      # 40% weight to ROC\n    prices.rsi(14) * 0.3 +      # 30% weight to RSI\n    prices.momentum(10) * 0.3   # 30% weight to Momentum\n)\n</code></pre>"},{"location":"user-guide/parray/#best-practices","title":"Best Practices","text":""},{"location":"user-guide/parray/#1-signal-generation","title":"1. Signal Generation","text":"<ul> <li>1.1. Multiple Indicators: Combine multiple indicators for confirmation</li> <li>1.2. Risk Management: Use proper risk management with every signal</li> <li>1.3. Time Frame Alignment: Consider time frame alignment across indicators</li> <li>1.4. Noise Filtering: Filter out noise with minimum threshold values</li> </ul>"},{"location":"user-guide/parray/#2-performance-optimization","title":"2. Performance Optimization","text":"<ul> <li>2.1. Memory Management: Be mindful that method chaining creates intermediate arrays</li> <li>2.2. Large Datasets: For extremely large datasets, consider using underlying functions directly</li> <li>2.3. Vectorization: Leverage NumPy's vectorized operations for better performance</li> </ul>"},{"location":"user-guide/parray/#3-analysis-techniques","title":"3. Analysis Techniques","text":"<ul> <li>3.1. Custom Indicators: Create custom indicators by combining existing ones</li> <li>3.2. Backtesting: Test strategies on historical data before applying</li> <li>3.3. Parameter Optimization: Test different parameters to find optimal settings</li> </ul>"},{"location":"user-guide/parray/#performance-considerations","title":"Performance Considerations","text":"<p>Since <code>Parray</code> is a subclass of <code>numpy.ndarray</code>, it inherits all of NumPy's performance characteristics. However, there are a few things to keep in mind:</p> <ol> <li>Method chaining creates intermediate arrays, which can increase memory usage for very large datasets.</li> <li>For extremely performance-critical applications, you may want to use the underlying functions directly.</li> </ol> <p>For most use cases, the convenience of method chaining outweighs any minor performance impact. </p>"},{"location":"user-guide/portfolio/","title":"Portfolio Guide","text":"<p>The <code>Portfolio</code> class provides a comprehensive suite of methods for portfolio analysis, risk management, and performance attribution.</p>"},{"location":"user-guide/portfolio/#basic-usage","title":"Basic Usage","text":"<pre><code>from pypulate import Portfolio\n\n# Initialize portfolio analyzer\nportfolio = Portfolio()\n\n# Calculate basic returns\nsimple_ret = portfolio.simple_return(10, 12)\nlog_ret = portfolio.log_return(10, 12)\n</code></pre>"},{"location":"user-guide/portfolio/#return-metrics","title":"Return Metrics","text":""},{"location":"user-guide/portfolio/#simple-returns","title":"Simple Returns","text":"<pre><code># Calculate simple returns\nreturns = portfolio.simple_return([10, 20, 25], [12, 21, 20])\n\n# Calculate holding period return\nhpr = portfolio.holding_period_return(\n    [10, 20, 25]\n)\n\n# Calculate annualized return\nannual_ret = portfolio.annualized_return(\n    [10, 20, 25],\n    years=2\n)\n</code></pre>"},{"location":"user-guide/portfolio/#time-weighted-returns","title":"Time-Weighted Returns","text":"<pre><code># Calculate time-weighted return\ntwrr = portfolio.time_weighted_return(\n    [0.01, 0.03, 0.02, 0.02, 0.001],\n)\n</code></pre>"},{"location":"user-guide/portfolio/#money-weighted-returns","title":"Money-Weighted Returns","text":"<pre><code># Calculate money-weighted return (IRR)\nmwrr = portfolio.money_weighted_return([-1000, -500, 1700], [0, 0.5, 1], 0)\n</code></pre>"},{"location":"user-guide/portfolio/#risk-metrics","title":"Risk Metrics","text":""},{"location":"user-guide/portfolio/#volatility-measures","title":"Volatility Measures","text":"<pre><code># Calculate standard deviation\nstd_dev = portfolio.standard_deviation([0.01, 0.03, 0.02, 0.02, 0.001])\n</code></pre>"},{"location":"user-guide/portfolio/#value-at-risk","title":"Value at Risk","text":"<pre><code># Calculate parametric VaR\nvar = portfolio.value_at_risk(\n    [0.01, 0.03, 0.02, 0.02, 0.001],\n    confidence_level=0.95,\n    method = 'monte_carlo'\n)\n\n# Calculate conditional VaR (Expected Shortfall)\ncvar = portfolio.conditional_value_at_risk(\n    returns,\n    confidence_level=0.95\n)\n</code></pre>"},{"location":"user-guide/portfolio/#drawdown-analysis","title":"Drawdown Analysis","text":"<pre><code># Calculate maximum drawdown\nmax_dd = portfolio.max_drawdown(prices)\n\n# Get drawdown details\ndd_amount, dd_percent, dd_length = portfolio.drawdown_details(prices)\n</code></pre>"},{"location":"user-guide/portfolio/#risk-adjusted-performance","title":"Risk-Adjusted Performance","text":""},{"location":"user-guide/portfolio/#sharpe-ratio","title":"Sharpe Ratio","text":"<pre><code># Calculate Sharpe ratio\nsharpe = portfolio.sharpe_ratio(\n    returns,\n    risk_free_rate=0.02,\n    periods_per_year=252\n)\n</code></pre>"},{"location":"user-guide/portfolio/#information-ratio","title":"Information Ratio","text":"<pre><code># Calculate Information ratio\ninfo_ratio = portfolio.information_ratio(\n    returns,\n    benchmark_returns,\n    periods_per_year=252\n)\n</code></pre>"},{"location":"user-guide/portfolio/#capm-metrics","title":"CAPM Metrics","text":"<pre><code># Calculate beta\nbeta = portfolio.beta(returns, market_returns)\n\n# Calculate alpha\nalpha = portfolio.alpha(\n    returns,\n    market_returns,\n    risk_free_rate=0.02\n)\n</code></pre>"},{"location":"user-guide/portfolio/#health-assessment","title":"Health Assessment","text":"<p>The <code>health</code> property provides a comprehensive assessment of portfolio health:</p> <pre><code>health = portfolio.health\n\n# Health assessment structure\n{\n    'overall_score': 82.5,\n    'status': 'Good',\n    'components': {\n        'returns': {\n            'score': 85.0,\n            'status': 'Good'\n        },\n        'risk': {\n            'score': 78.0,\n            'status': 'Good'\n        },\n        'risk_adjusted': {\n            'score': 88.0,\n            'status': 'Good'\n        }\n    }\n}\n</code></pre>"},{"location":"user-guide/portfolio/#health-score-components","title":"Health Score Components","text":"<p>The portfolio health score is calculated based on three main components:</p> <ul> <li>Returns (30%)</li> <li>Absolute Returns</li> <li>Relative Returns</li> <li> <p>Consistency of Returns</p> </li> <li> <p>Risk Metrics (40%)</p> </li> <li>Volatility</li> <li>Value at Risk</li> <li>Maximum Drawdown</li> <li> <p>Recovery Time</p> </li> <li> <p>Risk-Adjusted Performance (30%)</p> </li> <li>Sharpe Ratio</li> <li>Information Ratio</li> <li>Sortino Ratio</li> <li>Treynor Ratio</li> </ul> <p>Each component is scored from 0-100 and assigned a status: - Excellent: \u2265 90 - Good: \u2265 75 - Fair: \u2265 60 - Poor: \u2265 45 - Critical: &lt; 45</p>"},{"location":"user-guide/portfolio/#state-management","title":"State Management","text":"<p>The Portfolio class maintains state for calculated metrics in the <code>_state</code> dictionary:</p> <pre><code># Access stored metrics\nstored_returns = portfolio._state['returns']\nstored_volatility = portfolio._state['volatility']\nstored_sharpe = portfolio._state['sharpe_ratio']\n</code></pre>"},{"location":"user-guide/portfolio/#best-practices","title":"Best Practices","text":""},{"location":"user-guide/portfolio/#1-data-management","title":"1. Data Management","text":"<ul> <li>1.1. Data Quality: Ensure price and return data is clean and properly formatted</li> <li>1.2. Time Consistency: Use consistent time periods for comparative analysis</li> <li>1.3. Adjustments: Account for dividends, splits, and corporate actions</li> </ul>"},{"location":"user-guide/portfolio/#2-risk-assessment","title":"2. Risk Assessment","text":"<ul> <li>2.1. Regular Monitoring: Regularly monitor risk metrics</li> <li>2.2. Multiple Metrics: Use multiple risk measures for comprehensive assessment</li> <li>2.3. Stress Testing: Conduct stress tests under various market scenarios</li> </ul>"},{"location":"user-guide/portfolio/#3-performance-analysis","title":"3. Performance Analysis","text":"<ul> <li>3.1. Benchmark Selection: Choose appropriate benchmarks for relative analysis</li> <li>3.2. Attribution: Analyze sources of returns and risk</li> <li>3.3. Health Monitoring: Regularly assess portfolio health</li> </ul>"},{"location":"user-guide/portfolio/#4-reporting-and-communication","title":"4. Reporting and Communication","text":"<ul> <li>4.1. Clear Visualization: Present portfolio metrics with clear visualizations</li> <li>4.2. Context Provision: Provide context for performance numbers</li> <li>4.3. Consistent Reporting: Maintain consistent reporting formats </li> </ul>"},{"location":"user-guide/service-pricing/","title":"Service Pricing","text":"<p>The <code>ServicePricing</code> class provides a unified interface for calculating various types of service pricing models. It supports tiered pricing, subscription-based pricing, usage-based pricing, dynamic pricing adjustments, volume discounts, and custom pricing rules.</p>"},{"location":"user-guide/service-pricing/#quick-start","title":"Quick Start","text":"<pre><code>from pypulate import ServicePricing\n\n# Initialize pricing calculator\npricing = ServicePricing()\n\n# Calculate tiered pricing\nprice = pricing.calculate_tiered_price(\n    usage_units=1500,\n    tiers={\n        \"0-1000\": 0.10,\n        \"1001-2000\": 0.08,\n        \"2001+\": 0.05\n    }\n)\nprint(f\"Total price: ${price:.2f}\")  # Output: Total price: $140.02\n</code></pre>"},{"location":"user-guide/service-pricing/#features","title":"Features","text":""},{"location":"user-guide/service-pricing/#tiered-pricing","title":"Tiered Pricing","text":"<p>Calculate prices based on usage tiers:</p> <pre><code>tiers = {\n    \"0-1000\": 0.10,    # $0.10 per unit for first 1000 units = $100\n    \"1001-2000\": 0.08, # $0.08 per unit for next 500 units = $40\n    \"2001+\": 0.05      # $0.05 per unit for 2001+ units\n}\n\n# Cumulative pricing (default)\nprice = pricing.calculate_tiered_price(1500, tiers)\n# Result: $140.02\n\n# Non-cumulative pricing\nprice = pricing.calculate_tiered_price(1500, tiers, cumulative=False)\n# Result: $120.00\n</code></pre>"},{"location":"user-guide/service-pricing/#subscription-pricing","title":"Subscription Pricing","text":"<p>Calculate subscription prices with features and discounts:</p> <pre><code>price = pricing.calculate_subscription_price(\n    base_price=99.99,\n    features=['premium', 'api_access'],\n    feature_prices={'premium': 49.99, 'api_access': 29.99},\n    duration_months=12,\n    discount_rate=0.10\n)\n</code></pre>"},{"location":"user-guide/service-pricing/#usage-based-pricing","title":"Usage-Based Pricing","text":"<p>Calculate prices based on multiple usage metrics:</p> <pre><code>usage_metrics = {'api_calls': 1000, 'storage_gb': 50}\nmetric_rates = {'api_calls': 0.001, 'storage_gb': 0.10}\nprice = pricing.calculate_usage_price(\n    usage_metrics,\n    metric_rates,\n    minimum_charge=10.0,\n    maximum_charge=1000.0\n)\n</code></pre>"},{"location":"user-guide/service-pricing/#volume-discounts","title":"Volume Discounts","text":"<p>Apply volume-based discounts:</p> <pre><code>discount_tiers = {\n    100: 0.05,   # 5% discount for 100+ units\n    500: 0.10,   # 10% discount for 500+ units\n    1000: 0.15   # 15% discount for 1000+ units\n}\nprice = pricing.calculate_volume_discount(\n    base_price=10.0,\n    volume=750,\n    discount_tiers=discount_tiers\n)\n</code></pre>"},{"location":"user-guide/service-pricing/#time-based-pricing","title":"Time-Based Pricing","text":"<p>Calculate prices based on time duration with different units and rounding options:</p> <pre><code>price = pricing.calculate_time_based_price(\n    base_price=25.0,      # $25 per hour\n    duration=2.5,         # 2.5 hours\n    time_unit='hour',     # pricing unit (minute, hour, day)\n    minimum_duration=1.0, # minimum billable duration\n    rounding_method='up'  # round up to nearest unit\n)\n# Result: $63.00 (25.0 * 2.5 = 62.5, rounded up to 63)\n\n# Using minutes as the time unit\nprice = pricing.calculate_time_based_price(\n    base_price=0.50,      # $0.50 per minute\n    duration=45,          # 45 minutes\n    time_unit='minute'\n)\n# Result: $23.00 (0.50 * 45 = 22.5, rounded up to 23)\n</code></pre>"},{"location":"user-guide/service-pricing/#freemium-pricing","title":"Freemium Pricing","text":"<p>Calculate prices for freemium models with base features (free up to limits) and premium features:</p> <pre><code>price = pricing.calculate_freemium_price(\n    base_features=['storage', 'api_calls', 'users'],\n    premium_features=['advanced_analytics', 'priority_support'],\n    feature_usage={\n        'storage': 150,           # GB\n        'api_calls': 12000,\n        'users': 25,\n        'advanced_analytics': 100,\n        'priority_support': 1\n    },\n    free_limits={\n        'storage': 100,           # 100 GB free\n        'api_calls': 10000,       # 10,000 calls free\n        'users': 20               # 20 users free\n    },\n    overage_rates={\n        'storage': 0.1,           # $0.1 per GB over limit\n        'api_calls': 0.001,       # $0.001 per call over limit\n        'users': 2.0,             # $2 per user over limit\n        'advanced_analytics': 0.05, # $0.05 per usage unit\n        'priority_support': 50.0   # $50 flat fee (usage=1)\n    }\n)\n</code></pre>"},{"location":"user-guide/service-pricing/#bundle-pricing","title":"Bundle Pricing","text":"<p>Calculate prices for bundled items with combination-specific discounts:</p> <pre><code>price = pricing.calculate_bundle_price(\n    items=['laptop', 'mouse', 'keyboard', 'monitor'],\n    item_prices={\n        'laptop': 1200.0,\n        'mouse': 25.0,\n        'keyboard': 50.0,\n        'monitor': 200.0\n    },\n    bundle_discounts={\n        'laptop+mouse': 0.05,                # 5% off laptop+mouse\n        'keyboard+mouse': 0.10,              # 10% off keyboard+mouse\n        'laptop+keyboard+mouse': 0.15,       # 15% off laptop+keyboard+mouse\n        'laptop+monitor+keyboard+mouse': 0.20 # 20% off complete setup\n    },\n    minimum_bundle_size=2  # minimum items for discount eligibility\n)\n# Result: $1180.00 (20% discount on the complete bundle)\n</code></pre>"},{"location":"user-guide/service-pricing/#peak-pricing","title":"Peak Pricing","text":"<p>Apply different rates based on peak and off-peak hours:</p> <pre><code>price = pricing.calculate_peak_pricing(\n    base_price=50.0,      # base price per unit\n    usage_time=\"14:30\",   # time of usage (2:30 PM)\n    peak_hours={\n        \"monday\": (\"09:00\", \"17:00\"),\n        \"tuesday\": (\"09:00\", \"17:00\"),\n        \"wednesday\": (\"09:00\", \"17:00\"),\n        \"thursday\": (\"09:00\", \"17:00\"),\n        \"friday\": (\"09:00\", \"17:00\"),\n        \"saturday\": (\"10:00\", \"15:00\"),\n        \"sunday\": (\"10:00\", \"15:00\")\n    },\n    peak_multiplier=1.5,      # 50% premium during peak hours\n    off_peak_multiplier=0.8   # 20% discount during off-peak hours\n)\n# Result: $75.00 during peak hours (1.5 * $50)\n# Result: $40.00 during off-peak hours (0.8 * $50)\n</code></pre>"},{"location":"user-guide/service-pricing/#loyalty-pricing","title":"Loyalty Pricing","text":"<p>Calculate prices with loyalty discounts based on customer tenure:</p> <pre><code>result = pricing.calculate_loyalty_price(\n    base_price=100.0,\n    customer_tenure=24,    # months\n    loyalty_tiers={\n        12: 0.05,          # 5% discount after 1 year\n        24: 0.10,          # 10% discount after 2 years\n        36: 0.15           # 15% discount after 3 years\n    },\n    additional_benefits={\n        'free_shipping': 10.0,\n        'priority_support': 15.0\n    }\n)\n# Result is a dictionary with details:\n# {\n#   'loyalty_price': 90.0,           # $100 - 10% discount\n#   'loyalty_tier': 24,              # 2-year tier\n#   'loyalty_discount': 10.0,        # $10 discount\n#   'additional_benefits': {'free_shipping': 10.0, 'priority_support': 15.0}\n# }\n\nprint(f\"Loyalty Price: ${result['loyalty_price']}\")\n</code></pre>"},{"location":"user-guide/service-pricing/#dynamic-pricing","title":"Dynamic Pricing","text":"<p>Adjust prices based on market factors:</p> <pre><code>price = pricing.apply_dynamic_pricing(\n    base_price=100.0,\n    demand_factor=1.2,      # High demand\n    competition_factor=0.9,  # Strong competition\n    seasonality_factor=1.1,  # Peak season\n    min_price=80.0,\n    max_price=150.0\n)\n</code></pre>"},{"location":"user-guide/service-pricing/#custom-pricing-rules","title":"Custom Pricing Rules","text":"<p>Create and apply custom pricing rules:</p> <pre><code># Add a custom holiday pricing rule\npricing.add_custom_pricing_rule(\n    'holiday',\n    lambda price, multiplier: price * multiplier,\n    description=\"Applies holiday season multiplier\"\n)\n\n# Apply the custom rule\nholiday_price = pricing.apply_custom_pricing_rule('holiday', 100.0, 1.2)\n# Result: $120.00\n</code></pre>"},{"location":"user-guide/service-pricing/#price-history-tracking","title":"Price History Tracking","text":"<p>The <code>ServicePricing</code> class automatically tracks pricing calculations:</p> <pre><code># Save current pricing state to history\npricing.save_current_pricing()\n\n# Get pricing history\nhistory = pricing.get_pricing_history()\n</code></pre> <p>Each history entry contains: - Timestamp of the calculation - Pricing details for each calculation type (tiered, subscription, usage, etc.)</p>"},{"location":"user-guide/service-pricing/#best-practices","title":"Best Practices","text":""},{"location":"user-guide/service-pricing/#1-tiered-pricing","title":"1. Tiered Pricing","text":"<ul> <li>1.1. Use cumulative pricing for fair billing across tiers</li> <li>1.2. Ensure tier ranges are continuous without gaps</li> <li>1.3. Use \"+\" suffix for unlimited upper tiers</li> </ul>"},{"location":"user-guide/service-pricing/#2-subscription-pricing","title":"2. Subscription Pricing","text":"<ul> <li>2.1. Set reasonable discount rates for longer subscriptions</li> <li>2.2. Keep feature prices proportional to their value</li> <li>2.3. Consider minimum subscription durations</li> </ul>"},{"location":"user-guide/service-pricing/#3-usage-pricing","title":"3. Usage Pricing","text":"<ul> <li>3.1. Set appropriate minimum charges to cover fixed costs</li> <li>3.2. Use maximum charges to make costs predictable</li> <li>3.3. Choose meaningful usage metrics</li> </ul>"},{"location":"user-guide/service-pricing/#4-time-based-pricing","title":"4. Time-Based Pricing","text":"<ul> <li>4.1. Choose appropriate time units for your service (minute, hour, day)</li> <li>4.2. Set minimum durations to avoid micro-billing</li> <li>4.3. Consider different rounding methods based on industry standards</li> </ul>"},{"location":"user-guide/service-pricing/#5-freemium-pricing","title":"5. Freemium Pricing","text":"<ul> <li>5.1. Clearly separate base (free) and premium features</li> <li>5.2. Set reasonable free limits that provide value but encourage upgrades</li> <li>5.3. Price premium features based on their value proposition</li> </ul>"},{"location":"user-guide/service-pricing/#6-bundle-pricing","title":"6. Bundle Pricing","text":"<ul> <li>6.1. Create meaningful bundles that complement each other</li> <li>6.2. Increase discount rates for larger bundles</li> <li>6.3. Set minimum bundle sizes to prevent abuse</li> </ul>"},{"location":"user-guide/service-pricing/#7-peak-pricing","title":"7. Peak Pricing","text":"<ul> <li>7.1. Define peak hours based on actual usage patterns</li> <li>7.2. Set reasonable multipliers that reflect demand without alienating customers</li> <li>7.3. Consider different peak hours for different days of the week</li> </ul>"},{"location":"user-guide/service-pricing/#8-loyalty-pricing","title":"8. Loyalty Pricing","text":"<ul> <li>8.1. Create meaningful tenure tiers that reward long-term customers</li> <li>8.2. Include additional benefits beyond just discounts</li> <li>8.3. Ensure discounts scale appropriately with tenure</li> </ul>"},{"location":"user-guide/service-pricing/#9-dynamic-pricing","title":"9. Dynamic Pricing","text":"<ul> <li>9.1. Keep market factors between 0.5 and 2.0</li> <li>9.2. Set reasonable price floors and ceilings</li> <li>9.3. Update factors regularly based on market conditions</li> </ul>"},{"location":"user-guide/service-pricing/#10-custom-rules","title":"10. Custom Rules","text":"<ul> <li>10.1. Document rule logic clearly</li> <li>10.2. Validate inputs in custom calculation functions</li> <li>10.3. Consider rule interactions and precedence</li> </ul>"},{"location":"user-guide/service-pricing/#error-handling","title":"Error Handling","text":"<p>The class includes robust error handling:</p> <ul> <li>Invalid tier ranges raise ValueError</li> <li>Missing custom rules raise KeyError</li> <li>Invalid metric names raise KeyError</li> <li>Negative prices raise ValueError</li> </ul>"},{"location":"user-guide/service-pricing/#performance-considerations","title":"Performance Considerations","text":"<ul> <li>Pricing calculations are optimized for speed</li> <li>History tracking has minimal overhead</li> <li>Custom rules are cached for repeated use</li> <li>Large tier structures are handled efficiently </li> </ul>"},{"location":"user-guide/technical/","title":"Technical Analysis","text":"<p>The <code>pypulate.technical</code> module provides a comprehensive set of technical analysis tools for financial time series data. This guide demonstrates practical usage with real market data.</p>"},{"location":"user-guide/technical/#quick-start","title":"Quick Start","text":"<p>Let's start with some sample market data:</p> <pre><code>import numpy as np\nfrom pypulate import Parray\n\n# Sample market data\nnp.random.seed(42)\ndays = 200\nprice = np.cumsum(np.random.normal(0, 1, days)) + 100\n\n# Convert to Parray for analysis\nclose = Parray(price)\n</code></pre>"},{"location":"user-guide/technical/#momentum-indicators","title":"Momentum Indicators","text":""},{"location":"user-guide/technical/#relative-strength-index-rsi","title":"Relative Strength Index (RSI)","text":"<p>RSI measures momentum on a scale of 0 to 100, with readings above 70 indicating overbought conditions and below 30 indicating oversold conditions.</p> <pre><code># Calculate RSI with 14-period lookback\nrsi = close.rsi(14)\nprint(f\"Latest RSI: {rsi[-1]:.2f}\")\n</code></pre>"},{"location":"user-guide/technical/#moving-average-convergence-divergence-macd","title":"Moving Average Convergence Divergence (MACD)","text":"<p>MACD shows the relationship between two moving averages of a price series. Note that MACD calculation requires enough data points to compute both moving averages - the minimum required length is the slow period (typically 26 points).</p> <pre><code># Calculate MACD (12, 26, 9)\nmacd_line, signal_line, histogram = close.macd(12, 26, 9)\nprint(f\"MACD Line: {macd_line[-1]:.2f}\")\nprint(f\"Signal Line: {signal_line[-1]:.2f}\")\nprint(f\"Histogram: {histogram[-1]:.2f}\")\n</code></pre> <p>Note: The traditional MACD settings (12, 26, 9) require at least 26 data points. For shorter time series: - Consider using shorter periods - Ensure your data length is sufficient for the chosen periods - The minimum data length needed = slow_period (second parameter)</p>"},{"location":"user-guide/technical/#volatility-indicators","title":"Volatility Indicators","text":""},{"location":"user-guide/technical/#bollinger-bands","title":"Bollinger Bands","text":"<p>Bollinger Bands consist of a middle band (20-day SMA) with upper and lower bands 2 standard deviations away.</p> <pre><code># Calculate Bollinger Bands\nupper_bb, middle_bb, lower_bb = close.bollinger_bands(20, 2.0)\nprint(f\"Upper Band: {upper_bb[-1]:.2f}\")\nprint(f\"Middle Band: {middle_bb[-1]:.2f}\")\nprint(f\"Lower Band: {lower_bb[-1]:.2f}\")\n</code></pre>"},{"location":"user-guide/technical/#trend-indicators","title":"Trend Indicators","text":""},{"location":"user-guide/technical/#moving-averages","title":"Moving Averages","text":"<pre><code># Calculate different types of moving averages\nsma_20 = close.sma(20)  # Simple Moving Average\nema_20 = close.ema(20)  # Exponential Moving Average\nwma_20 = close.wma(20)  # Weighted Moving Average\n\nprint(f\"20-day SMA: {sma_20[-1]:.2f}\")\nprint(f\"20-day EMA: {ema_20[-1]:.2f}\")\nprint(f\"20-day WMA: {wma_20[-1]:.2f}\")\n</code></pre>"},{"location":"user-guide/technical/#building-trading-strategies","title":"Building Trading Strategies","text":"<p>Here's an example of combining multiple indicators for a trading strategy:</p> <pre><code># Calculate indicators\nrsi = close.rsi(14)\nmacd_line, signal, hist = close.macd(12, 26, 9)\nupper_bb, middle_bb, lower_bb = close.bollinger_bands(20, 2.0)\n\n# Generate trading signals\nbuy_signals = (\n    (rsi &lt; 30) &amp;                  # RSI oversold\n    (macd_line &gt; signal) &amp;        # MACD bullish\n    (close &lt; lower_bb)            # Price below lower Bollinger Band\n)\n\nsell_signals = (\n    (rsi &gt; 70) &amp;                  # RSI overbought\n    (macd_line &lt; signal) &amp;        # MACD bearish\n    (close &gt; upper_bb)            # Price above upper Bollinger Band\n)\n\n# Print latest signals\nprint(\"Latest Signals:\")\nprint(f\"Buy Signal: {buy_signals[-1]}\")\nprint(f\"Sell Signal: {sell_signals[-1]}\")\n</code></pre>"},{"location":"user-guide/technical/#advanced-analysis","title":"Advanced Analysis","text":""},{"location":"user-guide/technical/#logarithmic-returns","title":"Logarithmic Returns","text":"<p>Calculate and analyze logarithmic returns:</p> <pre><code># Calculate log returns\nlog_returns = close.log().diff()\nprint(f\"Latest Log Return: {log_returns[-1]:.4f}\")\n\n# Calculate RSI on log returns\nlog_rsi = close.log().rsi(14)\nprint(f\"RSI of Log Returns: {log_rsi[-1]:.2f}\")\n</code></pre>"},{"location":"user-guide/technical/#statistical-measures","title":"Statistical Measures","text":"<pre><code># Calculate rolling statistics\nvolatility = close.rolling_std(20)\nzscore = close.zscore(20)\n\nprint(f\"20-day Volatility: {volatility[-1]:.2f}\")\nprint(f\"20-day Z-Score: {zscore[-1]:.2f}\")\n</code></pre>"},{"location":"user-guide/technical/#utility-functions","title":"Utility Functions","text":"<p>The module provides various utility functions for common calculations:</p> <pre><code>from pypulate.technical.utils import rolling_max, rolling_min, slope\n\n# Calculate 20-day high and low\nhigh_20 = rolling_max(close, 20)\nlow_20 = rolling_min(close, 20)\n\n# Calculate price slope\nprice_slope = slope(close, 5)\n\nprint(f\"20-day High: {high_20[-1]:.2f}\")\nprint(f\"20-day Low: {low_20[-1]:.2f}\")\nprint(f\"5-day Slope: {price_slope[-1]:.4f}\")\n\n# Calculate top and high from slope of moving averages\ntop_low = close.sma(20).slope()\n</code></pre>"},{"location":"user-guide/transforms/","title":"Transforms","text":"<p>Pypulate provides transforms for identifying patterns especialy price action patterns in financial time series data. This page explains the available transforms and how to use them.</p>"},{"location":"user-guide/transforms/#overview","title":"Overview","text":"<p>Transforms in Pypulate are functions that convert price data into a different representation to identify patterns or significant points. Currently, Pypulate supports two main transforms:</p> <ol> <li>Wave Transform: Identifies wave patterns in price data</li> <li>ZigZag Transform: Identifies significant highs and lows</li> </ol>"},{"location":"user-guide/transforms/#wave-transform","title":"Wave Transform","text":"<p>The wave transform converts OHLC data into a line without losing highs and lows, inspired by Glenn Neely wave chart.</p>"},{"location":"user-guide/transforms/#parameters","title":"Parameters","text":"<ul> <li><code>open</code>: Open prices array</li> <li><code>high</code>: High prices array</li> <li><code>low</code>: Low prices array</li> <li><code>close</code>: Close prices array</li> </ul>"},{"location":"user-guide/transforms/#usage","title":"Usage","text":"<pre><code>from pypulate.transforms import wave\nfrom pypulate import Parray\n\n# Real gold (XAU) OHLC data sample\ndata = {\n    'open': [1936.13, 1935.33, 1938.06, 1947.38, 1943.64, 1942.30, 1947.15, 1945.40, 1944.72, 1943.69,\n             1940.41, 1939.15, 1942.55, 1939.68, 1944.19, 1943.61, 1941.12, 1939.94, 1942.98, 1944.50],\n    'high': [1937.48, 1938.79, 1948.68, 1949.05, 1944.51, 1947.70, 1947.71, 1946.24, 1947.87, 1945.06,\n             1942.03, 1944.03, 1942.61, 1944.45, 1952.94, 1943.61, 1941.34, 1944.02, 1946.06, 1946.32],\n    'low': [1935.16, 1934.91, 1936.62, 1943.12, 1942.04, 1941.94, 1944.43, 1943.19, 1940.27, 1939.03,\n            1939.34, 1938.66, 1938.17, 1938.40, 1940.06, 1934.44, 1939.48, 1939.35, 1942.94, 1940.76],\n    'close': [1935.33, 1938.09, 1947.36, 1943.64, 1942.35, 1947.14, 1945.40, 1944.72, 1943.70, 1940.43,\n              1940.04, 1942.55, 1939.70, 1944.20, 1943.68, 1941.12, 1940.10, 1942.96, 1944.50, 1940.95]\n}\n\nwaves = wave(data['open'], data['high'], data['low'], data['close'])\n</code></pre>"},{"location":"user-guide/transforms/#interpreting-results","title":"Interpreting Results","text":"<p>The wave transform returns a 1D array containing the wave points.</p>"},{"location":"user-guide/transforms/#example","title":"Example","text":"<pre><code>import matplotlib.pylab as plt\nimport numpy as np\n\n# Plot the results\nplt.figure(figsize=(12, 6))\n\nfor i in range(len(data['close'])):\n    plt.plot([i, i], [data['low'][i], data['high'][i]], 'k-', alpha=0.3)\n\n    if data['close'][i] &gt;= data['open'][i]:\n        body_color = 'green'\n    else:\n        body_color = 'red'\n\n    plt.plot([i, i], [data['open'][i], data['close'][i]], color=body_color, linewidth=4)\n\nif len(waves) &gt; 0: \n    indices = np.arange(len(waves))\n    plt.plot(indices, waves, 'b-o', linewidth=2, markersize=5, label='Wave Points')\n\nplt.title('Wave Pattern Detection with Gold (XAU) OHLC Data')\nplt.xlabel('Time Period')\nplt.ylabel('Price (USD)')\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.show()\n</code></pre>"},{"location":"user-guide/transforms/#zigzag-transform","title":"ZigZag Transform","text":"<p>The ZigZag transform identifies significant highs and lows in price data by filtering out smaller price movements.</p>"},{"location":"user-guide/transforms/#parameters_1","title":"Parameters","text":"<ul> <li><code>threshold</code>: Minimum percentage change (0.03 = 3%) required to identify a new pivot point (default: 0.03)</li> </ul>"},{"location":"user-guide/transforms/#usage_1","title":"Usage","text":"<pre><code>import numpy as np\nfrom pypulate.transforms import zigzag\nfrom pypulate import Parray\n\n# Real gold (XAU) price data\nprice = [1935.33, 1938.09, 1947.36, 1943.64, 1942.35, 1947.14, 1945.40, 1944.72, 1943.70, 1940.43,\n         1940.04, 1942.55, 1939.70, 1944.20, 1943.68, 1941.12, 1940.10, 1942.96, 1944.50, 1940.95]\np_array = Parray(price)\n\n# Method 1: Using the function directly\nzz = zigzag(price, threshold=0.0005)  # 0.05% threshold for gold which is less volatile\n\n# Method 2: Using Parray method chaining\nzz = p_array.zigzag(threshold=0.0005)  # 0.05% threshold\n</code></pre>"},{"location":"user-guide/transforms/#interpreting-results_1","title":"Interpreting Results","text":"<p>The zigzag transform returns a array with zigzag pivot points.</p>"},{"location":"user-guide/transforms/#example_1","title":"Example","text":"<pre><code>import matplotlib.pylab as plt\n\n# Plot zigzag points and lines\nplt.figure(figsize=(12, 6))\nplt.plot(price, label='Gold Price', alpha=0.7, color='gold')\n\nif zz.size &gt; 0:\n    plt.plot(zz[:, 0], zz[:, 1], 'ro-', linewidth=2, label='ZigZag')\n\nplt.title('ZigZag Pattern Detection on Gold (XAU) Prices')\nplt.xlabel('Time Period')\nplt.ylabel('Price (USD)')\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.show()\n</code></pre>"},{"location":"user-guide/transforms/#combining-wave-and-zigzag-transforms","title":"Combining Wave and ZigZag Transforms","text":"<p>You can control the wave transform with zigzag as it will filter the mini changes in direction of line by zigzag threshold. This combination is particularly useful for identifying significant wave patterns while filtering out market noise.</p>"},{"location":"user-guide/transforms/#example-filtered-wave-analysis","title":"Example: Filtered Wave Analysis","text":"<pre><code>import numpy as np\nimport matplotlib.pyplot as plt\nfrom pypulate import Parray\nfrom pypulate.transforms import wave, zigzag\n\n# Sample OHLC data\ndata = {\n    'open': [1936.13, 1935.33, 1938.06, 1947.38, 1943.64, 1942.30, 1947.15, 1945.40, 1944.72, 1943.69,\n             1940.41, 1939.15, 1942.55, 1939.68, 1944.19, 1943.61, 1941.12, 1939.94, 1942.98, 1944.50],\n    'high': [1937.48, 1938.79, 1948.68, 1949.05, 1944.51, 1947.70, 1947.71, 1946.24, 1947.87, 1945.06,\n             1942.03, 1944.03, 1942.61, 1944.45, 1952.94, 1943.61, 1941.34, 1944.02, 1946.06, 1946.32],\n    'low': [1935.16, 1934.91, 1936.62, 1943.12, 1942.04, 1941.94, 1944.43, 1943.19, 1940.27, 1939.03,\n            1939.34, 1938.66, 1938.17, 1938.40, 1940.06, 1934.44, 1939.48, 1939.35, 1942.94, 1940.76],\n    'close': [1935.33, 1938.09, 1947.36, 1943.64, 1942.35, 1947.14, 1945.40, 1944.72, 1943.70, 1940.43,\n              1940.04, 1942.55, 1939.70, 1944.20, 1943.68, 1941.12, 1940.10, 1942.96, 1944.50, 1940.95]\n}\n\n# Convert to numpy arrays\nopen_prices = np.array(data['open'])\nhigh_prices = np.array(data['high'])\nlow_prices = np.array(data['low'])\nclose_prices = np.array(data['close'])\n\n# Step 1: Calculate wave points\nwave_points = wave(open_prices, high_prices, low_prices, close_prices)\n\n# Step 2: Apply zigzag to filter the wave points\n# Create a Parray from wave points to use the zigzag method\nwave_parray = Parray(wave_points)\nfiltered_wave = wave_parray.zigzag(threshold=0.005)  # 0.5% threshold\n\n# Create figure and axis\nfig, ax = plt.subplots(figsize=(12, 6))\n\n# Plot OHLC data as candlesticks\nfor i in range(len(close_prices)):\n    # Plot vertical line from low to high (wick)\n    ax.plot([i, i], [low_prices[i], high_prices[i]], 'k-', alpha=0.3)\n\n    # Determine candle color\n    if close_prices[i] &gt;= open_prices[i]:\n        # Bullish candle (close &gt; open)\n        body_color = 'green'\n    else:\n        # Bearish candle (open &gt; close)\n        body_color = 'red'\n\n    # Plot candle body\n    ax.plot([i, i], [open_prices[i], close_prices[i]], color=body_color, linewidth=4)\n\n# Plot original wave points\nindices = np.arange(len(wave_points))\nax.plot(indices, wave_points, 'b-', linewidth=1, alpha=0.5, label='Wave Points')\n\n# Plot filtered wave points\nif filtered_wave.size &gt; 0:\n    ax.plot(filtered_wave[:, 0], filtered_wave[:, 1], 'ro-', linewidth=2, markersize=5, label='Filtered Wave Points')\n\n# Add labels and styling\nax.set_title('Filtered Wave Pattern Detection with ZigZag')\nax.set_xlabel('Time Period')\nax.set_ylabel('Price')\nax.legend()\nax.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n</code></pre> <p>This technique provides several benefits:</p> <ol> <li>Noise Reduction: The zigzag transform filters out minor price fluctuations in the wave pattern</li> <li>Trend Identification: Helps identify the true underlying trend by focusing on significant price movements</li> <li>Signal Clarity: Reduces false signals by eliminating small reversals that don't meet the threshold criteria</li> <li>Visualization Enhancement: Creates a cleaner chart that highlights important price levels and potential reversal points</li> <li>Price Action: This method is super useful for detecting price action patterns from price movement maybe better than candlesticks.</li> </ol> <p>You can adjust the threshold parameter to control the sensitivity of the filtering. A higher threshold will result in fewer, more significant pivot points, while a lower threshold will capture more minor price movements. </p>"},{"location":"user-guide/credit/altman_zscore/","title":"Altman Z-Score","text":"<p>The Altman Z-Score is a financial metric used to predict the probability of a company going bankrupt within the next two years. Developed by Edward I. Altman in 1968, it combines five financial ratios with weighted coefficients to produce a single score that indicates financial health.</p>"},{"location":"user-guide/credit/altman_zscore/#usage-in-pypulate","title":"Usage in Pypulate","text":"<pre><code>from pypulate.credit import altman_z_score\n\n\n# Calculate Altman Z-Score\nresult = altman_z_score(\n    working_capital=120000000,        # Working capital\n    retained_earnings=200000000,      # Retained earnings\n    ebit=80000000,                    # Earnings before interest and taxes\n    market_value_equity=500000000,    # Market value of equity\n    sales=350000000,                  # Sales\n    total_assets=400000000,           # Total assets\n    total_liabilities=150000000       # Total liabilities\n)\n\n# Access the results\nz_score = result['z_score']\nrisk_assessment = result['risk_assessment']\nzone = result['zone']\ncomponents = result['components']\n</code></pre>"},{"location":"user-guide/credit/altman_zscore/#parameters","title":"Parameters","text":"Parameter Type Description Default <code>working_capital</code> float Working capital (current assets - current liabilities) Required <code>retained_earnings</code> float Retained earnings Required <code>ebit</code> float Earnings before interest and taxes Required <code>market_value_equity</code> float Market value of equity Required <code>sales</code> float Annual sales Required <code>total_assets</code> float Total assets Required <code>total_liabilities</code> float Total liabilities Required"},{"location":"user-guide/credit/altman_zscore/#return-value","title":"Return Value","text":"<p>The function returns a dictionary with the following keys:</p> Key Type Description <code>z_score</code> float The calculated Z-Score value <code>risk_assessment</code> str Text description of the bankruptcy risk <code>zone</code> str Classification zone (\"Safe\", \"Grey\", or \"Distress\") <code>interpretation</code> str Same as risk_assessment (for compatibility) <code>components</code> dict Dictionary containing the individual ratio components <p>The <code>components</code> dictionary includes:</p> <ul> <li><code>x1</code>: Working capital / Total assets</li> <li><code>x2</code>: Retained earnings / Total assets</li> <li><code>x3</code>: EBIT / Total assets</li> <li><code>x4</code>: Market value of equity / Total liabilities</li> <li><code>x5</code>: Sales / Total assets</li> </ul>"},{"location":"user-guide/credit/altman_zscore/#risk-level-classification","title":"Risk Level Classification","text":"<p>The Z-Score is categorized into risk zones:</p> Z-Score Range Risk Zone &gt; 2.99 Safe Zone 1.81 - 2.99 Grey Zone &lt; 1.81 Distress Zone"},{"location":"user-guide/credit/altman_zscore/#comprehensive-example","title":"Comprehensive Example","text":"<p>Here's a complete example analyzing three companies with different financial profiles:</p> <pre><code>from pypulate.credit import altman_z_score\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n\n# Example 1: Financially healthy manufacturing company\nhealthy_company = altman_z_score(\n    working_capital=120000000,        # $120M working capital\n    retained_earnings=200000000,      # $200M retained earnings\n    ebit=80000000,                    # $80M earnings before interest and taxes\n    market_value_equity=500000000,    # $500M market value of equity\n    sales=350000000,                  # $350M annual sales\n    total_assets=400000000,           # $400M total assets\n    total_liabilities=150000000       # $150M total liabilities\n)\n\n# Example 2: Company in the \"grey zone\"\ngrey_zone_company = altman_z_score(\n    working_capital=30000000,         # $30M working capital\n    retained_earnings=40000000,       # $40M retained earnings\n    ebit=25000000,                    # $25M earnings before interest and taxes\n    market_value_equity=120000000,    # $120M market value of equity\n    sales=200000000,                  # $200M annual sales\n    total_assets=250000000,           # $250M total assets\n    total_liabilities=150000000       # $150M total liabilities\n)\n\n# Example 3: Financially distressed company\ndistressed_company = altman_z_score(\n    working_capital=5000000,          # $5M working capital\n    retained_earnings=-20000000,      # -$20M retained earnings (accumulated losses)\n    ebit=-8000000,                    # -$8M earnings before interest and taxes (operating loss)\n    market_value_equity=30000000,     # $30M market value of equity\n    sales=100000000,                  # $100M annual sales\n    total_assets=150000000,           # $150M total assets\n    total_liabilities=120000000       # $120M total liabilities\n)\n\n# Print the results\nprint(\"Altman Z-Score Analysis\")\nprint(\"======================\")\n\nprint(\"\\nExample 1: Financially Healthy Company\")\nprint(f\"Z-Score: {healthy_company['z_score']:.2f}\")\nprint(f\"Risk Assessment: {healthy_company['risk_assessment']}\")\nprint(f\"Zone: {healthy_company['zone']}\")\nprint(\"Component Values:\")\nfor component, value in healthy_company['components'].items():\n    print(f\"  {component}: {value:.4f}\")\n\nprint(\"\\nExample 2: Grey Zone Company\")\nprint(f\"Z-Score: {grey_zone_company['z_score']:.2f}\")\nprint(f\"Risk Assessment: {grey_zone_company['risk_assessment']}\")\nprint(f\"Zone: {grey_zone_company['zone']}\")\nprint(\"Component Values:\")\nfor component, value in grey_zone_company['components'].items():\n    print(f\"  {component}: {value:.4f}\")\n\nprint(\"\\nExample 3: Financially Distressed Company\")\nprint(f\"Z-Score: {distressed_company['z_score']:.2f}\")\nprint(f\"Risk Assessment: {distressed_company['risk_assessment']}\")\nprint(f\"Zone: {distressed_company['zone']}\")\nprint(\"Component Values:\")\nfor component, value in distressed_company['components'].items():\n    print(f\"  {component}: {value:.4f}\")\n\n# Visualize the results\ncompanies = ['Healthy', 'Grey Zone', 'Distressed']\nz_scores = [\n    healthy_company['z_score'],\n    grey_zone_company['z_score'],\n    distressed_company['z_score']\n]\n\n# Create a bar chart\nplt.figure(figsize=(10, 6))\nbars = plt.bar(companies, z_scores, color=['green', 'orange', 'red'])\n\n# Add horizontal lines for the Z-score thresholds\nplt.axhline(y=1.81, color='r', linestyle='--', label='Distress Zone (Z &lt; 1.81)')\nplt.axhline(y=2.99, color='g', linestyle='--', label='Safe Zone (Z &gt; 2.99)')\nplt.axhspan(1.81, 2.99, alpha=0.2, color='orange', label='Grey Zone (1.81 &lt; Z &lt; 2.99)')\n\n# Add labels and title\nplt.ylabel('Altman Z-Score')\nplt.title('Altman Z-Score Comparison')\nplt.ylim(bottom=0)  # Start y-axis at 0\n\n# Add the Z-score values on top of the bars\nfor bar in bars:\n    height = bar.get_height()\n    plt.text(bar.get_x() + bar.get_width()/2., height + 0.1,\n             f'{height:.2f}', ha='center', va='bottom')\n\nplt.legend()\nplt.tight_layout()\nplt.show()\n</code></pre>"},{"location":"user-guide/credit/altman_zscore/#example-output","title":"Example Output","text":"<pre><code>Altman Z-Score Analysis\n======================\nExample 1: Financially Healthy Company\nZ-Score: 4.59\nRisk Assessment: Low risk of bankruptcy\nZone: Safe\nComponent Values:\n  x1: 0.3000\n  x2: 0.5000\n  x3: 0.2000\n  x4: 3.3333\n  x5: 0.8750\nExample 2: Grey Zone Company\nZ-Score: 1.98\nRisk Assessment: Grey area, moderate risk\nZone: Grey\nComponent Values:\n  x1: 0.1200\n  x2: 0.1600\n  x3: 0.1000\n  x4: 0.8000\n  x5: 0.8000\nExample 3: Financially Distressed Company\nZ-Score: 0.49\nRisk Assessment: High risk of bankruptcy\nZone: Distress\nComponent Values:\n  x1: 0.0333\n  x2: -0.1333\n  x3: -0.0533\n  x4: 0.2500\n  x5: 0.6667\n</code></pre>"},{"location":"user-guide/credit/altman_zscore/#visualization","title":"Visualization","text":"<p>The visualization shows the Z-scores for three example companies, with horizontal lines indicating the threshold values that separate the Safe, Grey, and Distress zones.</p>"},{"location":"user-guide/credit/altman_zscore/#component-analysis","title":"Component Analysis","text":"<p>Each component of the Z-Score provides insight into different aspects of a company's financial health:</p> <ol> <li> <p>X\u2081 (Working Capital / Total Assets)</p> <ul> <li>Measures liquidity relative to company size</li> <li>Higher values indicate better short-term financial health</li> <li>Weight: 1.2</li> </ul> </li> <li> <p>X\u2082 (Retained Earnings / Total Assets)</p> <ul> <li>Measures cumulative profitability and company age</li> <li>Higher values indicate stronger historical performance</li> <li>Weight: 1.4</li> </ul> </li> <li> <p>X\u2083 (EBIT / Total Assets)</p> <ul> <li>Measures operating efficiency independent of tax and leverage</li> <li>Has the highest weight (3.3), indicating its importance</li> <li>Higher values indicate better operational performance</li> </ul> </li> <li> <p>X\u2084 (Market Value of Equity / Total Liabilities)</p> <ul> <li>Measures financial leverage and market confidence</li> <li>Higher values indicate lower financial risk</li> <li>Weight: 0.6</li> </ul> </li> <li> <p>X\u2085 (Sales / Total Assets)</p> <ul> <li>Measures asset turnover and management efficiency</li> <li>Higher values indicate better utilization of assets</li> <li>Weight: 0.999</li> </ul> </li> </ol>"},{"location":"user-guide/credit/altman_zscore/#practical-applications","title":"Practical Applications","text":"<p>The Altman Z-Score can be used for:</p> <ol> <li>Credit Risk Assessment: Evaluating potential borrowers' bankruptcy risk</li> <li>Investment Screening: Identifying financially stable companies</li> <li>Portfolio Risk Management: Monitoring existing investments</li> <li>Supplier Evaluation: Assessing the financial stability of key suppliers</li> <li>Merger &amp; Acquisition Analysis: Evaluating target companies</li> </ol>"},{"location":"user-guide/credit/altman_zscore/#limitations","title":"Limitations","text":"<p>While the Altman Z-Score is a powerful tool, it has some limitations:</p> <ol> <li>Originally developed for manufacturing companies</li> <li>May need industry-specific adjustments</li> <li>Works best for public companies with market value data</li> <li>Should be used alongside other financial metrics</li> <li>Historical performance may not predict future outcomes</li> </ol>"},{"location":"user-guide/credit/debt_service_coverage_ratio/","title":"Debt Service Coverage Ratio (DSCR)","text":"<p>The <code>debt_service_coverage_ratio</code> function calculates the Debt Service Coverage Ratio (DSCR), a key financial metric used to assess a borrower's ability to repay debt. This ratio is widely used in commercial real estate lending, corporate finance, and credit risk assessment.</p>"},{"location":"user-guide/credit/debt_service_coverage_ratio/#usage-in-pypulate","title":"Usage in Pypulate","text":"<pre><code>from pypulate.credit import debt_service_coverage_ratio\n\n# Calculate DSCR\nresult = debt_service_coverage_ratio(\n    net_operating_income=500000,  # $500,000 net operating income\n    total_debt_service=300000     # $300,000 total debt service\n)\n\n# Access the results\ndscr = result[\"dscr\"]\nassessment = result[\"assessment\"]\nrating = result[\"rating\"]\n</code></pre>"},{"location":"user-guide/credit/debt_service_coverage_ratio/#parameters","title":"Parameters","text":"Parameter Type Description Default <code>net_operating_income</code> float Net operating income of the borrower Required <code>total_debt_service</code> float Total debt service obligations (principal, interest, lease payments, etc.) Required"},{"location":"user-guide/credit/debt_service_coverage_ratio/#return-value","title":"Return Value","text":"<p>The function returns a dictionary with the following keys:</p> Key Type Description <code>dscr</code> float The calculated Debt Service Coverage Ratio <code>assessment</code> str Text description of the risk level <code>rating</code> str Categorical rating (\"Poor\", \"Fair\", \"Good\", or \"Excellent\")"},{"location":"user-guide/credit/debt_service_coverage_ratio/#risk-level-classification","title":"Risk Level Classification","text":"<p>The DSCR is categorized into risk levels:</p> DSCR Range Risk Level &lt; 1.0 Poor 1.0 - 1.25 Fair 1.25 - 1.5 Good &gt; 1.5 Excellent"},{"location":"user-guide/credit/debt_service_coverage_ratio/#comprehensive-example","title":"Comprehensive Example","text":"<p>Here's a complete example demonstrating how to calculate and analyze DSCR for different borrowers:</p> <pre><code>from pypulate.credit import debt_service_coverage_ratio\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Example 1: Strong borrower with high income relative to debt\nstrong_borrower = debt_service_coverage_ratio(\n    net_operating_income=800000,  # $800,000 net operating income\n    total_debt_service=400000     # $400,000 total debt service\n)\n\n# Example 2: Average borrower with moderate coverage\naverage_borrower = debt_service_coverage_ratio(\n    net_operating_income=450000,  # $450,000 net operating income\n    total_debt_service=350000     # $350,000 total debt service\n)\n\n# Example 3: Weak borrower with insufficient coverage\nweak_borrower = debt_service_coverage_ratio(\n    net_operating_income=280000,  # $280,000 net operating income\n    total_debt_service=300000     # $300,000 total debt service\n)\n\n# Print the results\nprint(\"Debt Service Coverage Ratio Analysis\")\nprint(\"===================================\")\n\nprint(\"\\nExample 1: Strong Borrower\")\nprint(f\"DSCR: {strong_borrower['dscr']:.2f}\")\nprint(f\"Assessment: {strong_borrower['assessment']}\")\nprint(f\"Rating: {strong_borrower['rating']}\")\n\nprint(\"\\nExample 2: Average Borrower\")\nprint(f\"DSCR: {average_borrower['dscr']:.2f}\")\nprint(f\"Assessment: {average_borrower['assessment']}\")\nprint(f\"Rating: {average_borrower['rating']}\")\n\nprint(\"\\nExample 3: Weak Borrower\")\nprint(f\"DSCR: {weak_borrower['dscr']:.2f}\")\nprint(f\"Assessment: {weak_borrower['assessment']}\")\nprint(f\"Rating: {weak_borrower['rating']}\")\n\n# Visualize the results\nborrowers = ['Weak', 'Average', 'Strong']\ndscr_values = [\n    weak_borrower['dscr'],\n    average_borrower['dscr'],\n    strong_borrower['dscr']\n]\n\n# Create a bar chart\nplt.figure(figsize=(10, 6))\nbars = plt.bar(borrowers, dscr_values, color=['red', 'orange', 'green'])\n\n# Add horizontal lines for the DSCR thresholds\nplt.axhline(y=1.0, color='r', linestyle='--', label='Poor/Fair Threshold (1.0)')\nplt.axhline(y=1.25, color='orange', linestyle='--', label='Fair/Good Threshold (1.25)')\nplt.axhline(y=1.5, color='g', linestyle='--', label='Good/Excellent Threshold (1.5)')\n\n# Add labels and title\nplt.ylabel('Debt Service Coverage Ratio')\nplt.title('DSCR Comparison')\nplt.ylim(bottom=0)  # Start y-axis at 0\n\n# Add the DSCR values on top of the bars\nfor bar in bars:\n    height = bar.get_height()\n    plt.text(bar.get_x() + bar.get_width()/2., height + 0.05,\n             f'{height:.2f}', ha='center', va='bottom')\n\nplt.legend()\nplt.tight_layout()\nplt.show()\n\n# Create a sensitivity analysis\nincome_values = np.linspace(200000, 1000000, 100)  # Range of income values\ndebt_service = 400000  # Fixed debt service\n\ndscr_values = [income / debt_service for income in income_values]\nratings = []\n\nfor dscr in dscr_values:\n    if dscr &lt; 1.0:\n        ratings.append(\"Poor\")\n    elif dscr &lt; 1.25:\n        ratings.append(\"Fair\")\n    elif dscr &lt; 1.5:\n        ratings.append(\"Good\")\n    else:\n        ratings.append(\"Excellent\")\n\n# Create a plot showing how DSCR changes with income\nplt.figure(figsize=(12, 6))\n\n# Plot DSCR curve\nplt.plot(income_values, dscr_values, 'b-', linewidth=2)\n\n# Add colored regions for different ratings\npoor_indices = [i for i, r in enumerate(ratings) if r == \"Poor\"]\nfair_indices = [i for i, r in enumerate(ratings) if r == \"Fair\"]\ngood_indices = [i for i, r in enumerate(ratings) if r == \"Good\"]\nexcellent_indices = [i for i, r in enumerate(ratings) if r == \"Excellent\"]\n\nif poor_indices:\n    plt.fill_between(income_values[min(poor_indices):max(poor_indices)+1], \n                     0, dscr_values[min(poor_indices):max(poor_indices)+1], \n                     color='red', alpha=0.3, label='Poor')\nif fair_indices:\n    plt.fill_between(income_values[min(fair_indices):max(fair_indices)+1], \n                     0, dscr_values[min(fair_indices):max(fair_indices)+1], \n                     color='orange', alpha=0.3, label='Fair')\nif good_indices:\n    plt.fill_between(income_values[min(good_indices):max(good_indices)+1], \n                     0, dscr_values[min(good_indices):max(good_indices)+1], \n                     color='yellow', alpha=0.3, label='Good')\nif excellent_indices:\n    plt.fill_between(income_values[min(excellent_indices):max(excellent_indices)+1], \n                     0, dscr_values[min(excellent_indices):max(excellent_indices)+1], \n                     color='green', alpha=0.3, label='Excellent')\n\n# Add horizontal lines for the DSCR thresholds\nplt.axhline(y=1.0, color='r', linestyle='--')\nplt.axhline(y=1.25, color='orange', linestyle='--')\nplt.axhline(y=1.5, color='g', linestyle='--')\n\n# Add labels and title\nplt.xlabel('Net Operating Income ($)')\nplt.ylabel('Debt Service Coverage Ratio')\nplt.title('DSCR Sensitivity to Income (Fixed Debt Service: $400,000)')\nplt.grid(True, linestyle='--', alpha=0.7)\nplt.legend()\nplt.tight_layout()\nplt.show()\n</code></pre>"},{"location":"user-guide/credit/debt_service_coverage_ratio/#example-output","title":"Example Output","text":"<pre><code>Debt Service Coverage Ratio Analysis\n===================================\n\nExample 1: Strong Borrower\nDSCR: 2.00\nAssessment: Strong coverage, low risk\nRating: Excellent\n\nExample 2: Average Borrower\nDSCR: 1.29\nAssessment: Sufficient coverage, acceptable risk\nRating: Good\n\nExample 3: Weak Borrower\nDSCR: 0.93\nAssessment: Negative cash flow, high risk\nRating: Poor\n</code></pre>"},{"location":"user-guide/credit/debt_service_coverage_ratio/#visualizations","title":"Visualizations","text":""},{"location":"user-guide/credit/debt_service_coverage_ratio/#dscr-comparison","title":"DSCR Comparison","text":"<p>This visualization shows the DSCR values for three example borrowers, with horizontal lines indicating the threshold values that separate the rating categories.</p>"},{"location":"user-guide/credit/debt_service_coverage_ratio/#dscr-sensitivity-analysis","title":"DSCR Sensitivity Analysis","text":"<p>This visualization demonstrates how the DSCR changes with varying levels of net operating income while keeping debt service constant, highlighting the income thresholds for different rating categories.</p> <p></p>"},{"location":"user-guide/credit/debt_service_coverage_ratio/#practical-applications","title":"Practical Applications","text":"<p>The DSCR can be used for:</p> <ol> <li>Commercial Real Estate Lending: Evaluating property cash flow relative to debt obligations</li> <li>Corporate Credit Analysis: Assessing a company's ability to service its debt</li> <li>Project Finance: Determining the financial viability of infrastructure projects</li> <li>Small Business Lending: Evaluating loan applications from small businesses</li> <li>Risk-Based Pricing: Setting interest rates based on the borrower's repayment capacity</li> </ol>"},{"location":"user-guide/credit/debt_service_coverage_ratio/#industry-standards","title":"Industry Standards","text":"<p>Different lenders and industries may use slightly different DSCR thresholds:</p> <ol> <li> <p>Commercial Real Estate:</p> <ul> <li>Typically requires DSCR \u2265 1.25</li> <li>Premium properties may require DSCR \u2265 1.5</li> <li>Riskier properties may accept DSCR \u2265 1.15</li> </ul> </li> <li> <p>Corporate Lending:</p> <ul> <li>Investment grade: DSCR \u2265 1.5</li> <li>Non-investment grade: DSCR \u2265 1.2</li> <li>Distressed: DSCR &lt; 1.0</li> </ul> </li> <li> <p>Small Business Administration (SBA):</p> <ul> <li>Generally requires DSCR \u2265 1.15</li> <li>May consider global DSCR including owner's personal income</li> </ul> </li> </ol>"},{"location":"user-guide/credit/debt_service_coverage_ratio/#best-practices","title":"Best Practices","text":"<ol> <li>Historical Analysis: Calculate DSCR using historical data to establish trends</li> <li>Stress Testing: Test DSCR under adverse scenarios (e.g., reduced income, increased interest rates)</li> <li>Industry Comparison: Compare DSCR to industry benchmarks</li> <li>Global DSCR: Consider all sources of income and all debt obligations</li> <li>Forward-Looking: Project future DSCR based on expected changes in income and debt</li> </ol>"},{"location":"user-guide/credit/expected_credit_loss/","title":"Expected Credit Loss (ECL)","text":"<p>The <code>expected_credit_loss</code> function calculates the Expected Credit Loss (ECL), a critical metric in credit risk management that estimates the probability-weighted loss on a financial asset. This metric is widely used in banking, lending, and financial risk management, especially since the introduction of IFRS 9 and similar accounting standards.</p>","boost":2},{"location":"user-guide/credit/expected_credit_loss/#usage-in-pypulate","title":"Usage in Pypulate","text":"<pre><code>from pypulate.credit import expected_credit_loss\n\n# Calculate ECL\nresult = expected_credit_loss(\n    pd=0.05,           # 5% probability of default\n    lgd=0.4,           # 40% loss given default\n    ead=1000000,       # $1,000,000 exposure at default\n    time_horizon=1.0,  # 1 year time horizon\n    discount_rate=0.03 # 3% discount rate\n)\n\n# Access the results\necl = result[\"expected_credit_loss\"]\nlifetime_ecl = result[\"lifetime_ecl\"]\nrisk_level = result[\"risk_level\"]\n</code></pre>","boost":2},{"location":"user-guide/credit/expected_credit_loss/#parameters","title":"Parameters","text":"Parameter Type Description Default <code>pd</code> float Probability of default (between 0 and 1) Required <code>lgd</code> float Loss given default (between 0 and 1) Required <code>ead</code> float Exposure at default Required <code>time_horizon</code> float Time horizon in years 1.0 <code>discount_rate</code> float Discount rate for future losses 0.0","boost":2},{"location":"user-guide/credit/expected_credit_loss/#return-value","title":"Return Value","text":"<p>The function returns a dictionary with the following keys:</p> Key Type Description <code>expected_credit_loss</code> float The calculated ECL value <code>lifetime_ecl</code> float The lifetime expected credit loss <code>expected_loss_rate</code> float The product of PD and LGD <code>risk_level</code> str Risk level categorization (\"Very Low\", \"Low\", \"Moderate\", \"High\", or \"Very High\") <code>components</code> dict Dictionary containing calculation components <p>The <code>components</code> dictionary includes:</p> <ul> <li><code>pd</code>: Probability of default</li> <li><code>lgd</code>: Loss given default</li> <li><code>ead</code>: Exposure at default</li> <li><code>time_horizon</code>: Time horizon in years</li> <li><code>discount_rate</code>: Discount rate for future losses</li> <li><code>discount_factor</code>: Calculated discount factor based on time horizon and discount rate</li> </ul>","boost":2},{"location":"user-guide/credit/expected_credit_loss/#risk-level-classification","title":"Risk Level Classification","text":"<p>The Expected Loss Rate (PD \u00d7 LGD) is categorized into risk levels:</p> Expected Loss Rate Range Risk Level &lt; 1% Very Low 1% - 3% Low 3% - 7% Moderate 7% - 15% High &gt; 15% Very High","boost":2},{"location":"user-guide/credit/expected_credit_loss/#comprehensive-example","title":"Comprehensive Example","text":"<p>Here's a complete example demonstrating how to calculate and analyze ECL for different loan portfolios:</p> <pre><code>from pypulate.credit import expected_credit_loss\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Example 1: Low-risk corporate loan\nlow_risk_loan = expected_credit_loss(\n    pd=0.01,           # 1% probability of default\n    lgd=0.3,           # 30% loss given default\n    ead=2000000,       # $2,000,000 exposure\n    time_horizon=1.0,  # 1 year\n    discount_rate=0.02 # 2% discount rate\n)\n\n# Example 2: Medium-risk SME loan\nmedium_risk_loan = expected_credit_loss(\n    pd=0.05,           # 5% probability of default\n    lgd=0.45,          # 45% loss given default\n    ead=500000,        # $500,000 exposure\n    time_horizon=1.0,  # 1 year\n    discount_rate=0.02 # 2% discount rate\n)\n\n# Example 3: High-risk unsecured consumer loan\nhigh_risk_loan = expected_credit_loss(\n    pd=0.15,           # 15% probability of default\n    lgd=0.65,          # 65% loss given default\n    ead=50000,         # $50,000 exposure\n    time_horizon=1.0,  # 1 year\n    discount_rate=0.02 # 2% discount rate\n)\n\n# Print the results\nprint(\"Expected Credit Loss Analysis\")\nprint(\"============================\")\n\nprint(\"\\nExample 1: Low-risk Corporate Loan\")\nprint(f\"ECL: ${low_risk_loan['expected_credit_loss']:.2f}\")\nprint(f\"Expected Loss Rate: {low_risk_loan['expected_loss_rate']:.2%}\")\nprint(f\"Risk Level: {low_risk_loan['risk_level']}\")\n\nprint(\"\\nExample 2: Medium-risk SME Loan\")\nprint(f\"ECL: ${medium_risk_loan['expected_credit_loss']:.2f}\")\nprint(f\"Expected Loss Rate: {medium_risk_loan['expected_loss_rate']:.2%}\")\nprint(f\"Risk Level: {medium_risk_loan['risk_level']}\")\n\nprint(\"\\nExample 3: High-risk Consumer Loan\")\nprint(f\"ECL: ${high_risk_loan['expected_credit_loss']:.2f}\")\nprint(f\"Expected Loss Rate: {high_risk_loan['expected_loss_rate']:.2%}\")\nprint(f\"Risk Level: {high_risk_loan['risk_level']}\")\n\n# Create a DataFrame for visualization\nloan_types = ['Corporate Loan', 'SME Loan', 'Consumer Loan']\necl_values = [\n    low_risk_loan['expected_credit_loss'],\n    medium_risk_loan['expected_credit_loss'],\n    high_risk_loan['expected_credit_loss']\n]\nloss_rates = [\n    low_risk_loan['expected_loss_rate'],\n    medium_risk_loan['expected_loss_rate'],\n    high_risk_loan['expected_loss_rate']\n]\nexposures = [2000000, 500000, 50000]\nrisk_levels = [\n    low_risk_loan['risk_level'],\n    medium_risk_loan['risk_level'],\n    high_risk_loan['risk_level']\n]\n\n# Create a bar chart for ECL comparison\nplt.figure(figsize=(12, 6))\nbars = plt.bar(loan_types, ecl_values, color=['green', 'orange', 'red'])\n\n# Add labels and title\nplt.ylabel('Expected Credit Loss ($)')\nplt.title('Expected Credit Loss Comparison')\nplt.grid(axis='y', linestyle='--', alpha=0.7)\n\n# Add the ECL values on top of the bars\nfor bar in bars:\n    height = bar.get_height()\n    plt.text(bar.get_x() + bar.get_width()/2., height + 0.05 * max(ecl_values),\n             f'${height:.2f}', ha='center', va='bottom')\n\nplt.tight_layout()\nplt.show()\n\n# Create a scatter plot showing the relationship between exposure and ECL\nplt.figure(figsize=(12, 6))\n\n# Create a scatter plot with size proportional to exposure\nsizes = [exposure/5000 for exposure in exposures]  # Scale for better visualization\ncolors = ['green', 'orange', 'red']\n\nfor i, loan_type in enumerate(loan_types):\n    plt.scatter(loss_rates[i], ecl_values[i], s=sizes[i], \n                color=colors[i], alpha=0.7, label=f\"{loan_type} (EAD: ${exposures[i]:,})\")\n\n# Add labels and title\nplt.xlabel('Expected Loss Rate (PD \u00d7 LGD)')\nplt.ylabel('Expected Credit Loss ($)')\nplt.title('ECL vs. Expected Loss Rate (Size represents Exposure at Default)')\nplt.grid(True, linestyle='--', alpha=0.7)\n\n# Add risk level regions\nplt.axvspan(0, 0.01, alpha=0.2, color='green', label='Very Low Risk')\nplt.axvspan(0.01, 0.03, alpha=0.2, color='lightgreen', label='Low Risk')\nplt.axvspan(0.03, 0.07, alpha=0.2, color='yellow', label='Moderate Risk')\nplt.axvspan(0.07, 0.15, alpha=0.2, color='orange', label='High Risk')\nplt.axvspan(0.15, 1, alpha=0.2, color='red', label='Very High Risk')\n\nplt.legend(loc='right', bbox_to_anchor=(1.25, 0.5), fontsize=9)\nplt.tight_layout()\nplt.show()\n\n# Create a sensitivity analysis for PD and LGD\npd_values = np.linspace(0.01, 0.2, 20)\nlgd_values = np.linspace(0.1, 0.9, 20)\nPD, LGD = np.meshgrid(pd_values, lgd_values)\nELR = PD * LGD  # Expected Loss Rate\n\n# Create risk level categories\nrisk_levels = np.zeros_like(ELR, dtype=str)\nrisk_levels = np.where(ELR &lt; 0.01, 'Very Low', risk_levels)\nrisk_levels = np.where((ELR &gt;= 0.01) &amp; (ELR &lt; 0.03), 'Low', risk_levels)\nrisk_levels = np.where((ELR &gt;= 0.03) &amp; (ELR &lt; 0.07), 'Moderate', risk_levels)\nrisk_levels = np.where((ELR &gt;= 0.07) &amp; (ELR &lt; 0.15), 'High', risk_levels)\nrisk_levels = np.where(ELR &gt;= 0.15, 'Very High', risk_levels)\n\n# Create a heatmap\nplt.figure(figsize=(12, 8))\ncontour = plt.contourf(PD, LGD, ELR, levels=20, cmap='RdYlGn_r')\nplt.colorbar(contour, label='Expected Loss Rate (PD \u00d7 LGD)')\n\n# Add contour lines for risk level boundaries\nplt.contour(PD, LGD, ELR, levels=[0.01, 0.03, 0.07, 0.15], colors='black', linestyles='dashed')\n\n# Add labels for risk regions\nplt.text(0.005, 0.5, 'Very Low Risk', rotation=90, va='center', ha='center', color='black', fontweight='bold')\nplt.text(0.02, 0.5, 'Low Risk', rotation=90, va='center', ha='center', color='black', fontweight='bold')\nplt.text(0.05, 0.5, 'Moderate Risk', rotation=90, va='center', ha='center', color='black', fontweight='bold')\nplt.text(0.11, 0.5, 'High Risk', rotation=90, va='center', ha='center', color='black', fontweight='bold')\nplt.text(0.175, 0.5, 'Very High Risk', rotation=90, va='center', ha='center', color='black', fontweight='bold')\n\n# Add labels and title\nplt.xlabel('Probability of Default (PD)')\nplt.ylabel('Loss Given Default (LGD)')\nplt.title('Risk Level Sensitivity to PD and LGD')\nplt.grid(True, linestyle='--', alpha=0.3)\nplt.tight_layout()\nplt.show()\n</code></pre>","boost":2},{"location":"user-guide/credit/expected_credit_loss/#example-output","title":"Example Output","text":"<pre><code>Expected Credit Loss Analysis\n============================\n\nExample 1: Low-risk Corporate Loan\nECL: $5882.35\nExpected Loss Rate: 0.30%\nRisk Level: Very Low\n\nExample 2: Medium-risk SME Loan\nECL: $11029.41\nExpected Loss Rate: 2.25%\nRisk Level: Low\n\nExample 3: High-risk Consumer Loan\nECL: $4779.41\nExpected Loss Rate: 9.75%\nRisk Level: High\n</code></pre>","boost":2},{"location":"user-guide/credit/expected_credit_loss/#visualizations","title":"Visualizations","text":"","boost":2},{"location":"user-guide/credit/expected_credit_loss/#ecl-comparison","title":"ECL Comparison","text":"<p>This visualization compares the Expected Credit Loss for three different loan types, showing how the combination of risk factors and exposure amounts affects the total expected loss.</p>","boost":2},{"location":"user-guide/credit/expected_credit_loss/#ecl-vs-expected-loss-rate","title":"ECL vs. Expected Loss Rate","text":"<p>This scatter plot shows the relationship between the Expected Loss Rate (PD \u00d7 LGD) and the resulting ECL, with the size of each point representing the Exposure at Default. The background is color-coded to indicate different risk level regions.</p> <p></p>","boost":2},{"location":"user-guide/credit/expected_credit_loss/#risk-level-sensitivity","title":"Risk Level Sensitivity","text":"<p>This heatmap demonstrates how the risk level changes with different combinations of PD and LGD, helping to visualize the sensitivity of the Expected Loss Rate to these two key parameters.</p> <p></p>","boost":2},{"location":"user-guide/credit/expected_credit_loss/#practical-applications","title":"Practical Applications","text":"<p>The Expected Credit Loss can be used for:</p> <ol> <li>IFRS 9 / CECL Compliance: Meeting accounting standards for loan loss provisioning</li> <li>Credit Risk Management: Quantifying and managing credit risk in loan portfolios</li> <li>Loan Pricing: Incorporating expected losses into loan pricing models</li> <li>Capital Allocation: Determining economic capital requirements for credit risk</li> <li>Portfolio Management: Optimizing the risk-return profile of loan portfolios</li> <li>Stress Testing: Assessing the impact of adverse economic scenarios on credit losses</li> <li>Risk-Based Limits: Setting exposure limits based on expected loss considerations</li> </ol>","boost":2},{"location":"user-guide/credit/expected_credit_loss/#industry-standards","title":"Industry Standards","text":"<p>Different financial institutions and regulatory frameworks may use slightly different approaches:</p> <ol> <li> <p>Banking (Basel Framework):</p> <ul> <li>Uses PD, LGD, and EAD for regulatory capital calculations</li> <li>Typically requires through-the-cycle PD estimates</li> <li>Downturn LGD estimates for capital adequacy</li> </ul> </li> <li> <p>Accounting Standards:</p> <ul> <li>IFRS 9: Forward-looking, point-in-time estimates with multiple economic scenarios</li> <li>CECL: Lifetime expected losses from origination</li> <li>Both require consideration of past events, current conditions, and reasonable forecasts</li> </ul> </li> <li> <p>Credit Rating Agencies:</p> <ul> <li>Provide expected loss estimates based on historical default and recovery data</li> <li>Often use through-the-cycle methodologies for stability</li> </ul> </li> </ol>","boost":2},{"location":"user-guide/credit/expected_credit_loss/#best-practices","title":"Best Practices","text":"<ol> <li>Data Quality: Ensure high-quality historical data for PD and LGD estimation</li> <li>Forward-Looking Adjustments: Incorporate macroeconomic forecasts into PD and LGD estimates</li> <li>Segmentation: Group exposures with similar risk characteristics</li> <li>Multiple Scenarios: Consider various economic scenarios and their probabilities</li> <li>Regular Validation: Backtest and validate ECL models regularly</li> <li>Expert Judgment: Complement quantitative models with expert judgment</li> <li>Documentation: Maintain comprehensive documentation of methodologies and assumptions</li> </ol>","boost":2},{"location":"user-guide/credit/exposure_at_default/","title":"Exposure at Default (EAD)","text":"<p>The <code>exposure_at_default</code> function calculates the Exposure at Default (EAD), a key metric in credit risk management that estimates the expected amount outstanding when a borrower defaults. This metric is essential for credit risk modeling, regulatory capital calculations, and expected credit loss estimation under frameworks like Basel and IFRS 9.</p>"},{"location":"user-guide/credit/exposure_at_default/#usage-in-pypulate","title":"Usage in Pypulate","text":"<pre><code>from pypulate.credit import exposure_at_default\n\n# Calculate EAD\nresult = exposure_at_default(\n    current_balance=500000,    # $500,000 drawn amount\n    undrawn_amount=500000,     # $500,000 undrawn commitment\n    credit_conversion_factor=0.5  # 50% CCF\n)\n\n# Access the results\nead = result[\"ead\"]\nregulatory_ead = result[\"regulatory_ead\"]\nstressed_ead = result[\"stressed_ead\"]\nrisk_level = result[\"risk_level\"]\n</code></pre>"},{"location":"user-guide/credit/exposure_at_default/#parameters","title":"Parameters","text":"Parameter Type Description Default <code>current_balance</code> float Current drawn amount of the credit facility Required <code>undrawn_amount</code> float Undrawn commitment available to the borrower Required <code>credit_conversion_factor</code> float Factor to convert undrawn amounts to exposure (between 0 and 1) 0.5 (50%)"},{"location":"user-guide/credit/exposure_at_default/#return-value","title":"Return Value","text":"<p>The function returns a dictionary with the following keys:</p> Key Type Description <code>ead</code> float Exposure at Default using the provided CCF <code>regulatory_ead</code> float EAD calculated using regulatory CCF based on utilization rate <code>stressed_ead</code> float EAD calculated using a stressed CCF (1.5x the provided CCF, capped at 1.0) <code>ead_percentage</code> float EAD as a percentage of total facility <code>risk_level</code> str Risk level categorization (\"Low\", \"Moderate\", or \"High\") <code>components</code> dict Dictionary containing calculation components <p>The <code>components</code> dictionary includes:</p> <ul> <li><code>current_balance</code>: The provided current balance</li> <li><code>undrawn_amount</code>: The provided undrawn amount</li> <li><code>total_facility</code>: Sum of current balance and undrawn amount</li> <li><code>utilization_rate</code>: Current balance divided by total facility</li> <li><code>credit_conversion_factor</code>: The provided CCF</li> <li><code>regulatory_ccf</code>: CCF based on regulatory guidelines</li> <li><code>stress_ccf</code>: Stressed CCF for scenario analysis</li> </ul>"},{"location":"user-guide/credit/exposure_at_default/#risk-level-classification","title":"Risk Level Classification","text":"<p>The Utilization Rate is categorized into risk levels:</p> Utilization Rate Range Risk Level &lt; 30% Low 30% - 70% Moderate &gt; 70% High"},{"location":"user-guide/credit/exposure_at_default/#comprehensive-example","title":"Comprehensive Example","text":"<p>Here's a complete example demonstrating how to calculate and analyze EAD for different credit facilities:</p> <pre><code>from pypulate.credit import exposure_at_default\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Example 1: Low utilization corporate credit line\nlow_util_facility = exposure_at_default(\n    current_balance=200000,    # $200,000 drawn\n    undrawn_amount=800000,     # $800,000 undrawn\n    credit_conversion_factor=0.5  # 50% CCF\n)\n\n# Example 2: Medium utilization SME credit line\nmedium_util_facility = exposure_at_default(\n    current_balance=500000,    # $500,000 drawn\n    undrawn_amount=500000,     # $500,000 undrawn\n    credit_conversion_factor=0.5  # 50% CCF\n)\n\n# Example 3: High utilization retail credit card\nhigh_util_facility = exposure_at_default(\n    current_balance=45000,     # $45,000 drawn\n    undrawn_amount=5000,       # $5,000 undrawn\n    credit_conversion_factor=0.5  # 50% CCF\n)\n\n# Print the results\nprint(\"Exposure at Default Analysis\")\nprint(\"============================\")\n\nprint(\"\\nExample 1: Low Utilization Corporate Credit Line\")\nprint(f\"EAD: ${low_util_facility['ead']:.2f}\")\nprint(f\"Regulatory EAD: ${low_util_facility['regulatory_ead']:.2f}\")\nprint(f\"Stressed EAD: ${low_util_facility['stressed_ead']:.2f}\")\nprint(f\"Utilization Rate: {low_util_facility['components']['utilization_rate']:.2%}\")\nprint(f\"Risk Level: {low_util_facility['risk_level']}\")\n\nprint(\"\\nExample 2: Medium Utilization SME Credit Line\")\nprint(f\"EAD: ${medium_util_facility['ead']:.2f}\")\nprint(f\"Regulatory EAD: ${medium_util_facility['regulatory_ead']:.2f}\")\nprint(f\"Stressed EAD: ${medium_util_facility['stressed_ead']:.2f}\")\nprint(f\"Utilization Rate: {medium_util_facility['components']['utilization_rate']:.2%}\")\nprint(f\"Risk Level: {medium_util_facility['risk_level']}\")\n\nprint(\"\\nExample 3: High Utilization Retail Credit Card\")\nprint(f\"EAD: ${high_util_facility['ead']:.2f}\")\nprint(f\"Regulatory EAD: ${high_util_facility['regulatory_ead']:.2f}\")\nprint(f\"Stressed EAD: ${high_util_facility['stressed_ead']:.2f}\")\nprint(f\"Utilization Rate: {high_util_facility['components']['utilization_rate']:.2%}\")\nprint(f\"Risk Level: {high_util_facility['risk_level']}\")\n\n# Create a DataFrame for visualization\nfacility_types = ['Corporate Credit Line', 'SME Credit Line', 'Retail Credit Card']\nead_values = [\n    low_util_facility['ead'],\n    medium_util_facility['ead'],\n    high_util_facility['ead']\n]\nregulatory_ead_values = [\n    low_util_facility['regulatory_ead'],\n    medium_util_facility['regulatory_ead'],\n    high_util_facility['regulatory_ead']\n]\nstressed_ead_values = [\n    low_util_facility['stressed_ead'],\n    medium_util_facility['stressed_ead'],\n    high_util_facility['stressed_ead']\n]\nutilization_rates = [\n    low_util_facility['components']['utilization_rate'],\n    medium_util_facility['components']['utilization_rate'],\n    high_util_facility['components']['utilization_rate']\n]\ntotal_facilities = [\n    low_util_facility['components']['total_facility'],\n    medium_util_facility['components']['total_facility'],\n    high_util_facility['components']['total_facility']\n]\n\n# Create a bar chart for EAD comparison\nplt.figure(figsize=(12, 6))\nx = np.arange(len(facility_types))\nwidth = 0.25\n\nplt.bar(x - width, ead_values, width, label='Standard EAD', color='blue')\nplt.bar(x, regulatory_ead_values, width, label='Regulatory EAD', color='green')\nplt.bar(x + width, stressed_ead_values, width, label='Stressed EAD', color='red')\n\nplt.xlabel('Facility Type')\nplt.ylabel('Exposure at Default ($)')\nplt.title('EAD Comparison Across Different Facility Types')\nplt.xticks(x, facility_types)\nplt.legend()\nplt.grid(axis='y', linestyle='--', alpha=0.7)\n\n# Add the utilization rate on top of each group\nfor i, rate in enumerate(utilization_rates):\n    plt.text(i, max(ead_values[i], regulatory_ead_values[i], stressed_ead_values[i]) + 20000, \n             f'Utilization: {rate:.1%}', ha='center', va='bottom')\n\nplt.tight_layout()\nplt.show()\n\n# Create a scatter plot showing the relationship between utilization rate and EAD percentage\nplt.figure(figsize=(12, 6))\n\n# Create a scatter plot with size proportional to total facility\nsizes = [facility/10000 for facility in total_facilities]  # Scale for better visualization\ncolors = ['green', 'orange', 'red']\n\nfor i, facility_type in enumerate(facility_types):\n    plt.scatter(utilization_rates[i], \n                ead_values[i]/total_facilities[i], \n                s=sizes[i], \n                color=colors[i], \n                alpha=0.7, \n                label=f\"{facility_type} (Total: ${total_facilities[i]:,})\")\n\n# Add labels and title\nplt.xlabel('Utilization Rate')\nplt.ylabel('EAD as % of Total Facility')\nplt.title('EAD Percentage vs. Utilization Rate (Size represents Total Facility)')\nplt.grid(True, linestyle='--', alpha=0.7)\n\n# Add risk level regions\nplt.axvspan(0, 0.3, alpha=0.2, color='green', label='Low Risk')\nplt.axvspan(0.3, 0.7, alpha=0.2, color='yellow', label='Moderate Risk')\nplt.axvspan(0.7, 1, alpha=0.2, color='red', label='High Risk')\n\nplt.legend(loc='upper left')\nplt.tight_layout()\nplt.show()\n\n# Create a sensitivity analysis for utilization rate and CCF\nutilization_values = np.linspace(0.1, 0.9, 9)\nccf_values = np.linspace(0.1, 1.0, 10)\n\n# Create a matrix to store EAD percentages\nead_percentages = np.zeros((len(utilization_values), len(ccf_values)))\n\n# Calculate EAD percentage for each combination\nfor i, util in enumerate(utilization_values):\n    for j, ccf in enumerate(ccf_values):\n        # For a total facility of 1.0, calculate EAD percentage\n        current_balance = util * 1.0\n        undrawn_amount = (1.0 - util)\n        ead = current_balance + (undrawn_amount * ccf)\n        ead_percentages[i, j] = ead\n\n# Create a heatmap\nplt.figure(figsize=(12, 8))\ncontour = plt.contourf(ccf_values, utilization_values, ead_percentages, levels=20, cmap='viridis')\nplt.colorbar(contour, label='EAD as % of Total Facility')\n\n# Add contour lines\nplt.contour(ccf_values, utilization_values, ead_percentages, levels=10, colors='white', linestyles='dashed', linewidths=0.5)\n\n# Add labels and title\nplt.xlabel('Credit Conversion Factor (CCF)')\nplt.ylabel('Utilization Rate')\nplt.title('EAD Sensitivity to Utilization Rate and CCF')\nplt.grid(True, linestyle='--', alpha=0.3)\n\n# Add risk level indicators\nplt.axhspan(0, 0.3, alpha=0.1, color='green', label='Low Risk')\nplt.axhspan(0.3, 0.7, alpha=0.1, color='yellow', label='Moderate Risk')\nplt.axhspan(0.7, 1, alpha=0.1, color='red', label='High Risk')\n\nplt.legend(loc='upper right')\nplt.tight_layout()\nplt.show()\n</code></pre>"},{"location":"user-guide/credit/exposure_at_default/#example-output","title":"Example Output","text":"<pre><code>Exposure at Default Analysis\n============================\n\nExample 1: Low Utilization Corporate Credit Line\nEAD: $600000.00\nRegulatory EAD: $360000.00\nStressed EAD: $800000.00\nUtilization Rate: 20.00%\nRisk Level: Low\n\nExample 2: Medium Utilization SME Credit Line\nEAD: $750000.00\nRegulatory EAD: $800000.00\nStressed EAD: $875000.00\nUtilization Rate: 50.00%\nRisk Level: Moderate\n\nExample 3: High Utilization Retail Credit Card\nEAD: $47500.00\nRegulatory EAD: $49000.00\nStressed EAD: $48750.00\nUtilization Rate: 90.00%\nRisk Level: High\n</code></pre>"},{"location":"user-guide/credit/exposure_at_default/#visualizations","title":"Visualizations","text":""},{"location":"user-guide/credit/exposure_at_default/#ead-comparison","title":"EAD Comparison","text":"<p>This visualization compares the standard EAD, regulatory EAD, and stressed EAD for three different facility types, showing how the utilization rate affects the exposure calculations.</p> <p></p>"},{"location":"user-guide/credit/exposure_at_default/#ead-percentage-vs-utilization-rate","title":"EAD Percentage vs. Utilization Rate","text":"<p>This scatter plot shows the relationship between the utilization rate and the EAD as a percentage of the total facility, with the size of each point representing the total facility amount. The background is color-coded to indicate different risk level regions.</p> <p></p>"},{"location":"user-guide/credit/exposure_at_default/#ead-sensitivity","title":"EAD Sensitivity","text":"<p>This heatmap demonstrates how the EAD percentage changes with different combinations of utilization rate and credit conversion factor, helping to visualize the sensitivity of the exposure calculation to these two key parameters.</p> <p></p>"},{"location":"user-guide/credit/exposure_at_default/#practical-applications","title":"Practical Applications","text":"<p>Exposure at Default calculations can be used for:</p> <ol> <li>Regulatory Capital: Calculating regulatory capital requirements under Basel frameworks</li> <li>IFRS 9 / CECL: Determining exposure inputs for expected credit loss calculations</li> <li>Credit Risk Management: Quantifying potential exposure in credit facilities</li> <li>Limit Setting: Establishing appropriate credit limits for different facility types</li> <li>Stress Testing: Assessing the impact of increased drawdowns during stress scenarios</li> <li>Portfolio Management: Understanding the risk profile of credit portfolios</li> <li>Pricing: Incorporating potential exposure into risk-based pricing models</li> </ol>"},{"location":"user-guide/credit/exposure_at_default/#industry-standards","title":"Industry Standards","text":"<p>Different regulatory frameworks provide guidance on EAD calculation:</p> <ol> <li> <p>Basel Framework:</p> <ul> <li>Standardized Approach: Prescribes fixed CCFs based on facility type</li> <li>Internal Ratings-Based Approach: Allows banks to estimate their own CCFs</li> <li>Typically differentiates between committed and uncommitted facilities</li> </ul> </li> <li> <p>Accounting Standards:</p> <ul> <li>IFRS 9: Requires consideration of expected drawdowns over the lifetime of the facility</li> <li>CECL: Similar approach, focusing on lifetime exposure estimates</li> </ul> </li> <li> <p>Industry Practice:</p> <ul> <li>CCFs typically range from 0% (for uncommitted facilities) to 100% (for fully committed facilities)</li> <li>Higher CCFs are applied to facilities with longer tenors and fewer covenants</li> <li>Retail products often have product-specific CCFs based on historical behavior</li> </ul> </li> </ol>"},{"location":"user-guide/credit/exposure_at_default/#best-practices","title":"Best Practices","text":"<ol> <li>Historical Analysis: Base CCF estimates on historical drawdown behavior</li> <li>Segmentation: Group facilities with similar characteristics for CCF estimation</li> <li>Stress Scenarios: Consider increased drawdowns during economic downturns</li> <li>Facility Characteristics: Account for commitment type, covenants, and maturity</li> <li>Regular Monitoring: Track utilization rates and update CCF estimates periodically</li> <li>Conservative Approach: Apply higher CCFs for facilities with uncertain drawdown patterns</li> <li>Documentation: Maintain comprehensive documentation of methodologies and assumptions</li> </ol>"},{"location":"user-guide/credit/financial_ratios/","title":"Financial Ratios","text":"<p>The <code>financial_ratios</code> function calculates key financial ratios used in credit assessment and provides an overall assessment of a company's financial health. These ratios are grouped into categories including liquidity, solvency, profitability, coverage, and efficiency.</p>"},{"location":"user-guide/credit/financial_ratios/#usage-in-pypulate","title":"Usage in Pypulate","text":"<pre><code>from pypulate.credit import financial_ratios\n\n# Calculate financial ratios\nresult = financial_ratios(\n    current_assets=250000,         # $250,000 current assets\n    current_liabilities=100000,    # $100,000 current liabilities\n    total_assets=1000000,          # $1,000,000 total assets\n    total_liabilities=400000,      # $400,000 total liabilities\n    ebit=150000,                   # $150,000 earnings before interest and taxes\n    interest_expense=30000,        # $30,000 interest expense\n    net_income=100000,             # $100,000 net income\n    total_equity=600000,           # $600,000 total equity\n    sales=800000                   # $800,000 sales\n)\n\n# Access the results\nliquidity = result[\"liquidity\"]\nsolvency = result[\"solvency\"]\nprofitability = result[\"profitability\"]\ncoverage = result[\"coverage\"]\nefficiency = result[\"efficiency\"]\noverall = result[\"overall_assessment\"]\n</code></pre>"},{"location":"user-guide/credit/financial_ratios/#parameters","title":"Parameters","text":"Parameter Type Description Default <code>current_assets</code> float The company's current assets Required <code>current_liabilities</code> float The company's current liabilities Required <code>total_assets</code> float The company's total assets Required <code>total_liabilities</code> float The company's total liabilities Required <code>ebit</code> float Earnings before interest and taxes Required <code>interest_expense</code> float Interest expense Required <code>net_income</code> float Net income Required <code>total_equity</code> float Total equity Required <code>sales</code> float Total sales Required"},{"location":"user-guide/credit/financial_ratios/#return-value","title":"Return Value","text":"<p>The function returns a dictionary with the following keys:</p> Key Type Description <code>liquidity</code> dict Dictionary containing liquidity ratios and assessment <code>solvency</code> dict Dictionary containing solvency ratios and assessment <code>profitability</code> dict Dictionary containing profitability ratios and assessment <code>coverage</code> dict Dictionary containing coverage ratios and assessment <code>efficiency</code> dict Dictionary containing efficiency ratios <code>overall_assessment</code> str Overall assessment of financial health <p>The <code>liquidity</code> dictionary includes: - <code>current_ratio</code>: Current assets divided by current liabilities - <code>assessment</code>: Assessment of liquidity (\"Strong\", \"Adequate\", or \"Weak\")</p> <p>The <code>solvency</code> dictionary includes: - <code>debt_ratio</code>: Total liabilities divided by total assets - <code>debt_to_equity</code>: Total liabilities divided by total equity - <code>assessment</code>: Assessment of solvency (\"Strong\", \"Adequate\", or \"Weak\")</p> <p>The <code>profitability</code> dictionary includes: - <code>return_on_assets</code>: Net income divided by total assets - <code>return_on_equity</code>: Net income divided by total equity - <code>assessment</code>: Assessment of profitability (\"Strong\", \"Adequate\", or \"Weak\")</p> <p>The <code>coverage</code> dictionary includes: - <code>interest_coverage</code>: EBIT divided by interest expense - <code>assessment</code>: Assessment of coverage (\"Strong\", \"Adequate\", or \"Weak\")</p> <p>The <code>efficiency</code> dictionary includes: - <code>asset_turnover</code>: Sales divided by total assets - <code>assessment</code>: Assessment of efficiency (\"Strong\", \"Adequate\", or \"Weak\")</p>"},{"location":"user-guide/credit/financial_ratios/#risk-level-classification","title":"Risk Level Classification","text":"<p>The financial ratios are categorized into assessment levels:</p> Ratio Range Assessment Current Ratio &lt; 1.0 Weak 1.0 - 2.0 Adequate &gt; 2.0 Strong Debt Ratio &gt; 0.6 Weak 0.4 - 0.6 Adequate &lt; 0.4 Strong Debt-to-Equity &gt; 1.5 Weak 0.5 - 1.5 Adequate &lt; 0.5 Strong Return on Assets &lt; 0.02 Weak 0.02 - 0.05 Adequate &gt; 0.05 Strong Return on Equity &lt; 0.05 Weak 0.05 - 0.15 Adequate &gt; 0.15 Strong Interest Coverage &lt; 1.5 Weak 1.5 - 3.0 Adequate &gt; 3.0 Strong Asset Turnover &lt; 0.5 Weak 0.5 - 1.0 Adequate &gt; 1.0 Strong"},{"location":"user-guide/credit/financial_ratios/#comprehensive-example","title":"Comprehensive Example","text":"<p>Here's a complete example demonstrating how to calculate and analyze financial ratios for different companies:</p> <pre><code>from pypulate.credit import financial_ratios\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Example 1: Financially strong company\nstrong_company = financial_ratios(\n    current_assets=500000,         # $500,000 current assets\n    current_liabilities=200000,    # $200,000 current liabilities\n    total_assets=2000000,          # $2,000,000 total assets\n    total_liabilities=600000,      # $600,000 total liabilities\n    ebit=400000,                   # $400,000 earnings before interest and taxes\n    interest_expense=50000,        # $50,000 interest expense\n    net_income=300000,             # $300,000 net income\n    total_equity=1400000,          # $1,400,000 total equity\n    sales=2500000                  # $2,500,000 sales\n)\n\n# Example 2: Company with adequate financial health\nadequate_company = financial_ratios(\n    current_assets=300000,         # $300,000 current assets\n    current_liabilities=200000,    # $200,000 current liabilities\n    total_assets=1500000,          # $1,500,000 total assets\n    total_liabilities=750000,      # $750,000 total liabilities\n    ebit=200000,                   # $200,000 earnings before interest and taxes\n    interest_expense=80000,        # $80,000 interest expense\n    net_income=100000,             # $100,000 net income\n    total_equity=750000,           # $750,000 total equity\n    sales=1200000                  # $1,200,000 sales\n)\n\n# Example 3: Financially weak company\nweak_company = financial_ratios(\n    current_assets=150000,         # $150,000 current assets\n    current_liabilities=200000,    # $200,000 current liabilities\n    total_assets=1000000,          # $1,000,000 total assets\n    total_liabilities=700000,      # $700,000 total liabilities\n    ebit=50000,                    # $50,000 earnings before interest and taxes\n    interest_expense=60000,        # $60,000 interest expense\n    net_income=20000,              # $20,000 net income\n    total_equity=300000,           # $300,000 total equity\n    sales=600000                   # $600,000 sales\n)\n\n# Print the results\nprint(\"Financial Ratios Analysis\")\nprint(\"========================\")\n\nprint(\"\\nExample 1: Strong Company\")\nprint(f\"Current Ratio: {strong_company['liquidity']['current_ratio']:.2f} ({strong_company['liquidity']['assessment']})\")\nprint(f\"Debt Ratio: {strong_company['solvency']['debt_ratio']:.2f} ({strong_company['solvency']['assessment']})\")\nprint(f\"Return on Equity: {strong_company['profitability']['return_on_equity']:.2f} ({strong_company['profitability']['assessment']})\")\nprint(f\"Interest Coverage: {strong_company['coverage']['interest_coverage']:.2f} ({strong_company['coverage']['assessment']})\")\nprint(f\"Asset Turnover: {strong_company['efficiency']['asset_turnover']:.2f}\")\nprint(f\"Overall Assessment: {strong_company['overall_assessment']}\")\n\nprint(\"\\nExample 2: Adequate Company\")\nprint(f\"Current Ratio: {adequate_company['liquidity']['current_ratio']:.2f} ({adequate_company['liquidity']['assessment']})\")\nprint(f\"Debt Ratio: {adequate_company['solvency']['debt_ratio']:.2f} ({adequate_company['solvency']['assessment']})\")\nprint(f\"Return on Equity: {adequate_company['profitability']['return_on_equity']:.2f} ({adequate_company['profitability']['assessment']})\")\nprint(f\"Interest Coverage: {adequate_company['coverage']['interest_coverage']:.2f} ({adequate_company['coverage']['assessment']})\")\nprint(f\"Asset Turnover: {adequate_company['efficiency']['asset_turnover']:.2f}\")\nprint(f\"Overall Assessment: {adequate_company['overall_assessment']}\")\n\nprint(\"\\nExample 3: Weak Company\")\nprint(f\"Current Ratio: {weak_company['liquidity']['current_ratio']:.2f} ({weak_company['liquidity']['assessment']})\")\nprint(f\"Debt Ratio: {weak_company['solvency']['debt_ratio']:.2f} ({weak_company['solvency']['assessment']})\")\nprint(f\"Return on Equity: {weak_company['profitability']['return_on_equity']:.2f} ({weak_company['profitability']['assessment']})\")\nprint(f\"Interest Coverage: {weak_company['coverage']['interest_coverage']:.2f} ({weak_company['coverage']['assessment']})\")\nprint(f\"Asset Turnover: {weak_company['efficiency']['asset_turnover']:.2f}\")\nprint(f\"Overall Assessment: {weak_company['overall_assessment']}\")\n\n# Visualize the results\ncompanies = ['Strong', 'Adequate', 'Weak']\ncurrent_ratios = [\n    strong_company['liquidity']['current_ratio'],\n    adequate_company['liquidity']['current_ratio'],\n    weak_company['liquidity']['current_ratio']\n]\ndebt_ratios = [\n    strong_company['solvency']['debt_ratio'],\n    adequate_company['solvency']['debt_ratio'],\n    weak_company['solvency']['debt_ratio']\n]\ninterest_coverages = [\n    strong_company['coverage']['interest_coverage'],\n    adequate_company['coverage']['interest_coverage'],\n    weak_company['coverage']['interest_coverage']\n]\nreturn_on_equities = [\n    strong_company['profitability']['return_on_equity'],\n    adequate_company['profitability']['return_on_equity'],\n    weak_company['profitability']['return_on_equity']\n]\n\n# Create a comparison chart\nfig, axs = plt.subplots(2, 2, figsize=(14, 10))\nfig.suptitle('Financial Ratios Comparison', fontsize=16)\n\n# Current Ratio\naxs[0, 0].bar(companies, current_ratios, color=['green', 'orange', 'red'])\naxs[0, 0].axhline(y=2, color='g', linestyle='--', label='Strong (\u2265 2)')\naxs[0, 0].axhline(y=1, color='r', linestyle='--', label='Weak (&lt; 1)')\naxs[0, 0].set_title('Current Ratio')\naxs[0, 0].set_ylabel('Ratio')\naxs[0, 0].legend()\n\n# Debt Ratio\naxs[0, 1].bar(companies, debt_ratios, color=['green', 'orange', 'red'])\naxs[0, 1].axhline(y=0.4, color='g', linestyle='--', label='Strong (\u2264 0.4)')\naxs[0, 1].axhline(y=0.6, color='r', linestyle='--', label='Weak (&gt; 0.6)')\naxs[0, 1].set_title('Debt Ratio')\naxs[0, 1].set_ylabel('Ratio')\naxs[0, 1].legend()\n\n# Interest Coverage\naxs[1, 0].bar(companies, interest_coverages, color=['green', 'orange', 'red'])\naxs[1, 0].axhline(y=3, color='g', linestyle='--', label='Strong (\u2265 3)')\naxs[1, 0].axhline(y=1.5, color='r', linestyle='--', label='Weak (&lt; 1.5)')\naxs[1, 0].set_title('Interest Coverage Ratio')\naxs[1, 0].set_ylabel('Ratio')\naxs[1, 0].legend()\n\n# Return on Equity\naxs[1, 1].bar(companies, return_on_equities, color=['green', 'orange', 'red'])\naxs[1, 1].axhline(y=0.15, color='g', linestyle='--', label='Strong (\u2265 0.15)')\naxs[1, 1].axhline(y=0.08, color='r', linestyle='--', label='Weak (&lt; 0.08)')\naxs[1, 1].set_title('Return on Equity')\naxs[1, 1].set_ylabel('Ratio')\naxs[1, 1].legend()\n\nplt.tight_layout()\nplt.subplots_adjust(top=0.9)\nplt.show()\n\n# Create a sensitivity analysis for current ratio\ncurrent_assets_values = np.linspace(100000, 500000, 100)  # Range of current assets values\ncurrent_liabilities = 200000  # Fixed current liabilities\n\ncurrent_ratios = [ca / current_liabilities for ca in current_assets_values]\nassessments = []\n\nfor ratio in current_ratios:\n    if ratio &gt;= 2:\n        assessments.append(\"Strong\")\n    elif ratio &gt;= 1:\n        assessments.append(\"Adequate\")\n    else:\n        assessments.append(\"Weak\")\n\n# Create a plot showing how current ratio changes with current assets\nplt.figure(figsize=(12, 6))\n\n# Plot current ratio curve\nplt.plot(current_assets_values, current_ratios, 'b-', linewidth=2)\n\n# Add colored regions for different assessments\nweak_indices = [i for i, r in enumerate(assessments) if r == \"Weak\"]\nadequate_indices = [i for i, r in enumerate(assessments) if r == \"Adequate\"]\nstrong_indices = [i for i, r in enumerate(assessments) if r == \"Strong\"]\n\nif weak_indices:\n    plt.fill_between(current_assets_values[min(weak_indices):max(weak_indices)+1], \n                     0, current_ratios[min(weak_indices):max(weak_indices)+1], \n                     color='red', alpha=0.3, label='Weak')\nif adequate_indices:\n    plt.fill_between(current_assets_values[min(adequate_indices):max(adequate_indices)+1], \n                     0, current_ratios[min(adequate_indices):max(adequate_indices)+1], \n                     color='orange', alpha=0.3, label='Adequate')\nif strong_indices:\n    plt.fill_between(current_assets_values[min(strong_indices):max(strong_indices)+1], \n                     0, current_ratios[min(strong_indices):max(strong_indices)+1], \n                     color='green', alpha=0.3, label='Strong')\n\n# Add horizontal lines for the ratio thresholds\nplt.axhline(y=1, color='r', linestyle='--')\nplt.axhline(y=2, color='g', linestyle='--')\n\n# Add labels and title\nplt.xlabel('Current Assets ($)')\nplt.ylabel('Current Ratio')\nplt.title('Current Ratio Sensitivity to Current Assets (Fixed Current Liabilities: $200,000)')\nplt.grid(True, linestyle='--', alpha=0.7)\nplt.legend()\nplt.tight_layout()\nplt.show()\n</code></pre>"},{"location":"user-guide/credit/financial_ratios/#example-output","title":"Example Output","text":"<pre><code>Financial Ratios Analysis\n========================\n\nExample 1: Strong Company\nCurrent Ratio: 2.50 (Strong)\nDebt Ratio: 0.30 (Strong)\nReturn on Equity: 0.21 (Strong)\nInterest Coverage: 8.00 (Strong)\nAsset Turnover: 1.25\nOverall Assessment: Strong financial position\n\nExample 2: Adequate Company\nCurrent Ratio: 1.50 (Adequate)\nDebt Ratio: 0.50 (Adequate)\nReturn on Equity: 0.13 (Adequate)\nInterest Coverage: 2.50 (Adequate)\nAsset Turnover: 0.80\nOverall Assessment: Adequate financial position\n\nExample 3: Weak Company\nCurrent Ratio: 0.75 (Weak)\nDebt Ratio: 0.70 (Weak)\nReturn on Equity: 0.07 (Weak)\nInterest Coverage: 0.83 (Weak)\nAsset Turnover: 0.60\nOverall Assessment: Weak financial position\n</code></pre>"},{"location":"user-guide/credit/financial_ratios/#visualizations","title":"Visualizations","text":""},{"location":"user-guide/credit/financial_ratios/#financial-ratios-comparison","title":"Financial Ratios Comparison","text":"<p>The following visualization shows a comparison of key financial ratios across three different companies (strong, adequate, and weak):</p> <p></p> <p>This chart displays four key financial ratios: - Current Ratio: Shows liquidity with thresholds at 2.0 (strong) and 1.0 (weak) - Debt Ratio: Shows solvency with thresholds at 0.4 (strong) and 0.6 (weak) - Interest Coverage Ratio: Shows debt service ability with thresholds at 3.0 (strong) and 1.5 (weak) - Return on Equity: Shows profitability with thresholds at 0.15 (strong) and 0.08 (weak)</p>"},{"location":"user-guide/credit/financial_ratios/#ratio-sensitivity-analysis","title":"Ratio Sensitivity Analysis","text":"<p>The following visualization demonstrates how the current ratio changes as current assets increase, while keeping current liabilities constant:</p> <p></p> <p>This sensitivity analysis shows: - The blue line represents the current ratio as current assets increase - The red region represents the \"Weak\" assessment zone (ratio &lt; 1.0) - The orange region represents the \"Adequate\" assessment zone (1.0 \u2264 ratio &lt; 2.0) - The green region represents the \"Strong\" assessment zone (ratio \u2265 2.0) - The horizontal dashed lines mark the threshold values at 1.0 and 2.0</p>"},{"location":"user-guide/credit/financial_ratios/#ratio-categories-and-thresholds","title":"Ratio Categories and Thresholds","text":""},{"location":"user-guide/credit/financial_ratios/#1-liquidity-ratios","title":"1. Liquidity Ratios","text":"<p>Measure a company's ability to pay short-term obligations.</p> <ul> <li>Current Ratio = Current Assets / Current Liabilities</li> <li>Strong: \u2265 2.0</li> <li>Adequate: 1.0 - 2.0</li> <li>Weak: &lt; 1.0</li> </ul>"},{"location":"user-guide/credit/financial_ratios/#2-solvency-ratios","title":"2. Solvency Ratios","text":"<p>Measure a company's ability to meet long-term obligations.</p> <ul> <li>Debt Ratio = Total Liabilities / Total Assets</li> <li>Strong: \u2264 0.4</li> <li>Adequate: 0.4 - 0.6</li> <li> <p>Weak: &gt; 0.6</p> </li> <li> <p>Debt-to-Equity Ratio = Total Liabilities / Total Equity</p> </li> <li>Lower values indicate better solvency</li> </ul>"},{"location":"user-guide/credit/financial_ratios/#3-profitability-ratios","title":"3. Profitability Ratios","text":"<p>Measure a company's ability to generate earnings relative to its assets and equity.</p> <ul> <li>Return on Assets (ROA) = Net Income / Total Assets</li> <li> <p>Higher values indicate better profitability</p> </li> <li> <p>Return on Equity (ROE) = Net Income / Total Equity</p> </li> <li>Strong: \u2265 0.15 (15%)</li> <li>Adequate: 0.08 - 0.15 (8% - 15%)</li> <li>Weak: &lt; 0.08 (8%)</li> </ul>"},{"location":"user-guide/credit/financial_ratios/#4-coverage-ratios","title":"4. Coverage Ratios","text":"<p>Measure a company's ability to service its debt.</p> <ul> <li>Interest Coverage Ratio = EBIT / Interest Expense</li> <li>Strong: \u2265 3.0</li> <li>Adequate: 1.5 - 3.0</li> <li>Weak: &lt; 1.5</li> </ul>"},{"location":"user-guide/credit/financial_ratios/#5-efficiency-ratios","title":"5. Efficiency Ratios","text":"<p>Measure how effectively a company uses its assets.</p> <ul> <li>Asset Turnover Ratio = Sales / Total Assets</li> <li>Higher values indicate better efficiency</li> </ul>"},{"location":"user-guide/credit/financial_ratios/#practical-applications","title":"Practical Applications","text":"<p>Financial ratios can be used for:</p> <ol> <li>Credit Risk Assessment: Evaluating a borrower's financial health</li> <li>Investment Analysis: Identifying financially stable companies</li> <li>Benchmarking: Comparing a company's performance against industry peers</li> <li>Trend Analysis: Monitoring changes in a company's financial health over time</li> <li>Covenant Compliance: Ensuring borrowers maintain acceptable financial metrics</li> </ol>"},{"location":"user-guide/credit/financial_ratios/#limitations","title":"Limitations","text":"<p>When using financial ratios, consider these limitations:</p> <ol> <li>Industry differences may affect appropriate ratio values</li> <li>Seasonal variations can impact short-term ratios</li> <li>Accounting methods can affect ratio calculations</li> <li>Historical ratios may not predict future performance</li> <li>Ratios should be used alongside other financial metrics for comprehensive analysis </li> </ol>"},{"location":"user-guide/credit/loan_pricing/","title":"Loan Pricing","text":"<p>The <code>loan_pricing</code> function implements a risk-based loan pricing model that calculates the appropriate interest rate for a loan based on various risk factors and cost components. This model helps lenders determine fair and profitable loan terms while accounting for the borrower's risk profile.</p>"},{"location":"user-guide/credit/loan_pricing/#components-of-loan-pricing","title":"Components of Loan Pricing","text":"<p>The loan pricing model considers several key components:</p> <ol> <li>Expected Loss Component: Accounts for the probability of default and the expected loss given default</li> <li>Funding Cost Component: Reflects the lender's cost of obtaining funds</li> <li>Operating Cost Component: Covers the administrative costs of originating and servicing the loan</li> <li>Capital Cost Component: Accounts for the required return on the capital allocated to support the loan</li> </ol>"},{"location":"user-guide/credit/loan_pricing/#usage-in-pypulate","title":"Usage in Pypulate","text":"<pre><code>from pypulate.credit import loan_pricing\n\n# Calculate risk-based loan pricing\nresult = loan_pricing(\n    loan_amount=100000,           # $100,000 loan\n    term=5,                       # 5-year term\n    pd=0.02,                      # 2% annual probability of default\n    lgd=0.4,                      # 40% loss given default\n    funding_cost=0.03,            # 3% cost of funds\n    operating_cost=0.01,          # 1% operating costs\n    capital_requirement=0.08,     # 8% capital requirement\n    target_roe=0.15               # 15% target return on equity\n)\n\n# Access the results\nrecommended_rate = result[\"recommended_rate\"]\nmonthly_payment = result[\"monthly_payment\"]\ncomponents = result[\"components\"]\n</code></pre>"},{"location":"user-guide/credit/loan_pricing/#parameters","title":"Parameters","text":"Parameter Type Description Default <code>loan_amount</code> float The principal amount of the loan Required <code>term</code> float The loan term in years Required <code>pd</code> float Probability of default (annual rate, between 0 and 1) Required <code>lgd</code> float Loss given default (as a decimal, between 0 and 1) Required <code>funding_cost</code> float Cost of funds (annual rate) Required <code>operating_cost</code> float Operating costs as percentage of loan amount Required <code>capital_requirement</code> float Capital requirement as percentage of loan amount Required <code>target_roe</code> float Target return on equity (annual rate) Required"},{"location":"user-guide/credit/loan_pricing/#return-value","title":"Return Value","text":"<p>The function returns a dictionary with the following keys:</p> Key Type Description <code>recommended_rate</code> float The calculated interest rate for the loan <code>effective_annual_rate</code> float The effective annual rate (APR) <code>monthly_payment</code> float The calculated monthly payment amount <code>total_interest</code> float Total interest paid over the life of the loan <code>expected_profit</code> float Expected profit after accounting for losses and costs <code>return_on_investment</code> float Expected return on the allocated capital <code>components</code> dict Dictionary containing the individual pricing components <p>The <code>components</code> dictionary includes: - <code>expected_loss</code>: Component accounting for credit risk - <code>funding_cost</code>: Component accounting for cost of funds - <code>operating_cost</code>: Component accounting for operational expenses - <code>capital_cost</code>: Component accounting for capital allocation - <code>risk_premium</code>: Combined risk-related components (expected_loss + capital_cost)</p>"},{"location":"user-guide/credit/loan_pricing/#risk-level-classification","title":"Risk Level Classification","text":"<p>The loan risk is categorized based on the expected loss rate (PD \u00d7 LGD):</p> Expected Loss Rate Range Risk Level &lt; 1% Very Low 1% - 3% Low 3% - 7% Moderate 7% - 15% High &gt; 15% Very High"},{"location":"user-guide/credit/loan_pricing/#comprehensive-example","title":"Comprehensive Example","text":"<p>Here's a complete example demonstrating how to calculate and analyze loan pricing for different risk profiles:</p> <pre><code>from pypulate.credit import loan_pricing\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Example 1: Low-risk borrower\nlow_risk_loan = loan_pricing(\n    loan_amount=100000,           # $100,000 loan\n    term=5,                       # 5-year term\n    pd=0.01,                      # 1% probability of default\n    lgd=0.3,                      # 30% loss given default\n    funding_cost=0.03,            # 3% cost of funds\n    operating_cost=0.01,          # 1% operating costs\n    capital_requirement=0.08,     # 8% capital requirement\n    target_roe=0.15               # 15% target return on equity\n)\n\n# Example 2: Medium-risk borrower\nmedium_risk_loan = loan_pricing(\n    loan_amount=100000,           # $100,000 loan\n    term=5,                       # 5-year term\n    pd=0.03,                      # 3% probability of default\n    lgd=0.4,                      # 40% loss given default\n    funding_cost=0.03,            # 3% cost of funds\n    operating_cost=0.01,          # 1% operating costs\n    capital_requirement=0.08,     # 8% capital requirement\n    target_roe=0.15               # 15% target return on equity\n)\n\n# Example 3: High-risk borrower\nhigh_risk_loan = loan_pricing(\n    loan_amount=100000,           # $100,000 loan\n    term=5,                       # 5-year term\n    pd=0.08,                      # 8% probability of default\n    lgd=0.5,                      # 50% loss given default\n    funding_cost=0.03,            # 3% cost of funds\n    operating_cost=0.01,          # 1% operating costs\n    capital_requirement=0.08,     # 8% capital requirement\n    target_roe=0.15               # 15% target return on equity\n)\n\n# Print the results\nprint(\"Risk-Based Loan Pricing Analysis\")\nprint(\"===============================\")\n\nprint(\"\\nExample 1: Low-Risk Borrower\")\nprint(f\"Recommended Interest Rate: {low_risk_loan['recommended_rate']:.2%}\")\nprint(f\"Effective Annual Rate: {low_risk_loan['effective_annual_rate']:.2%}\")\nprint(f\"Monthly Payment: ${low_risk_loan['monthly_payment']:.2f}\")\nprint(f\"Total Interest: ${low_risk_loan['total_interest']:.2f}\")\nprint(f\"Expected Profit: ${low_risk_loan['expected_profit']:.2f}\")\nprint(f\"Return on Investment: {low_risk_loan['return_on_investment']:.2%}\")\nprint(\"Pricing Components:\")\nfor component, value in low_risk_loan['components'].items():\n    print(f\"  {component}: {value:.2%}\")\n\nprint(\"\\nExample 2: Medium-Risk Borrower\")\nprint(f\"Recommended Interest Rate: {medium_risk_loan['recommended_rate']:.2%}\")\nprint(f\"Effective Annual Rate: {medium_risk_loan['effective_annual_rate']:.2%}\")\nprint(f\"Monthly Payment: ${medium_risk_loan['monthly_payment']:.2f}\")\nprint(f\"Total Interest: ${medium_risk_loan['total_interest']:.2f}\")\nprint(f\"Expected Profit: ${medium_risk_loan['expected_profit']:.2f}\")\nprint(f\"Return on Investment: {medium_risk_loan['return_on_investment']:.2%}\")\nprint(\"Pricing Components:\")\nfor component, value in medium_risk_loan['components'].items():\n    print(f\"  {component}: {value:.2%}\")\n\nprint(\"\\nExample 3: High-Risk Borrower\")\nprint(f\"Recommended Interest Rate: {high_risk_loan['recommended_rate']:.2%}\")\nprint(f\"Effective Annual Rate: {high_risk_loan['effective_annual_rate']:.2%}\")\nprint(f\"Monthly Payment: ${high_risk_loan['monthly_payment']:.2f}\")\nprint(f\"Total Interest: ${high_risk_loan['total_interest']:.2f}\")\nprint(f\"Expected Profit: ${high_risk_loan['expected_profit']:.2f}\")\nprint(f\"Return on Investment: {high_risk_loan['return_on_investment']:.2%}\")\nprint(\"Pricing Components:\")\nfor component, value in high_risk_loan['components'].items():\n    print(f\"  {component}: {value:.2%}\")\n\n# Visualize the results - Interest Rate Comparison\nrisk_profiles = ['Low Risk', 'Medium Risk', 'High Risk']\ninterest_rates = [\n    low_risk_loan['recommended_rate'],\n    medium_risk_loan['recommended_rate'],\n    high_risk_loan['recommended_rate']\n]\n\nplt.figure(figsize=(10, 6))\nbars = plt.bar(risk_profiles, interest_rates, color=['green', 'orange', 'red'])\n\n# Add the rate values on top of the bars\nfor bar in bars:\n    height = bar.get_height()\n    plt.text(bar.get_x() + bar.get_width()/2., height + 0.005,\n             f'{height:.2%}', ha='center', va='bottom')\n\nplt.ylabel('Recommended Interest Rate')\nplt.title('Risk-Based Interest Rate Comparison')\nplt.grid(axis='y', linestyle='--', alpha=0.7)\nplt.tight_layout()\nplt.show()\n\n# Visualize the pricing components\ncomponents = ['Expected Loss', 'Funding Cost', 'Operating Cost', 'Capital Cost']\nlow_risk_components = [\n    low_risk_loan['components']['expected_loss'],\n    low_risk_loan['components']['funding_cost'],\n    low_risk_loan['components']['operating_cost'],\n    low_risk_loan['components']['capital_cost']\n]\nmedium_risk_components = [\n    medium_risk_loan['components']['expected_loss'],\n    medium_risk_loan['components']['funding_cost'],\n    medium_risk_loan['components']['operating_cost'],\n    medium_risk_loan['components']['capital_cost']\n]\nhigh_risk_components = [\n    high_risk_loan['components']['expected_loss'],\n    high_risk_loan['components']['funding_cost'],\n    high_risk_loan['components']['operating_cost'],\n    high_risk_loan['components']['capital_cost']\n]\n\nx = np.arange(len(components))  # the label locations\nwidth = 0.25  # the width of the bars\n\nfig, ax = plt.subplots(figsize=(12, 7))\nrects1 = ax.bar(x - width, low_risk_components, width, label='Low Risk', color='green')\nrects2 = ax.bar(x, medium_risk_components, width, label='Medium Risk', color='orange')\nrects3 = ax.bar(x + width, high_risk_components, width, label='High Risk', color='red')\n\n# Add some text for labels, title and custom x-axis tick labels, etc.\nax.set_ylabel('Rate Component')\nax.set_title('Loan Pricing Components by Risk Profile')\nax.set_xticks(x)\nax.set_xticklabels(components)\nax.legend()\n\n# Add value labels\ndef autolabel(rects):\n    for rect in rects:\n        height = rect.get_height()\n        ax.annotate(f'{height:.2%}',\n                    xy=(rect.get_x() + rect.get_width() / 2, height),\n                    xytext=(0, 3),  # 3 points vertical offset\n                    textcoords=\"offset points\",\n                    ha='center', va='bottom')\n\nautolabel(rects1)\nautolabel(rects2)\nautolabel(rects3)\n\nfig.tight_layout()\nplt.grid(axis='y', linestyle='--', alpha=0.7)\nplt.show()\n\n# Create a sensitivity analysis for PD\npd_values = np.linspace(0.01, 0.10, 10)  # Range of PD values from 1% to 10%\ninterest_rates = []\nmonthly_payments = []\nexpected_profits = []\n\nfor pd_value in pd_values:\n    result = loan_pricing(\n        loan_amount=100000,\n        term=5,\n        pd=pd_value,\n        lgd=0.4,\n        funding_cost=0.03,\n        operating_cost=0.01,\n        capital_requirement=0.08,\n        target_roe=0.15\n    )\n    interest_rates.append(result['recommended_rate'])\n    monthly_payments.append(result['monthly_payment'])\n    expected_profits.append(result['expected_profit'])\n\n# Plot interest rate sensitivity to PD\nplt.figure(figsize=(12, 6))\nplt.plot(pd_values * 100, np.array(interest_rates) * 100, 'b-', linewidth=2, marker='o')\nplt.xlabel('Probability of Default (%)')\nplt.ylabel('Recommended Interest Rate (%)')\nplt.title('Interest Rate Sensitivity to Probability of Default')\nplt.grid(True, linestyle='--', alpha=0.7)\nplt.tight_layout()\nplt.show()\n\n# Plot monthly payment sensitivity to PD\nplt.figure(figsize=(12, 6))\nplt.plot(pd_values * 100, monthly_payments, 'g-', linewidth=2, marker='o')\nplt.xlabel('Probability of Default (%)')\nplt.ylabel('Monthly Payment ($)')\nplt.title('Monthly Payment Sensitivity to Probability of Default')\nplt.grid(True, linestyle='--', alpha=0.7)\nplt.tight_layout()\nplt.show()\n\n# Plot expected profit sensitivity to PD\nplt.figure(figsize=(12, 6))\nplt.plot(pd_values * 100, expected_profits, 'r-', linewidth=2, marker='o')\nplt.xlabel('Probability of Default (%)')\nplt.ylabel('Expected Profit ($)')\nplt.title('Expected Profit Sensitivity to Probability of Default')\nplt.grid(True, linestyle='--', alpha=0.7)\nplt.tight_layout()\nplt.show()\n</code></pre>"},{"location":"user-guide/credit/loan_pricing/#example-output","title":"Example Output","text":"<pre><code>Risk-Based Loan Pricing Analysis\n===============================\n\nExample 1: Low-Risk Borrower\nRecommended Interest Rate: 4.46%\nEffective Annual Rate: 4.55%\nMonthly Payment: $1862.48\nTotal Interest: $11749.02\nExpected Profit: $6449.02\nReturn on Investment: 80.61%\nPricing Components:\n  expected_loss: 0.06%\n  funding_cost: 3.00%\n  operating_cost: 0.20%\n  capital_cost: 1.20%\n  risk_premium: 1.26%\n\nExample 2: Medium-Risk Borrower\nRecommended Interest Rate: 4.64%\nEffective Annual Rate: 4.74%\nMonthly Payment: $1870.67\nTotal Interest: $12240.48\nExpected Profit: $6040.48\nReturn on Investment: 75.51%\nPricing Components:\n  expected_loss: 0.24%\n  funding_cost: 3.00%\n  operating_cost: 0.20%\n  capital_cost: 1.20%\n  risk_premium: 1.44%\n\nExample 3: High-Risk Borrower\nRecommended Interest Rate: 5.20%\nEffective Annual Rate: 5.33%\nMonthly Payment: $1896.30\nTotal Interest: $13778.00\nExpected Profit: $4778.00\nReturn on Investment: 59.72%\nPricing Components:\n  expected_loss: 0.80%\n  funding_cost: 3.00%\n  operating_cost: 0.20%\n  capital_cost: 1.20%\n  risk_premium: 2.00%\n</code></pre>"},{"location":"user-guide/credit/loan_pricing/#pricing-component-analysis","title":"Pricing Component Analysis","text":"<p>Each component of the loan pricing model serves a specific purpose:</p> <ol> <li> <p>Expected Loss Component (pd \u00d7 lgd / term)</p> <ul> <li>Compensates for the expected credit losses</li> <li>Directly proportional to both probability of default and loss severity</li> <li>Higher risk borrowers have significantly higher expected loss components</li> </ul> </li> <li> <p>Funding Cost Component</p> <ul> <li>Represents the lender's cost of obtaining the funds to lend</li> <li>Typically based on market interest rates</li> <li>Generally consistent across borrowers regardless of risk</li> </ul> </li> <li> <p>Operating Cost Component (operating_cost / term)</p> <ul> <li>Covers origination, servicing, and administrative costs</li> <li>Spread over the life of the loan</li> <li>May vary slightly based on loan complexity</li> </ul> </li> <li> <p>Capital Cost Component (capital_requirement \u00d7 target_roe)</p> <ul> <li>Compensates for the opportunity cost of capital allocated to the loan</li> <li>Higher risk loans may require more capital allocation</li> <li>Reflects the lender's required return on invested capital</li> </ul> </li> <li> <p>Risk Premium (expected_loss + capital_cost)</p> <ul> <li>The combined risk-related components</li> <li>Represents the additional return required to compensate for risk</li> <li>Primary differentiator in pricing between low and high-risk borrowers</li> </ul> </li> </ol>"},{"location":"user-guide/credit/loan_pricing/#practical-applications","title":"Practical Applications","text":"<p>Risk-based loan pricing can be used for:</p> <ol> <li>Consumer Lending: Setting appropriate rates for personal loans, auto loans, and mortgages</li> <li>Commercial Lending: Pricing business loans based on company financial health</li> <li>Credit Card Pricing: Determining APRs for different customer segments</li> <li>Loan Portfolio Management: Ensuring adequate returns across a portfolio of loans</li> <li>Competitive Analysis: Benchmarking pricing against market competitors</li> </ol>"},{"location":"user-guide/credit/loan_pricing/#limitations-and-considerations","title":"Limitations and Considerations","text":"<p>When using risk-based loan pricing, consider these limitations:</p> <ol> <li>Model Assumptions: The accuracy depends on reliable estimates of PD and LGD</li> <li>Market Constraints: Competitive pressures may limit the ability to charge risk-appropriate rates</li> <li>Regulatory Considerations: Fair lending laws may restrict risk-based pricing in some markets</li> <li>Customer Acceptance: Very high rates may lead to adverse selection or reduced demand</li> <li>Economic Cycles: Risk parameters should be adjusted for changing economic conditions </li> </ol>"},{"location":"user-guide/credit/logistic_regression_score/","title":"Logistic Regression Score","text":"<p>The <code>logistic_regression_score</code> function implements a credit scoring model based on logistic regression, which is widely used in credit risk assessment. This function converts logistic regression outputs into a credit score on a standard scale (300-850), making it easier to interpret and use in credit decisions.</p>"},{"location":"user-guide/credit/logistic_regression_score/#usage-in-pypulate","title":"Usage in Pypulate","text":"<pre><code>from pypulate.credit import logistic_regression_score\n\n# Calculate credit score using logistic regression\nresult = logistic_regression_score(\n    coefficients=[0.5, -0.3, 0.8, -0.4],  # Coefficients from logistic regression model\n    features=[25000, 0.3, 5, 2],          # Feature values (e.g., income, DTI, years employed, inquiries)\n    intercept=-2.5                        # Intercept term from logistic regression model\n)\n\n# Access the results\nprobability = result[\"probability_of_default\"]\nscore = result[\"credit_score\"]\nrisk_category = result[\"risk_category\"]\nlog_odds = result[\"log_odds\"]\n</code></pre>"},{"location":"user-guide/credit/logistic_regression_score/#parameters","title":"Parameters","text":"Parameter Type Description Default <code>coefficients</code> array_like Coefficients from the logistic regression model Required <code>features</code> array_like Feature values for the borrower being scored Required <code>intercept</code> float Intercept term from the logistic regression model 0"},{"location":"user-guide/credit/logistic_regression_score/#return-value","title":"Return Value","text":"<p>The function returns a dictionary with the following keys:</p> Key Type Description <code>probability_of_default</code> float The calculated probability of default (between 0 and 1) <code>credit_score</code> int The credit score on a 300-850 scale <code>risk_category</code> str Categorical risk assessment (\"Excellent\", \"Good\", \"Fair\", \"Poor\", or \"Very Poor\") <code>log_odds</code> float The log odds from the logistic regression calculation"},{"location":"user-guide/credit/logistic_regression_score/#risk-level-classification","title":"Risk Level Classification","text":"<p>The credit score is categorized into risk levels:</p> Credit Score Range Risk Level 750-850 Excellent 700-749 Good 650-699 Fair 600-649 Poor 300-599 Very Poor"},{"location":"user-guide/credit/logistic_regression_score/#comprehensive-example","title":"Comprehensive Example","text":"<p>Here's a complete example demonstrating how to calculate and analyze credit scores for different borrowers:</p> <pre><code>from pypulate.credit import logistic_regression_score\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Define a simple logistic regression model\n# Coefficients for: income (in $10k), DTI ratio, years employed, recent inquiries\ncoefficients = [\n    -0.2,  # Income (negative coefficient: higher income -&gt; lower default probability)\n    2.5,   # DTI ratio (positive coefficient: higher DTI -&gt; higher default probability)\n    -0.3,  # Years employed (negative coefficient: longer employment -&gt; lower default probability)\n    0.4    # Recent inquiries (positive coefficient: more inquiries -&gt; higher default probability)\n]\nintercept = -1.0  # Intercept term\n\n# Example 1: Low-risk borrower\nlow_risk_borrower = logistic_regression_score(\n    coefficients=coefficients,\n    features=[8.0, 0.25, 10, 0],  # $80k income, 25% DTI, 10 years employed, 0 inquiries\n    intercept=intercept\n)\n\n# Example 2: Medium-risk borrower\nmedium_risk_borrower = logistic_regression_score(\n    coefficients=coefficients,\n    features=[4.5, 0.42, 3, 2],  # $45k income, 42% DTI, 3 years employed, 2 inquiries\n    intercept=intercept\n)\n\n# Example 3: High-risk borrower\nhigh_risk_borrower = logistic_regression_score(\n    coefficients=coefficients,\n    features=[3.0, 0.45, 2, 4],  # $30k income, 45% DTI, 2 years employed, 4 inquiries\n    intercept=intercept\n)\n\n# Print the results\nprint(\"Logistic Regression Credit Scoring Analysis\")\nprint(\"==========================================\")\n\nprint(\"\\nExample 1: Low-Risk Borrower\")\nprint(f\"Credit Score: {low_risk_borrower['credit_score']}\")\nprint(f\"Probability of Default: {low_risk_borrower['probability_of_default']:.4f}\")\nprint(f\"Risk Category: {low_risk_borrower['risk_category']}\")\nprint(f\"Log Odds: {low_risk_borrower['log_odds']:.4f}\")\n\nprint(\"\\nExample 2: Medium-Risk Borrower\")\nprint(f\"Credit Score: {medium_risk_borrower['credit_score']}\")\nprint(f\"Probability of Default: {medium_risk_borrower['probability_of_default']:.4f}\")\nprint(f\"Risk Category: {medium_risk_borrower['risk_category']}\")\nprint(f\"Log Odds: {medium_risk_borrower['log_odds']:.4f}\")\n\nprint(\"\\nExample 3: High-Risk Borrower\")\nprint(f\"Credit Score: {high_risk_borrower['credit_score']}\")\nprint(f\"Probability of Default: {high_risk_borrower['probability_of_default']:.4f}\")\nprint(f\"Risk Category: {high_risk_borrower['risk_category']}\")\nprint(f\"Log Odds: {high_risk_borrower['log_odds']:.4f}\")\n\n# Visualize the results - Credit Score Comparison\nrisk_profiles = ['Low Risk', 'Medium Risk', 'High Risk']\nscores = [\n    low_risk_borrower['credit_score'],\n    medium_risk_borrower['credit_score'],\n    high_risk_borrower['credit_score']\n]\nprobabilities = [\n    low_risk_borrower['probability_of_default'],\n    medium_risk_borrower['probability_of_default'],\n    high_risk_borrower['probability_of_default']\n]\n\n# Create a bar chart for credit score comparison\nplt.figure(figsize=(10, 6))\nbars = plt.bar(risk_profiles, scores, color=['green', 'orange', 'red'])\n\n# Add horizontal lines for the score thresholds\nplt.axhline(y=750, color='g', linestyle='--', label='Excellent (\u2265 750)')\nplt.axhline(y=700, color='b', linestyle='--', label='Good (\u2265 700)')\nplt.axhline(y=650, color='orange', linestyle='--', label='Fair (\u2265 650)')\nplt.axhline(y=600, color='r', linestyle='--', label='Poor (\u2265 600)')\n\n# Add the score values on top of the bars\nfor bar in bars:\n    height = bar.get_height()\n    plt.text(bar.get_x() + bar.get_width()/2., height + 5,\n             f'{height:.0f}', ha='center', va='bottom')\n\nplt.ylabel('Credit Score')\nplt.title('Credit Score Comparison')\nplt.ylim(300, 850)  # Standard credit score range\nplt.legend()\nplt.grid(axis='y', linestyle='--', alpha=0.7)\nplt.tight_layout()\nplt.show()\n\n# Create a figure showing the relationship between probability and score\nplt.figure(figsize=(12, 6))\nprob_range = np.linspace(0, 1, 100)\nscore_range = 850 - 550 * prob_range\nscore_range = np.clip(score_range, 300, 850)\n\nplt.plot(prob_range, score_range, 'b-', linewidth=2)\n\n# Add points for our examples\nplt.scatter([low_risk_borrower['probability_of_default']], [low_risk_borrower['credit_score']], \n            color='green', s=100, label='Low Risk')\nplt.scatter([medium_risk_borrower['probability_of_default']], [medium_risk_borrower['credit_score']], \n            color='orange', s=100, label='Medium Risk')\nplt.scatter([high_risk_borrower['probability_of_default']], [high_risk_borrower['credit_score']], \n            color='red', s=100, label='High Risk')\n\n# Add horizontal lines for score categories\nplt.axhline(y=750, color='g', linestyle='--')\nplt.axhline(y=700, color='b', linestyle='--')\nplt.axhline(y=650, color='orange', linestyle='--')\nplt.axhline(y=600, color='r', linestyle='--')\n\n# Add text labels for score categories\nplt.text(0.95, 800, 'Excellent', ha='right', va='center', color='green', fontweight='bold')\nplt.text(0.95, 725, 'Good', ha='right', va='center', color='blue', fontweight='bold')\nplt.text(0.95, 675, 'Fair', ha='right', va='center', color='orange', fontweight='bold')\nplt.text(0.95, 625, 'Poor', ha='right', va='center', color='red', fontweight='bold')\nplt.text(0.95, 450, 'Very Poor', ha='right', va='center', color='darkred', fontweight='bold')\n\nplt.xlabel('Probability of Default')\nplt.ylabel('Credit Score')\nplt.title('Relationship Between Probability of Default and Credit Score')\nplt.grid(True, linestyle='--', alpha=0.7)\nplt.legend()\nplt.tight_layout()\nplt.show()\n\n# Create a sensitivity analysis for a single feature\nfeature_index = 1  # DTI ratio (index 1 in our feature list)\nfeature_name = \"Debt-to-Income Ratio\"\nfeature_values = np.linspace(0.1, 0.6, 50)  # Range of DTI values from 10% to 60%\nscores = []\nprobabilities = []\n\n# Base features for a typical borrower\nbase_features = [5.0, 0.35, 5, 2]  # $50k income, 35% DTI, 5 years employed, 2 inquiries\n\nfor feature_value in feature_values:\n    # Create a copy of base features and update the feature of interest\n    test_features = base_features.copy()\n    test_features[feature_index] = feature_value\n\n    # Calculate score\n    result = logistic_regression_score(\n        coefficients=coefficients,\n        features=test_features,\n        intercept=intercept\n    )\n    scores.append(result['credit_score'])\n    probabilities.append(result['probability_of_default'])\n\n# Plot score sensitivity to feature\nplt.figure(figsize=(12, 6))\nplt.subplot(1, 2, 1)\nplt.plot(feature_values * 100, scores, 'b-', linewidth=2)\nplt.xlabel(f'{feature_name} (%)')\nplt.ylabel('Credit Score')\nplt.title(f'Credit Score Sensitivity to {feature_name}')\nplt.grid(True, linestyle='--', alpha=0.7)\n\n# Add horizontal lines for score categories\nplt.axhline(y=750, color='g', linestyle='--', label='Excellent (\u2265 750)')\nplt.axhline(y=700, color='b', linestyle='--', label='Good (\u2265 700)')\nplt.axhline(y=650, color='orange', linestyle='--', label='Fair (\u2265 650)')\nplt.axhline(y=600, color='r', linestyle='--', label='Poor (\u2265 600)')\nplt.legend(loc='lower left')\n\n# Plot probability sensitivity to feature\nplt.subplot(1, 2, 2)\nplt.plot(feature_values * 100, probabilities, 'r-', linewidth=2)\nplt.xlabel(f'{feature_name} (%)')\nplt.ylabel('Probability of Default')\nplt.title(f'Default Probability Sensitivity to {feature_name}')\nplt.grid(True, linestyle='--', alpha=0.7)\nplt.tight_layout()\nplt.show()\n</code></pre>"},{"location":"user-guide/credit/logistic_regression_score/#example-output","title":"Example Output","text":"<pre><code>Logistic Regression Credit Scoring Analysis\n==========================================\nExample 1: Low-Risk Borrower\nCredit Score: 847\nProbability of Default: 0.0069\nRisk Category: Excellent\nLog Odds: -4.9750\n\nExample 2: Medium-Risk Borrower\nCredit Score: 697\nProbability of Default: 0.2789\nRisk Category: Fair\nLog Odds: -0.9500\n\nExample 3: High-Risk Borrower\nCredit Score: 505\nProbability of Default: 0.6283\nRisk Category: Very Poor\nLog Odds: 0.5250\n</code></pre>"},{"location":"user-guide/credit/logistic_regression_score/#visualizations","title":"Visualizations","text":""},{"location":"user-guide/credit/logistic_regression_score/#credit-score-comparison","title":"Credit Score Comparison","text":"<p>The following visualization shows a comparison of credit scores across three different borrower profiles:</p> <p></p> <p>This chart displays the credit scores for low, medium, and high-risk borrowers, with horizontal lines indicating the threshold values that separate different credit quality categories.</p>"},{"location":"user-guide/credit/logistic_regression_score/#probability-to-score-relationship","title":"Probability to Score Relationship","text":"<p>The following visualization demonstrates the relationship between probability of default and credit score:</p> <p></p> <p>This chart illustrates how the credit score decreases as the probability of default increases, with points showing where our example borrowers fall on the curve.</p>"},{"location":"user-guide/credit/logistic_regression_score/#feature-sensitivity-analysis","title":"Feature Sensitivity Analysis","text":"<p>The following visualization shows how changes in a single feature affect both the credit score and probability of default:</p> <p></p> <p>This sensitivity analysis demonstrates how increasing the debt-to-income ratio leads to lower credit scores and higher default probabilities.</p>"},{"location":"user-guide/credit/logistic_regression_score/#practical-applications","title":"Practical Applications","text":"<p>Logistic regression scoring can be used for:</p> <ol> <li>Credit Underwriting: Automating credit decisions based on objective criteria</li> <li>Risk-Based Pricing: Setting interest rates based on creditworthiness</li> <li>Portfolio Segmentation: Dividing borrowers into risk tiers for targeted strategies</li> <li>Pre-qualification: Providing potential borrowers with preliminary credit assessments</li> <li>Account Management: Monitoring existing customers for changes in credit quality</li> </ol>"},{"location":"user-guide/credit/logistic_regression_score/#advantages-and-limitations","title":"Advantages and Limitations","text":""},{"location":"user-guide/credit/logistic_regression_score/#advantages","title":"Advantages","text":"<ol> <li>Interpretability: Coefficients directly show the impact of each feature</li> <li>Probability Output: Provides a meaningful probability of default</li> <li>Efficiency: Computationally simple and fast to implement</li> <li>Flexibility: Can incorporate various types of features</li> <li>Standard Scale: Converts to a familiar credit score scale</li> </ol>"},{"location":"user-guide/credit/logistic_regression_score/#limitations","title":"Limitations","text":"<ol> <li>Linearity Assumption: Assumes a linear relationship in the log odds</li> <li>Feature Independence: Doesn't naturally capture interactions between features</li> <li>Data Quality Dependency: Performance depends on the quality of training data</li> <li>Model Simplicity: May not capture complex patterns as well as more advanced models</li> <li>Calibration Needs: Requires proper calibration to produce accurate probabilities </li> </ol>"},{"location":"user-guide/credit/loss_given_default/","title":"Loss Given Default (LGD)","text":"<p>Loss Given Default (LGD) is a key component in credit risk modeling that estimates the portion of an exposure that is lost when a borrower defaults. It's a critical parameter in calculating expected credit losses and pricing loans.</p>"},{"location":"user-guide/credit/loss_given_default/#overview","title":"Overview","text":"<p>The LGD estimation in Pypulate considers:</p> <ul> <li>Collateral value and liquidation costs</li> <li>Loan amount and loan-to-value ratio</li> <li>Historical recovery rates (if available)</li> <li>Time value of money</li> </ul> <p>The model provides both a point-in-time LGD estimate and a present value calculation that accounts for the time to recovery.</p>"},{"location":"user-guide/credit/loss_given_default/#usage","title":"Usage","text":"<pre><code>from pypulate.credit import loss_given_default\n\n# Basic usage with collateral\nresult = loss_given_default(\n    collateral_value=80000,  # Value of collateral\n    loan_amount=100000,      # Outstanding loan amount\n    liquidation_costs=0.15,  # Costs to liquidate collateral (15%)\n    time_to_recovery=1.5     # Expected time to recovery in years\n)\n\n# With historical recovery rate\nresult = loss_given_default(\n    collateral_value=80000,\n    loan_amount=100000,\n    recovery_rate=0.6,       # Historical recovery rate for similar loans\n    liquidation_costs=0.15,\n    time_to_recovery=1.5\n)\n\n# Access results\nlgd = result[\"lgd\"]\npresent_value_lgd = result[\"present_value_lgd\"]\nrisk_level = result[\"risk_level\"]\ncomponents = result[\"components\"]\n</code></pre>"},{"location":"user-guide/credit/loss_given_default/#parameters","title":"Parameters","text":"Parameter Type Description Default <code>collateral_value</code> float Value of collateral Required <code>loan_amount</code> float Outstanding loan amount Required <code>recovery_rate</code> float, optional Historical recovery rate for similar loans None <code>liquidation_costs</code> float Costs associated with liquidating collateral (as a decimal) 0.1 (10%) <code>time_to_recovery</code> float Expected time to recovery in years 1.0"},{"location":"user-guide/credit/loss_given_default/#return-value","title":"Return Value","text":"<p>The function returns a dictionary with the following keys:</p> Key Type Description <code>lgd</code> float Loss given default estimate <code>present_value_lgd</code> float Present value of LGD accounting for time to recovery <code>risk_level</code> str Risk level categorization (\"Very Low\", \"Low\", \"Moderate\", \"High\", \"Very High\") <code>components</code> dict Dictionary containing calculation components <p>The <code>components</code> dictionary includes:</p> <ul> <li><code>collateral_value</code>: Original collateral value</li> <li><code>net_collateral_value</code>: Collateral value after liquidation costs</li> <li><code>loan_amount</code>: Outstanding loan amount</li> <li><code>loan_to_value</code>: Loan-to-value ratio</li> <li><code>collateral_lgd</code>: LGD based solely on collateral</li> <li><code>time_value_factor</code>: Discount factor for time value of money</li> </ul> <p>If a recovery rate is provided, additional components are included:</p> <ul> <li><code>recovery_rate</code>: Historical recovery rate</li> <li><code>weight_collateral</code>: Weight assigned to collateral-based LGD</li> <li><code>weight_historical</code>: Weight assigned to historical recovery rate</li> </ul>"},{"location":"user-guide/credit/loss_given_default/#risk-level-classification","title":"Risk Level Classification","text":"<p>The LGD estimate is categorized into risk levels:</p> LGD Range Risk Level &lt; 0.1 (10%) Very Low 0.1 - 0.3 (10-30%) Low 0.3 - 0.5 (30-50%) Moderate 0.5 - 0.7 (50-70%) High &gt; 0.7 (70%) Very High"},{"location":"user-guide/credit/loss_given_default/#comprehensive-example","title":"Comprehensive Example","text":"<p>Here's a complete example demonstrating how to calculate and analyze LGD for different loan scenarios using only matplotlib and numpy:</p> <pre><code>from pypulate.credit import loss_given_default\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Define sample loan data\nloan_ids = [1, 2, 3, 4, 5]\nloan_amounts = [100000, 200000, 150000, 300000, 80000]\ncollateral_values = [120000, 180000, 100000, 250000, 50000]\nrecovery_rates = [0.65, 0.55, None, 0.6, 0.5]\nliquidation_costs = [0.1, 0.15, 0.12, 0.2, 0.1]\ntime_to_recovery = [1.0, 1.5, 1.0, 2.0, 1.0]\nloan_types = ['Mortgage', 'Commercial', 'Personal', 'Commercial', 'Personal']\n\n# Calculate LGD for each loan\nlgd_values = []\npv_lgd_values = []\nrisk_levels = []\nltv_values = []\ncollateral_lgd_values = []\nweight_collateral_values = []\nweight_historical_values = []\ntime_value_factors = []\n\nfor i in range(len(loan_ids)):\n    lgd_result = loss_given_default(\n        collateral_value=collateral_values[i],\n        loan_amount=loan_amounts[i],\n        recovery_rate=recovery_rates[i],\n        liquidation_costs=liquidation_costs[i],\n        time_to_recovery=time_to_recovery[i]\n    )\n\n    # Extract results\n    lgd_values.append(lgd_result['lgd'])\n    pv_lgd_values.append(lgd_result['present_value_lgd'])\n    risk_levels.append(lgd_result['risk_level'])\n\n    # Extract components\n    components = lgd_result['components']\n    ltv_values.append(components['loan_to_value'])\n    collateral_lgd_values.append(components.get('collateral_lgd', 0))\n    weight_collateral_values.append(components.get('weight_collateral', 1.0) if 'weight_collateral' in components else 1.0)\n    weight_historical_values.append(components.get('weight_historical', 0.0) if 'weight_historical' in components else 0.0)\n    time_value_factors.append(components['time_value_factor'])\n\n# Print the results\nprint(\"Loss Given Default Analysis\")\nprint(\"===========================\")\nprint(\"Loan ID | Loan Type   | LGD     | Present Value LGD | Risk Level\")\nprint(\"--------|-------------|---------|------------------|------------\")\nfor i in range(len(loan_ids)):\n    print(f\"{loan_ids[i]:7d} | {loan_types[i]:&lt;11s} | {lgd_values[i]:.6f} | {pv_lgd_values[i]:.6f} | {risk_levels[i]}\")\n\n# Calculate expected loss for each loan (assuming PD = 0.05 for all loans)\npd_value = 0.05  # 5% probability of default\nexpected_losses = [pd_value * loan_amounts[i] * lgd_values[i] for i in range(len(loan_ids))]\n\n# Print expected loss\nprint(\"\\nExpected Loss Analysis (PD = 5%)\")\nprint(\"================================\")\nfor i in range(len(loan_ids)):\n    print(f\"Loan {loan_ids[i]} ({loan_types[i]}): ${expected_losses[i]:.2f}\")\n\n# Visualize LGD by loan type\nplt.figure(figsize=(10, 6))\n\n# Group by loan type\nunique_loan_types = list(set(loan_types))\nloan_type_indices = {loan_type: [] for loan_type in unique_loan_types}\nfor i, loan_type in enumerate(loan_types):\n    loan_type_indices[loan_type].append(i)\n\n# Calculate average LGD by loan type\nloan_type_avg_lgd = []\nfor loan_type in unique_loan_types:\n    indices = loan_type_indices[loan_type]\n    avg_lgd = sum(lgd_values[i] for i in indices) / len(indices)\n    loan_type_avg_lgd.append(avg_lgd)\n\n# Create bar chart\nplt.bar(unique_loan_types, loan_type_avg_lgd, color=['#1f77b4', '#ff7f0e', '#2ca02c'])\nplt.title('Average LGD by Loan Type')\nplt.xlabel('Loan Type')\nplt.ylabel('Loss Given Default (LGD)')\nplt.grid(axis='y', linestyle='--', alpha=0.7)\nplt.tight_layout()\nplt.show()\n\n# Visualize the relationship between LTV and LGD\nplt.figure(figsize=(10, 6))\n\n# Create scatter plot with different colors for loan types\ncolors = {'Mortgage': 'blue', 'Commercial': 'green', 'Personal': 'red'}\nfor loan_type in unique_loan_types:\n    indices = loan_type_indices[loan_type]\n    x = [ltv_values[i] for i in indices]\n    y = [lgd_values[i] for i in indices]\n    sizes = [ltv_values[i] * 100 for i in indices]  # Size proportional to LTV\n    plt.scatter(x, y, s=sizes, c=colors[loan_type], alpha=0.7, label=loan_type)\n\nplt.title('Relationship Between Loan-to-Value Ratio and LGD')\nplt.xlabel('Loan-to-Value Ratio')\nplt.ylabel('Loss Given Default (LGD)')\nplt.grid(True, linestyle='--', alpha=0.7)\n\n# Add risk level regions\nplt.axhspan(0, 0.1, alpha=0.2, color='green', label='Very Low Risk')\nplt.axhspan(0.1, 0.3, alpha=0.2, color='lightgreen')\nplt.axhspan(0.3, 0.5, alpha=0.2, color='yellow', label='Moderate Risk')\nplt.axhspan(0.5, 0.7, alpha=0.2, color='orange')\nplt.axhspan(0.7, 1.0, alpha=0.2, color='red', label='Very High Risk')\n\nplt.legend()\nplt.tight_layout()\nplt.show()\n\n# Create a sensitivity analysis for collateral value and liquidation costs\n# For a fixed loan amount of $100,000\nloan_amount = 100000\ncollateral_values_array = np.linspace(50000, 150000, 11)  # 50% to 150% of loan amount\nliquidation_costs_array = np.linspace(0.05, 0.3, 6)  # 5% to 30%\n\n# Create matrices to store LGD values\nlgd_matrix = np.zeros((len(collateral_values_array), len(liquidation_costs_array)))\nltv_array = np.zeros(len(collateral_values_array))\n\n# Calculate LGD for each combination\nfor i, collateral in enumerate(collateral_values_array):\n    ltv_array[i] = loan_amount / collateral\n    for j, cost in enumerate(liquidation_costs_array):\n        result = loss_given_default(\n            collateral_value=collateral,\n            loan_amount=loan_amount,\n            liquidation_costs=cost\n        )\n        lgd_matrix[i, j] = result['lgd']\n\n# Create a heatmap\nplt.figure(figsize=(12, 8))\nX, Y = np.meshgrid(liquidation_costs_array, collateral_values_array)\ncontour = plt.contourf(X, Y, lgd_matrix, levels=20, cmap='RdYlGn_r')\nplt.colorbar(contour, label='Loss Given Default (LGD)')\n\n# Add contour lines\ncontour_lines = plt.contour(X, Y, lgd_matrix, levels=[0.1, 0.3, 0.5, 0.7], \n                           colors='black', linestyles='dashed')\nplt.clabel(contour_lines, inline=True, fontsize=10)\n\n# Add labels and title\nplt.xlabel('Liquidation Costs')\nplt.ylabel('Collateral Value ($)')\nplt.title('LGD Sensitivity to Collateral Value and Liquidation Costs\\n(Loan Amount: $100,000)')\nplt.grid(True, linestyle='--', alpha=0.3)\n\n# Add LTV reference line\nax2 = plt.twinx()\nax2.plot(liquidation_costs_array, [100000] * len(liquidation_costs_array), 'r--', label='LTV = 1.0')\nax2.set_ylabel('Loan-to-Value Reference')\nax2.set_ylim(plt.ylim())\nax2.legend(loc='upper right')\n\nplt.tight_layout()\nplt.show()\n\n# Analyze the impact of time to recovery on present value LGD\ntime_values_array = np.linspace(0.5, 5, 10)  # 0.5 to 5 years\nlgd_base = 0.4  # Base LGD of 40%\npv_lgd_array = []\n\nfor time in time_values_array:\n    result = loss_given_default(\n        collateral_value=75000,\n        loan_amount=100000,\n        time_to_recovery=time\n    )\n    pv_lgd_array.append(result['present_value_lgd'])\n\n# Plot the time value effect\nplt.figure(figsize=(10, 6))\nplt.plot(time_values_array, pv_lgd_array, 'b-', linewidth=2)\nplt.axhline(y=lgd_base, color='r', linestyle='--', label=f'Base LGD: {lgd_base:.1%}')\nplt.fill_between(time_values_array, pv_lgd_array, lgd_base, alpha=0.2, color='blue')\n\nplt.title('Impact of Time to Recovery on Present Value LGD')\nplt.xlabel('Time to Recovery (Years)')\nplt.ylabel('Present Value LGD')\nplt.grid(True, linestyle='--', alpha=0.7)\nplt.legend()\nplt.tight_layout()\nplt.show()\n\n# Compare collateral-based LGD vs. recovery rate-based LGD\nrecovery_rates_array = np.linspace(0.3, 0.9, 7)\ncollateral_values_list = [60000, 80000, 100000, 120000]  # 60% to 120% of loan amount\nloan_amount = 100000\nliquidation_cost = 0.15\n\nplt.figure(figsize=(12, 8))\n\nfor collateral in collateral_values_list:\n    lgd_list = []\n    for recovery in recovery_rates_array:\n        result = loss_given_default(\n            collateral_value=collateral,\n            loan_amount=loan_amount,\n            recovery_rate=recovery,\n            liquidation_costs=liquidation_cost\n        )\n        lgd_list.append(result['lgd'])\n\n    ltv = loan_amount / collateral\n    plt.plot(recovery_rates_array, lgd_list, marker='o', linewidth=2, \n             label=f'Collateral: ${collateral:,} (LTV: {ltv:.2f})')\n\nplt.title('LGD vs. Recovery Rate for Different Collateral Values')\nplt.xlabel('Historical Recovery Rate')\nplt.ylabel('Loss Given Default (LGD)')\nplt.grid(True, linestyle='--', alpha=0.7)\nplt.legend()\nplt.tight_layout()\nplt.show()\n</code></pre>"},{"location":"user-guide/credit/loss_given_default/#example-output","title":"Example Output","text":"<p>The above code will produce a detailed analysis of LGD across different loan scenarios, including:</p> <pre><code>Loss Given Default Analysis\n===========================\nLoan ID | Loan Type   | LGD     | Present Value LGD | Risk Level\n--------|-------------|---------|------------------|------------\n      1 | Mortgage    | 0.210000 | 0.200000 | Low\n      2 | Commercial  | 0.364000 | 0.338312 | Moderate\n      3 | Personal    | 0.413333 | 0.393651 | Moderate\n      4 | Commercial  | 0.373333 | 0.338624 | Moderate\n      5 | Personal    | 0.475000 | 0.452381 | Moderate\nExpected Loss Analysis (PD = 5%)\n================================\nLoan 1 (Mortgage): $1050.00\nLoan 2 (Commercial): $3640.00\nLoan 3 (Personal): $3100.00\nLoan 4 (Commercial): $5600.00\nLoan 5 (Personal): $1900.00\n</code></pre>"},{"location":"user-guide/credit/loss_given_default/#visualizations","title":"Visualizations","text":""},{"location":"user-guide/credit/loss_given_default/#impact-of-time-to-recovery","title":"Impact of Time to Recovery","text":"<p>This visualization shows how the time to recovery affects the present value of LGD. As the time to recovery increases, the present value of LGD decreases due to the time value of money, even though the nominal LGD remains constant.</p> <p></p>"},{"location":"user-guide/credit/loss_given_default/#relationship-between-loan-to-value-ratio-and-lgd","title":"Relationship Between Loan-to-Value Ratio and LGD","text":"<p>This scatter plot illustrates the relationship between the loan-to-value ratio and LGD for different loan types. Higher LTV ratios generally correspond to higher LGD values. The background is color-coded to indicate different risk level regions.</p> <p></p>"},{"location":"user-guide/credit/loss_given_default/#lgd-sensitivity","title":"LGD Sensitivity","text":"<p>This heatmap demonstrates how LGD changes with different combinations of collateral value and liquidation costs, helping to visualize the sensitivity of LGD to these two key parameters. The contour lines represent different LGD levels.</p> <p></p>"},{"location":"user-guide/credit/loss_given_default/#key-insights","title":"Key Insights","text":"<p>From the comprehensive analysis, several key insights emerge:</p> <ol> <li> <p>Loan-to-Value (LTV) Ratio: As LTV increases, LGD typically increases. Loans with LTV &lt; 1.0 (where collateral exceeds loan amount) have lower LGD.</p> </li> <li> <p>Liquidation Costs: Higher liquidation costs significantly increase LGD, especially for loans with LTV close to 1.0.</p> </li> <li> <p>Recovery Rates: Historical recovery rates can provide valuable information to complement collateral-based LGD estimates.</p> </li> <li> <p>Time Value Effect: Longer recovery times reduce the present value of LGD but increase uncertainty.</p> </li> <li> <p>Risk Segmentation: LGD varies by loan type, with secured loans like mortgages typically having lower LGD than personal loans.</p> </li> </ol>"},{"location":"user-guide/credit/loss_given_default/#notes","title":"Notes","text":"<ul> <li>The LGD is expressed as a decimal between 0 and 1, where 0 means full recovery and 1 means total loss.</li> <li>The model assumes a fixed discount rate of 5% for present value calculations.</li> <li>When collateral value exceeds the loan amount (after liquidation costs), the collateral-based LGD is 0.</li> <li>The weighting between collateral-based LGD and historical recovery rates depends on the loan-to-value ratio. </li> </ul>"},{"location":"user-guide/credit/merton_model/","title":"Merton Model","text":"<p>The <code>merton_model</code> function implements the Merton structural model of default, a fundamental approach in credit risk modeling that treats a company's equity as a call option on its assets. This model, developed by Robert C. Merton in 1974, provides a framework for estimating the probability of default based on the company's capital structure and asset volatility.</p>"},{"location":"user-guide/credit/merton_model/#usage-in-pypulate","title":"Usage in Pypulate","text":"<pre><code>from pypulate.credit import merton_model\n\n# Calculate default probability using the Merton model\nresult = merton_model(\n    asset_value=1000000,        # $1,000,000 market value of assets\n    debt_face_value=600000,     # $600,000 face value of debt\n    asset_volatility=0.25,      # 25% annualized asset volatility\n    risk_free_rate=0.03,        # 3% risk-free rate\n    time_to_maturity=1.0        # 1 year to debt maturity\n)\n\n# Access the results\npd = result[\"probability_of_default\"]\ndd = result[\"distance_to_default\"]\n</code></pre>"},{"location":"user-guide/credit/merton_model/#parameters","title":"Parameters","text":"Parameter Type Description Default <code>asset_value</code> float Market value of the company's assets Required <code>debt_face_value</code> float Face value of the company's debt Required <code>asset_volatility</code> float Volatility of assets (annualized) Required <code>risk_free_rate</code> float Risk-free interest rate Required <code>time_to_maturity</code> float Time to debt maturity in years Required"},{"location":"user-guide/credit/merton_model/#return-value","title":"Return Value","text":"<p>The function returns a dictionary with the following keys:</p> Key Type Description <code>probability_of_default</code> float Probability of default within the time horizon <code>distance_to_default</code> float Number of standard deviations to default threshold <code>d1</code> float First parameter in the Black-Scholes-Merton formula <code>d2</code> float Second parameter in the Black-Scholes-Merton formula"},{"location":"user-guide/credit/merton_model/#risk-level-classification","title":"Risk Level Classification","text":"<p>The probability of default is categorized into risk levels:</p> Probability of Default Range Risk Level &lt; 0.5% Very Low 0.5% - 2% Low 2% - 5% Moderate 5% - 15% High &gt; 15% Very High"},{"location":"user-guide/credit/merton_model/#comprehensive-example","title":"Comprehensive Example","text":"<p>Here's a complete example demonstrating how to calculate and analyze default probabilities for companies with different financial profiles:</p> <pre><code>from pypulate.credit import merton_model\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Example 1: Financially strong company\nstrong_company = merton_model(\n    asset_value=1000000,        # $1,000,000 market value of assets\n    debt_face_value=400000,     # $400,000 face value of debt\n    asset_volatility=0.20,      # 20% annualized asset volatility\n    risk_free_rate=0.03,        # 3% risk-free rate\n    time_to_maturity=1.0        # 1 year to debt maturity\n)\n\n# Example 2: Average company\naverage_company = merton_model(\n    asset_value=1000000,        # $1,000,000 market value of assets\n    debt_face_value=600000,     # $600,000 face value of debt\n    asset_volatility=0.30,      # 30% annualized asset volatility\n    risk_free_rate=0.03,        # 3% risk-free rate\n    time_to_maturity=1.0        # 1 year to debt maturity\n)\n\n# Example 3: Financially distressed company\ndistressed_company = merton_model(\n    asset_value=1000000,        # $1,000,000 market value of assets\n    debt_face_value=800000,     # $800,000 face value of debt\n    asset_volatility=0.40,      # 40% annualized asset volatility\n    risk_free_rate=0.03,        # 3% risk-free rate\n    time_to_maturity=1.0        # 1 year to debt maturity\n)\n\n# Print the results\nprint(\"Merton Model Analysis\")\nprint(\"====================\")\n\nprint(\"\\nExample 1: Financially Strong Company\")\nprint(f\"Probability of Default: {strong_company['probability_of_default']:.4%}\")\nprint(f\"Distance to Default: {strong_company['distance_to_default']:.2f}\")\n\nprint(\"\\nExample 2: Average Company\")\nprint(f\"Probability of Default: {average_company['probability_of_default']:.4%}\")\nprint(f\"Distance to Default: {average_company['distance_to_default']:.2f}\")\n\nprint(\"\\nExample 3: Financially Distressed Company\")\nprint(f\"Probability of Default: {distressed_company['probability_of_default']:.4%}\")\nprint(f\"Distance to Default: {distressed_company['distance_to_default']:.2f}\")\n\n# Create a DataFrame for visualization\ncompanies = ['Strong', 'Average', 'Distressed']\npd_values = [\n    strong_company['probability_of_default'],\n    average_company['probability_of_default'],\n    distressed_company['probability_of_default']\n]\ndd_values = [\n    strong_company['distance_to_default'],\n    average_company['distance_to_default'],\n    distressed_company['distance_to_default']\n]\n\n# Create a bar chart for probability of default\nplt.figure(figsize=(12, 6))\nplt.subplot(1, 2, 1)\nbars = plt.bar(companies, [pd * 100 for pd in pd_values], color=['green', 'orange', 'red'])\n\n# Add the PD values on top of the bars\nfor bar in bars:\n    height = bar.get_height()\n    plt.text(bar.get_x() + bar.get_width()/2., height + 0.5,\n             f'{height:.2f}%', ha='center', va='bottom')\n\nplt.ylabel('Probability of Default (%)')\nplt.title('Probability of Default by Company Type')\nplt.ylim(0, max([pd * 100 for pd in pd_values]) * 1.2)  # Add some space above the highest bar\n\n# Create a bar chart for distance to default\nplt.subplot(1, 2, 2)\nbars = plt.bar(companies, dd_values, color=['green', 'orange', 'red'])\n\n# Add the DD values on top of the bars\nfor bar in bars:\n    height = bar.get_height()\n    plt.text(bar.get_x() + bar.get_width()/2., height + 0.1,\n             f'{height:.2f}', ha='center', va='bottom')\n\nplt.ylabel('Distance to Default')\nplt.title('Distance to Default by Company Type')\nplt.tight_layout()\nplt.show()\n\n# Sensitivity analysis: Effect of leverage (debt-to-asset ratio) on PD\nleverage_ratios = np.linspace(0.1, 0.95, 50)  # Debt-to-asset ratios from 10% to 95%\npd_by_leverage = []\ndd_by_leverage = []\n\nfor leverage in leverage_ratios:\n    debt = leverage * 1000000  # Debt face value based on leverage ratio\n    result = merton_model(\n        asset_value=1000000,\n        debt_face_value=debt,\n        asset_volatility=0.30,\n        risk_free_rate=0.03,\n        time_to_maturity=1.0\n    )\n    pd_by_leverage.append(result['probability_of_default'])\n    dd_by_leverage.append(result['distance_to_default'])\n\n# Plot the effect of leverage on PD and DD\nplt.figure(figsize=(12, 6))\nplt.subplot(1, 2, 1)\nplt.plot(leverage_ratios, [pd * 100 for pd in pd_by_leverage], 'b-', linewidth=2)\nplt.xlabel('Leverage Ratio (Debt/Assets)')\nplt.ylabel('Probability of Default (%)')\nplt.title('Effect of Leverage on Default Probability')\nplt.grid(True, linestyle='--', alpha=0.7)\n\n# Add risk level regions\nplt.axhspan(0, 0.5, alpha=0.2, color='green', label='Very Low Risk')\nplt.axhspan(0.5, 2, alpha=0.2, color='lightgreen', label='Low Risk')\nplt.axhspan(2, 5, alpha=0.2, color='yellow', label='Moderate Risk')\nplt.axhspan(5, 15, alpha=0.2, color='orange', label='High Risk')\nplt.axhspan(15, 100, alpha=0.2, color='red', label='Very High Risk')\nplt.legend(loc='upper left')\n\nplt.subplot(1, 2, 2)\nplt.plot(leverage_ratios, dd_by_leverage, 'r-', linewidth=2)\nplt.xlabel('Leverage Ratio (Debt/Assets)')\nplt.ylabel('Distance to Default')\nplt.title('Effect of Leverage on Distance to Default')\nplt.grid(True, linestyle='--', alpha=0.7)\nplt.tight_layout()\nplt.show()\n\n# Sensitivity analysis: Effect of asset volatility on PD\nvolatilities = np.linspace(0.1, 0.6, 50)  # Asset volatilities from 10% to 60%\npd_by_volatility = []\ndd_by_volatility = []\n\nfor vol in volatilities:\n    result = merton_model(\n        asset_value=1000000,\n        debt_face_value=600000,  # 60% leverage\n        asset_volatility=vol,\n        risk_free_rate=0.03,\n        time_to_maturity=1.0\n    )\n    pd_by_volatility.append(result['probability_of_default'])\n    dd_by_volatility.append(result['distance_to_default'])\n\n# Plot the effect of asset volatility on PD and DD\nplt.figure(figsize=(12, 6))\nplt.subplot(1, 2, 1)\nplt.plot(volatilities, [pd * 100 for pd in pd_by_volatility], 'b-', linewidth=2)\nplt.xlabel('Asset Volatility')\nplt.ylabel('Probability of Default (%)')\nplt.title('Effect of Asset Volatility on Default Probability')\nplt.grid(True, linestyle='--', alpha=0.7)\n\n# Add risk level regions\nplt.axhspan(0, 0.5, alpha=0.2, color='green', label='Very Low Risk')\nplt.axhspan(0.5, 2, alpha=0.2, color='lightgreen', label='Low Risk')\nplt.axhspan(2, 5, alpha=0.2, color='yellow', label='Moderate Risk')\nplt.axhspan(5, 15, alpha=0.2, color='orange', label='High Risk')\nplt.axhspan(15, 100, alpha=0.2, color='red', label='Very High Risk')\nplt.legend(loc='upper left')\n\nplt.subplot(1, 2, 2)\nplt.plot(volatilities, dd_by_volatility, 'r-', linewidth=2)\nplt.xlabel('Asset Volatility')\nplt.ylabel('Distance to Default')\nplt.title('Effect of Asset Volatility on Distance to Default')\nplt.grid(True, linestyle='--', alpha=0.7)\nplt.tight_layout()\nplt.show()\n</code></pre>"},{"location":"user-guide/credit/merton_model/#example-output","title":"Example Output","text":"<pre><code>Merton Model Analysis\n====================\n\nMerton Model Analysis\n====================\nExample 1: Financially Strong Company\nProbability of Default: 0.0002%\nDistance to Default: 4.63\n\nExample 2: Average Company\nProbability of Default: 4.9191%\nDistance to Default: 1.65\n\nExample 3: Financially Distressed Company\nProbability of Default: 33.2559%\nDistance to Default: 0.43\n</code></pre>"},{"location":"user-guide/credit/merton_model/#visualizations","title":"Visualizations","text":""},{"location":"user-guide/credit/merton_model/#default-probability-and-distance-to-default","title":"Default Probability and Distance to Default","text":"<p>These visualizations show the probability of default and distance to default for three example companies with different financial profiles.</p> <p></p>"},{"location":"user-guide/credit/merton_model/#sensitivity-to-leverage","title":"Sensitivity to Leverage","text":"<p>This analysis demonstrates how the probability of default and distance to default change with increasing leverage (debt-to-asset ratio), highlighting the non-linear relationship between leverage and default risk.</p> <p></p>"},{"location":"user-guide/credit/merton_model/#sensitivity-to-asset-volatility","title":"Sensitivity to Asset Volatility","text":"<p>This analysis shows how the probability of default and distance to default are affected by changes in asset volatility, illustrating the importance of asset stability in credit risk assessment.</p>"},{"location":"user-guide/credit/merton_model/#theoretical-background","title":"Theoretical Background","text":"<p>The Merton model is based on the following assumptions:</p> <ol> <li>The company's capital structure consists of equity and a single zero-coupon debt issue</li> <li>The company's asset value follows a geometric Brownian motion</li> <li>Default occurs only at debt maturity if the asset value falls below the face value of debt</li> <li>Markets are perfect (no transaction costs, taxes, or bankruptcy costs)</li> <li>The risk-free rate is constant</li> </ol> <p>Under these assumptions, the company's equity can be viewed as a European call option on the company's assets with a strike price equal to the face value of debt. The probability of default is then calculated as the probability that the asset value will be below the face value of debt at maturity.</p>"},{"location":"user-guide/credit/merton_model/#practical-applications","title":"Practical Applications","text":"<p>The Merton model can be used for:</p> <ol> <li>Credit Risk Assessment: Estimating default probabilities for corporate borrowers</li> <li>Bond Pricing: Determining credit spreads for corporate bonds</li> <li>Portfolio Management: Assessing the credit risk of investment portfolios</li> <li>Regulatory Capital: Calculating capital requirements for credit risk</li> <li>Early Warning System: Identifying companies with increasing default risk</li> </ol>"},{"location":"user-guide/credit/merton_model/#limitations","title":"Limitations","text":"<p>While the Merton model provides a theoretically sound framework for credit risk assessment, it has several limitations:</p> <ol> <li>Simplified Capital Structure: Assumes a single zero-coupon debt issue</li> <li>Default Timing: Assumes default can only occur at debt maturity</li> <li>Asset Value Unobservability: Requires estimation of unobservable asset value and volatility</li> <li>Constant Volatility: Assumes asset volatility is constant over time</li> <li>Perfect Markets: Ignores transaction costs, taxes, and bankruptcy costs</li> </ol>"},{"location":"user-guide/credit/merton_model/#extensions","title":"Extensions","text":"<p>Several extensions to the basic Merton model have been developed to address its limitations:</p> <ol> <li>KMV Model: Uses an iterative procedure to estimate asset value and volatility</li> <li>Black-Cox Model: Allows for default before maturity if asset value falls below a threshold</li> <li>Longstaff-Schwartz Model: Incorporates stochastic interest rates</li> <li>Leland Model: Accounts for bankruptcy costs and tax benefits of debt</li> <li>CreditGrades Model: Incorporates a stochastic default barrier </li> </ol>"},{"location":"user-guide/credit/scorecard/","title":"Credit Scorecard","text":"<p>The <code>create_scorecard</code> function implements a points-based credit scoring system, which is one of the most widely used approaches in the credit industry. This method assigns points to various borrower characteristics based on their predictive power for credit risk.</p>"},{"location":"user-guide/credit/scorecard/#what-is-a-credit-scorecard","title":"What is a Credit Scorecard?","text":"<p>A credit scorecard is a statistical model that: - Assigns points to different borrower characteristics - Combines these points into a total score - Categorizes applicants into risk segments based on their score - Provides transparency and interpretability in credit decisions</p> <p>Where: - \\(x_i\\) is the value of feature \\(i\\) - \\(\\text{offset}_i\\) is the reference point for feature \\(i\\) - \\(\\text{weight}_i\\) is the importance of feature \\(i\\) - \\(\\text{scaling factor}\\) adjusts the point scale</p>"},{"location":"user-guide/credit/scorecard/#usage-in-pypulate","title":"Usage in Pypulate","text":"<pre><code>from pypulate.credit import create_scorecard\n\n# Define applicant features\nfeatures = {\n    \"age\": 35,\n    \"income\": 75000,\n    \"credit_history\": 0.8,\n    \"debt_ratio\": 0.3,\n    \"payment_history\": 0.95\n}\n\n# Define feature weights (importance)\nweights = {\n    \"age\": 0.5,\n    \"income\": 0.3,\n    \"credit_history\": 2.0,\n    \"debt_ratio\": -1.5,\n    \"payment_history\": 1.8\n}\n\n# Define offsets (reference points)\noffsets = {\n    \"age\": 25,\n    \"income\": 50000,\n    \"credit_history\": 0.5,\n    \"debt_ratio\": 0.4,\n    \"payment_history\": 0.7\n}\n\n# Create the scorecard\nresult = create_scorecard(\n    features=features,\n    weights=weights,\n    offsets=offsets,\n    scaling_factor=100.0,\n    base_score=600\n)\n\n# Access the results\ntotal_score = result[\"total_score\"]\nrisk_category = result[\"risk_category\"]\npoints_breakdown = result[\"points_breakdown\"]\nthresholds = result[\"thresholds\"]  # Dynamic thresholds based on scaling factor\n</code></pre>"},{"location":"user-guide/credit/scorecard/#parameters","title":"Parameters","text":"Parameter Type Description Default <code>features</code> dict Dictionary of feature names and values Required <code>weights</code> dict Dictionary of feature names and weights Required <code>offsets</code> dict Dictionary of feature names and reference points {} <code>scaling_factor</code> float Controls the range of points 100.0 <code>base_score</code> float Starting point for the score calculation 600"},{"location":"user-guide/credit/scorecard/#return-value","title":"Return Value","text":"<p>The function returns a dictionary with the following keys:</p> Key Type Description <code>total_score</code> float The calculated credit score <code>risk_category</code> str Categorization based on the score <code>points_breakdown</code> dict Dictionary showing points contributed by each feature <code>thresholds</code> dict Dictionary of the adjusted thresholds used for risk categorization <p>The <code>points_breakdown</code> dictionary includes: - One key for each feature in the input <code>features</code> dictionary - The value is the points contributed by that feature to the total score</p> <p>The <code>thresholds</code> dictionary includes: - <code>excellent</code>: Threshold for \"Excellent\" risk category - <code>good</code>: Threshold for \"Good\" risk category - <code>fair</code>: Threshold for \"Fair\" risk category - <code>poor</code>: Threshold for \"Poor\" risk category</p>"},{"location":"user-guide/credit/scorecard/#risk-level-classification","title":"Risk Level Classification","text":"<p>The credit score is categorized into risk levels (using reference thresholds for scaling_factor=100.0):</p> Credit Score Range Risk Level \u2265 750 Excellent 700 - 749 Good 650 - 699 Fair 600 - 649 Poor &lt; 600 Very Poor <p>The thresholds are dynamically adjusted based on the scaling factor:</p> <ul> <li>Reference thresholds (for scaling_factor=100.0):</li> <li>Excellent: 750</li> <li>Good: 700</li> <li>Fair: 650</li> <li> <p>Poor: 600</p> </li> <li> <p>For different scaling factors, the thresholds are adjusted using:   <pre><code>adjusted_threshold = base_score + (reference_threshold - base_score) * (reference_scaling / scaling_factor)\n</code></pre></p> </li> </ul> <p>This formula ensures that: - With a smaller scaling factor (e.g., 20.0), thresholds are spread further apart from the base score - With a larger scaling factor (e.g., 500.0), thresholds are compressed closer to the base score</p> <p>This dynamic adjustment ensures that risk categories remain meaningful regardless of the scaling factor used.</p>"},{"location":"user-guide/credit/scorecard/#comprehensive-example","title":"Comprehensive Example","text":"<p>Here's a complete example demonstrating how to create and use a credit scorecard for multiple applicants with different scaling factors:</p> <pre><code>from pypulate.credit import create_scorecard\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Define applicant profiles\nweak_applicant = {\n    \"age\": 20,                  # Young, less stability\n    \"income\": 30000,            # Low income\n    \"credit_history\": 0.3,      # Poor credit record\n    \"debt_ratio\": 0.6,          # High debt\n    \"payment_history\": 0.5      # Frequent late payments\n}\n\nfair_applicant = {\n    \"age\": 40,                  # Mature, more stability\n    \"income\": 70000,            # Above-average income\n    \"credit_history\": 0.75,     # Decent credit record\n    \"debt_ratio\": 0.3,          # Below-average debt\n    \"payment_history\": 0.85     # Mostly on-time payments\n}\n\ngood_applicant = {\n    \"age\": 45,                  # Older, stable\n    \"income\": 90000,            # High income\n    \"credit_history\": 0.9,      # Excellent credit record\n    \"debt_ratio\": 0.15,         # Low debt\n    \"payment_history\": 0.95     # Nearly perfect payment record\n}\n\n# Define feature weights (importance)\nweights = {\n    \"age\": 0.5,                 # Moderate positive impact\n    \"income\": 0.3,              # Moderate positive impact\n    \"credit_history\": 2.0,      # Strong positive impact\n    \"debt_ratio\": -1.5,         # Strong negative impact\n    \"payment_history\": 1.8      # Strong positive impact\n}\n\n# Define offsets (reference points)\noffsets = {\n    \"age\": 25,                  # Reference age\n    \"income\": 50000,            # Reference income\n    \"credit_history\": 0.5,      # Reference credit history\n    \"debt_ratio\": 0.4,          # Reference debt ratio\n    \"payment_history\": 0.7      # Reference payment history\n}\n\n# Create scorecards with different scaling factors\nscaling_factors = [20.0, 100.0, 500.0]\nresults = {}\n\nfor scaling in scaling_factors:\n    results[scaling] = {\n        \"weak\": create_scorecard(\n            features=weak_applicant,\n            weights=weights,\n            offsets=offsets,\n            scaling_factor=scaling,\n            base_score=600\n        ),\n        \"fair\": create_scorecard(\n            features=fair_applicant,\n            weights=weights,\n            offsets=offsets,\n            scaling_factor=scaling,\n            base_score=600\n        ),\n        \"good\": create_scorecard(\n            features=good_applicant,\n            weights=weights,\n            offsets=offsets,\n            scaling_factor=scaling,\n            base_score=600\n        )\n    }\n\n# Print the results for the standard scaling factor (100.0)\nprint(\"Credit Scorecard Results (scaling_factor=100.0)\")\nprint(\"==============================================\")\n\nprint(\"\\nExample 1: Weak Applicant\")\nprint(f\"Total Score: {results[100.0]['weak']['total_score']:.2f}\")\nprint(f\"Risk Category: {results[100.0]['weak']['risk_category']}\")\nprint(\"Points Breakdown:\")\nfor feature, points in results[100.0]['weak']['points_breakdown'].items():\n    print(f\"  {feature}: {points:.2f} points\")\n\nprint(\"\\nExample 2: Fair Applicant\")\nprint(f\"Total Score: {results[100.0]['fair']['total_score']:.2f}\")\nprint(f\"Risk Category: {results[100.0]['fair']['risk_category']}\")\nprint(\"Points Breakdown:\")\nfor feature, points in results[100.0]['fair']['points_breakdown'].items():\n    print(f\"  {feature}: {points:.2f} points\")\n\nprint(\"\\nExample 3: Good Applicant\")\nprint(f\"Total Score: {results[100.0]['good']['total_score']:.2f}\")\nprint(f\"Risk Category: {results[100.0]['good']['risk_category']}\")\nprint(\"Points Breakdown:\")\nfor feature, points in results[100.0]['good']['points_breakdown'].items():\n    print(f\"  {feature}: {points:.2f} points\")\n\n# Print the thresholds for each scaling factor\nprint(\"\\nRisk Category Thresholds\")\nprint(\"=======================\")\nfor scaling in scaling_factors:\n    thresholds = results[scaling]['weak']['thresholds']\n    print(f\"\\nScaling Factor: {scaling}\")\n    for category, threshold in thresholds.items():\n        print(f\"  {category}: {threshold:.2f}\")\n\n# Visualize the results with different scaling factors\nplt.figure(figsize=(15, 8))\n\n# Use the original order of scaling factors\nscaling_factors = [20.0, 100.0, 500.0]\n\n# Create subplots for each scaling factor\nfor i, scaling in enumerate(scaling_factors):\n    plt.subplot(1, 3, i+1)\n\n    applicants = ['Weak', 'Fair', 'Good']\n    scores = [\n        results[scaling]['weak']['total_score'],\n        results[scaling]['fair']['total_score'],\n        results[scaling]['good']['total_score']\n    ]\n\n    # Create a bar chart\n    bars = plt.bar(applicants, scores, color=['red', 'orange', 'green'])\n\n    # Calculate the correct thresholds based on the scaling factor\n    reference_scaling = 100.0\n    reference_thresholds = {\n        \"Excellent\": 750,\n        \"Good\": 700,\n        \"Fair\": 650,\n        \"Poor\": 600\n    }\n\n    # Calculate adjustment factor and thresholds\n    adjustment_factor = reference_scaling / scaling\n    thresholds = {}\n    for category in reference_thresholds:\n        # Correct formula: multiply by adjustment factor instead of dividing\n        thresholds[category] = 600 + (reference_thresholds[category] - 600) * adjustment_factor\n\n    # Calculate the correct y-axis limits for this specific scaling factor\n    min_score = min(min(scores) * 0.9, thresholds['Poor'] * 0.9)  # 10% below the minimum score or threshold\n    max_score = max(max(scores) * 1.1, thresholds['Excellent'] * 1.1)  # 10% above the maximum score or threshold\n\n    # Set y-axis limits\n    plt.ylim(bottom=min_score, top=max_score)\n\n    # Add horizontal lines for the thresholds in the correct order\n    plt.axhline(y=thresholds['Poor'], color='r', linestyle='--', label='Poor')\n    plt.axhline(y=thresholds['Fair'], color='orange', linestyle='--', label='Fair')\n    plt.axhline(y=thresholds['Good'], color='y', linestyle='--', label='Good')\n    plt.axhline(y=thresholds['Excellent'], color='g', linestyle='--', label='Excellent')\n\n    # Add labels and title\n    plt.ylabel('Credit Score')\n    plt.title(f'Scaling Factor: {scaling}')\n\n    # Add the score values on top of the bars\n    for bar in bars:\n        height = bar.get_height()\n        plt.text(bar.get_x() + bar.get_width()/2., height + (max_score - min_score) * 0.02,\n                 f'{height:.1f}', ha='center', va='bottom', fontsize=8)\n\n    # Add legend to the first subplot only\n    if i == 0:\n        plt.legend(loc='upper left')\n\nplt.suptitle('Credit Score Comparison with Different Scaling Factors', fontsize=16)\nplt.tight_layout(rect=[0, 0, 1, 0.95])\nplt.show()\n\n# Create a breakdown chart for points per feature with scaling_factor=100.0\nfeatures = list(results[100.0]['weak']['points_breakdown'].keys())\nweak_points = [results[100.0]['weak']['points_breakdown'][f] for f in features]\nfair_points = [results[100.0]['fair']['points_breakdown'][f] for f in features]\ngood_points = [results[100.0]['good']['points_breakdown'][f] for f in features]\n\nplt.figure(figsize=(12, 6))\nx = np.arange(len(features))\nwidth = 0.25\n\nplt.bar(x - width, weak_points, width, label='Weak Applicant', color='red')\nplt.bar(x, fair_points, width, label='Fair Applicant', color='orange')\nplt.bar(x + width, good_points, width, label='Good Applicant', color='green')\n\nplt.ylabel('Points')\nplt.title('Scorecard Points Breakdown by Feature (scaling_factor=100.0)')\nplt.xticks(x, features)\nplt.legend()\nplt.grid(axis='y')\nplt.tight_layout()\nplt.show()\n\n# Create a visualization showing how thresholds change with different scaling factors\nplt.figure(figsize=(10, 6))\n\n# Extract thresholds for each scaling factor\nscaling_values = np.linspace(10, 500, 100)  # Range of scaling factors from 10 to 500\nthreshold_values = {\n    'Excellent': [],\n    'Good': [],\n    'Fair': [],\n    'Poor': []\n}\n\n# Calculate thresholds for each scaling factor\nfor scaling in scaling_values:\n    # Use the same formula as in the create_scorecard function\n    reference_scaling = 100.0\n    reference_thresholds = {\n        \"Excellent\": 750,\n        \"Good\": 700,\n        \"Fair\": 650,\n        \"Poor\": 600\n    }\n    adjustment_factor = reference_scaling / scaling\n    for category in threshold_values.keys():\n        # Correct formula: multiply by adjustment factor instead of dividing\n        threshold = 600 + (reference_thresholds[category] - 600) * adjustment_factor\n        threshold_values[category].append(threshold)\n\n# Plot the threshold curves\nplt.plot(scaling_values, threshold_values['Excellent'], 'g-', label='Excellent')\nplt.plot(scaling_values, threshold_values['Good'], 'y-', label='Good')\nplt.plot(scaling_values, threshold_values['Fair'], 'orange', label='Fair')\nplt.plot(scaling_values, threshold_values['Poor'], 'r-', label='Poor')\n\n# Add markers for the specific scaling factors used in the example\nfor scaling in scaling_factors:\n    # Calculate thresholds for this scaling factor\n    adjustment_factor = reference_scaling / scaling\n    for category, color in zip(['Excellent', 'Good', 'Fair', 'Poor'], ['g', 'y', 'orange', 'r']):\n        threshold = 600 + (reference_thresholds[category] - 600) * adjustment_factor\n        plt.plot(scaling, threshold, 'o', color=color, markersize=8)\n\n# Add labels and title\nplt.xlabel('Scaling Factor')\nplt.ylabel('Threshold Value')\nplt.title('How Risk Category Thresholds Change with Scaling Factor')\nplt.grid(True)\nplt.legend()\nplt.tight_layout()\nplt.show()\n</code></pre>"},{"location":"user-guide/credit/scorecard/#example-output","title":"Example Output","text":"<pre><code>Credit Scorecard Results (scaling_factor=100.0)\n==============================================\nExample 1: Weak Applicant\nTotal Score: 539.96\nRisk Category: Very Poor\nPoints Breakdown:\n  age: -0.03 points\n  income: -60.00 points\n  credit_history: -0.00 points\n  debt_ratio: -0.00 points\n  payment_history: -0.00 points\nExample 2: Fair Applicant\nTotal Score: 660.08\nRisk Category: Fair\nPoints Breakdown:\n  age: 0.07 points\n  income: 60.00 points\n  credit_history: 0.01 points\n  debt_ratio: 0.00 points\n  payment_history: 0.00 points\nExample 3: Good Applicant\nTotal Score: 720.12\nRisk Category: Good\nPoints Breakdown:\n  age: 0.10 points\n  income: 120.00 points\n  credit_history: 0.01 points\n  debt_ratio: 0.00 points\n  payment_history: 0.00 points\nRisk Category Thresholds\n=======================\nScaling Factor: 20.0\n  Excellent: 630.00\n  Good: 620.00\n  Fair: 610.00\n  Poor: 600.00\nScaling Factor: 100.0\n  Excellent: 750.00\n  Good: 700.00\n  Fair: 650.00\n  Poor: 600.00\nScaling Factor: 500.0\n  Excellent: 1350.00\n  Good: 1100.00\n  Fair: 850.00\n  Poor: 600.00\n</code></pre>"},{"location":"user-guide/credit/scorecard/#visualizations","title":"Visualizations","text":""},{"location":"user-guide/credit/scorecard/#credit-score-comparison-with-different-scaling-factors","title":"Credit Score Comparison with Different Scaling Factors","text":"<p>This visualization shows how the same applicant profiles result in different scores based on the scaling factor used, while still maintaining the same risk categorization due to the dynamic thresholds.</p> <p></p>"},{"location":"user-guide/credit/scorecard/#points-breakdown-by-feature","title":"Points Breakdown by Feature","text":"<p>This visualization shows how each feature contributes to the total score for each applicant, highlighting the strengths and weaknesses of each profile.</p>"},{"location":"user-guide/credit/scorecard/#threshold-scaling-relationship","title":"Threshold Scaling Relationship","text":"<p>This visualization demonstrates how the risk category thresholds change as the scaling factor changes, showing the inverse relationship between scaling factor and threshold spread.</p> <p></p>"},{"location":"user-guide/credit/scorecard/#how-points-are-calculated","title":"How Points Are Calculated","text":"<p>Let's break down the calculation for the fair applicant with scaling_factor=100.0:</p> <ol> <li> <p>Age: (40 - 25) \u00d7 0.5 / 100.0 = 0.075 points</p> <ul> <li>15 years above reference age</li> <li>Moderate positive weight (0.5)</li> <li>Divided by scaling factor (100.0)</li> <li>Results in 0.075 additional points</li> </ul> </li> <li> <p>Income: (70000 - 50000) \u00d7 0.3 / 100.0 = 60.0 points</p> <ul> <li>$20,000 above reference income</li> <li>Moderate positive weight (0.3)</li> <li>Divided by scaling factor (100.0)</li> <li>Results in 60.0 additional points</li> </ul> </li> <li> <p>Credit History: (0.75 - 0.5) \u00d7 2.0 / 100.0 = 0.5 points</p> <ul> <li>0.25 above reference credit history</li> <li>Strong positive weight (2.0)</li> <li>Divided by scaling factor (100.0)</li> <li>Results in 0.5 additional points</li> </ul> </li> <li> <p>Debt Ratio: (0.3 - 0.4) \u00d7 -1.5 / 100.0 = 0.15 points</p> <ul> <li>0.1 below reference debt ratio</li> <li>Strong negative weight (-1.5)</li> <li>Divided by scaling factor (100.0)</li> <li>Being below reference with negative weight results in positive points</li> <li>Results in 0.15 additional points</li> </ul> </li> <li> <p>Payment History: (0.85 - 0.7) \u00d7 1.8 / 100.0 = 0.27 points</p> <ul> <li>0.15 above reference payment history</li> <li>Strong positive weight (1.8)</li> <li>Divided by scaling factor (100.0)</li> <li>Results in 0.27 additional points</li> </ul> </li> <li> <p>Base Score: 600 points</p> </li> <li> <p>Total Score: 600 + 0.075 + 60.0 + 0.5 + 0.15 + 0.27 = 660.995 points</p> </li> <li> <p>Risk Category: Fair (between 650 and 700)</p> <ul> <li>The thresholds are dynamically adjusted based on the scaling factor</li> <li>For scaling_factor=100.0, the thresholds are:<ul> <li>Excellent: 750</li> <li>Good: 700</li> <li>Fair: 650</li> <li>Poor: 600</li> </ul> </li> </ul> </li> </ol>"},{"location":"user-guide/credit/scorecard/#impact-of-scaling-factor","title":"Impact of Scaling Factor","text":"<p>The scaling factor significantly impacts the range of scores:</p> <ol> <li> <p>Small Scaling Factor (e.g., 20.0):</p> <ul> <li>Creates wider score ranges</li> <li>Points have more impact on the total score</li> <li>Thresholds are spread further from the base score</li> </ul> </li> <li> <p>Large Scaling Factor (e.g., 500.0):</p> <ul> <li>Creates narrower score ranges</li> <li>Points have less impact on the total score</li> <li>Thresholds are compressed closer to the base score</li> </ul> </li> <li> <p>Standard Scaling Factor (100.0):</p> <ul> <li>Provides a balanced approach</li> <li>Points have moderate impact on the total score</li> <li>Thresholds are at standard intervals from the base score</li> </ul> </li> </ol> <p>The dynamic threshold adjustment ensures that risk categories remain meaningful regardless of the scaling factor used.</p>"},{"location":"user-guide/credit/scorecard/#benefits-of-the-scorecard-approach","title":"Benefits of the Scorecard Approach","text":"<ol> <li>Transparency: Clear relationship between applicant characteristics and score</li> <li>Customizability: Weights and offsets can be adjusted based on business needs</li> <li>Interpretability: Easy to explain why an applicant received a particular score</li> <li>Consistency: Standardized approach to evaluating creditworthiness</li> <li>Flexibility: Can be applied to various lending contexts (mortgages, auto loans, credit cards)</li> </ol>"},{"location":"user-guide/credit/scorecard/#practical-applications","title":"Practical Applications","text":"<p>The scorecard approach can be used for:</p> <ol> <li>Consumer Lending: Evaluating loan applications</li> <li>Credit Card Approvals: Determining credit limits and interest rates</li> <li>Mortgage Underwriting: Assessing mortgage applicants</li> <li>Small Business Lending: Evaluating business loan applications</li> <li>Tenant Screening: Assessing potential renters</li> </ol>"},{"location":"user-guide/credit/scorecard/#best-practices","title":"Best Practices","text":"<ol> <li>Feature Selection: Choose features with strong predictive power</li> <li>Weight Calibration: Derive weights from statistical analysis of historical data</li> <li>Offset Selection: Set offsets based on population averages or policy considerations</li> <li>Regular Validation: Periodically validate the scorecard against actual outcomes</li> <li>Compliance Checks: Ensure the scorecard complies with fair lending regulations</li> </ol>"},{"location":"user-guide/credit/scoring_model_validation/","title":"Scoring Model Validation","text":"<p>The <code>scoring_model_validation</code> function provides a comprehensive set of metrics and visualizations to evaluate the performance of credit scoring models. This is a critical step in model development to ensure that your scoring system effectively discriminates between good and bad customers.</p>"},{"location":"user-guide/credit/scoring_model_validation/#purpose","title":"Purpose","text":"<p>Credit scoring model validation serves several key purposes:</p> <ol> <li>Assessing the model's discriminatory power</li> <li>Measuring the separation between good and bad customers</li> <li>Evaluating the predictive strength of the model</li> <li>Analyzing the relationship between scores and default rates</li> <li>Providing insights for setting appropriate cutoff thresholds</li> </ol>"},{"location":"user-guide/credit/scoring_model_validation/#usage-in-pypulate","title":"Usage in Pypulate","text":"<pre><code>from pypulate.credit import scoring_model_validation\n\n# Validate a scoring model\nvalidation_results = scoring_model_validation(\n    predicted_scores=scores_array,     # Array of predicted scores\n    actual_defaults=defaults_array,    # Array of actual default outcomes (0/1)\n    score_bins=10                      # Number of score bins for analysis\n)\n\n# Access validation metrics\nauc = validation_results['auc']\ngini = validation_results['gini']\nks_statistic = validation_results['ks_statistic']\ninformation_value = validation_results['information_value']\nconcordance = validation_results['concordance']\n\n# Access ROC curve data\nfpr = validation_results['roc_curve']['fpr']\ntpr = validation_results['roc_curve']['tpr']\nthresholds = validation_results['roc_curve']['thresholds']\n\n# Access bin analysis\nbin_analysis = validation_results['bin_analysis']\n</code></pre>"},{"location":"user-guide/credit/scoring_model_validation/#parameters","title":"Parameters","text":"Parameter Type Description Default <code>predicted_scores</code> array_like Array of predicted scores or probabilities Required <code>actual_defaults</code> array_like Array of actual default outcomes (0/1) Required <code>score_bins</code> int Number of score bins for analysis 10"},{"location":"user-guide/credit/scoring_model_validation/#return-value","title":"Return Value","text":"<p>The function returns a dictionary with the following keys:</p> Key Type Description <code>auc</code> float Area Under the ROC Curve <code>gini</code> float Gini coefficient (2*AUC - 1) <code>ks_statistic</code> float Kolmogorov-Smirnov statistic <code>information_value</code> float Information Value (IV) <code>concordance</code> float Concordance rate <code>roc_curve</code> dict Dictionary containing ROC curve data <code>bin_analysis</code> list List of dictionaries with bin-level statistics <p>The <code>roc_curve</code> dictionary includes: - <code>fpr</code>: False positive rates - <code>tpr</code>: True positive rates - <code>thresholds</code>: Threshold values</p> <p>The <code>bin_analysis</code> list contains dictionaries with the following keys for each bin: - <code>bin_number</code>: Bin number - <code>min_score</code>: Minimum score in the bin - <code>max_score</code>: Maximum score in the bin - <code>count</code>: Number of observations in the bin - <code>default_rate</code>: Default rate in the bin - <code>cumulative_good</code>: Cumulative percentage of good customers - <code>cumulative_bad</code>: Cumulative percentage of bad customers - <code>ks</code>: KS statistic at this bin</p>"},{"location":"user-guide/credit/scoring_model_validation/#risk-level-classification","title":"Risk Level Classification","text":"<p>The key validation metrics are categorized into performance levels:</p> Metric Range Performance Level AUC 0.5-0.6 Poor 0.6-0.7 Fair 0.7-0.8 Good 0.8-0.9 Very Good 0.9-1.0 Excellent Gini 0.0-0.2 Poor 0.2-0.4 Fair 0.4-0.6 Good 0.6-0.8 Very Good 0.8-1.0 Excellent KS Statistic 0.0-0.2 Poor 0.2-0.3 Fair 0.3-0.4 Good 0.4-0.5 Very Good &gt;0.5 Excellent Information Value &lt;0.02 Not Predictive 0.02-0.1 Weak 0.1-0.3 Medium 0.3-0.5 Strong &gt;0.5 Very Strong"},{"location":"user-guide/credit/scoring_model_validation/#comprehensive-example","title":"Comprehensive Example","text":"<p>Here's a complete example demonstrating how to validate a credit scoring model:</p> <pre><code>from pypulate.credit import scoring_model_validation\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Generate synthetic data for demonstration\nnp.random.seed(42)\n\n# Sample size\nn_samples = 1000\n\n# Generate synthetic credit scores (higher score = better credit)\n# Good customers tend to have higher scores, but with more overlap with bad customers\ngood_scores = np.random.normal(650, 120, 800)\ngood_scores = np.clip(good_scores, 300, 850)  # Clip to typical credit score range\n\n# Bad customers tend to have lower scores, but with more overlap with good customers\nbad_scores = np.random.normal(580, 100, 200)\nbad_scores = np.clip(bad_scores, 300, 850)\n\n# Combine scores and create actual default labels (0 = good, 1 = bad)\npredicted_scores = np.concatenate([good_scores, bad_scores])\nactual_defaults = np.concatenate([np.zeros(800), np.ones(200)])\n\n# Shuffle the data\nindices = np.arange(n_samples)\nnp.random.shuffle(indices)\npredicted_scores = predicted_scores[indices]\nactual_defaults = actual_defaults[indices]\n\n# Validate the scoring model\nvalidation_results = scoring_model_validation(\n    predicted_scores=predicted_scores,\n    actual_defaults=actual_defaults,\n    score_bins=10  # Divide scores into 10 bins for analysis\n)\n\n# Print the validation metrics\nprint(\"Model Validation Results:\")\nprint(f\"AUC: {validation_results['auc']:.4f}\")\nprint(f\"Gini Coefficient: {validation_results['gini']:.4f}\")\nprint(f\"KS Statistic: {validation_results['ks_statistic']:.4f}\")\nprint(f\"Information Value: {validation_results['information_value']:.4f}\")\nprint(f\"Concordance: {validation_results['concordance']:.4f}\")\n\n# Print bin analysis\nprint(\"\\nBin Analysis:\")\nprint(\"Bin\\tScore Range\\t\\tCount\\tDefault Rate\")\nprint(\"-\" * 50)\nfor bin_info in validation_results['bin_analysis']:\n    print(f\"{bin_info['bin']}\\t{bin_info['min_score']:.0f}-{bin_info['max_score']:.0f}\\t\\t{bin_info['count']}\\t{bin_info['default_rate']:.2%}\")\n\n# Plot ROC curve\nplt.figure(figsize=(10, 6))\nplt.plot(validation_results['roc_curve']['fpr'], \n         validation_results['roc_curve']['tpr'], \n         label=f\"AUC = {validation_results['auc']:.4f}\")\nplt.plot([0, 1], [0, 1], 'k--', label='Random Model')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n# Plot default rates by score bin\nbins = [b['bin'] for b in validation_results['bin_analysis']]\ndefault_rates = [b['default_rate'] for b in validation_results['bin_analysis']]\n\nplt.figure(figsize=(10, 6))\nplt.bar(bins, default_rates)\nplt.xlabel('Score Bin (Higher = Better Score)')\nplt.ylabel('Default Rate')\nplt.title('Default Rate by Score Bin')\nplt.xticks(bins)\nplt.grid(axis='y')\nplt.show()\n</code></pre>"},{"location":"user-guide/credit/scoring_model_validation/#example-output","title":"Example Output","text":"<pre><code>Model Validation Results:\nAUC: -0.3565\nGini Coefficient: -1.7129\nKS Statistic: 0.2450\nInformation Value: 0.3722\nConcordance: 0.5805\nBin Analysis:\nBin Score Range     Count   Default Rate\n--------------------------------------------------\n1   300-492     100 27.00%\n2   492-536     100 37.00%\n3   536-574     100 22.00%\n4   574-604     100 28.00%\n5   604-638     100 22.00%\n6   638-664     100 19.00%\n7   664-696     100 12.00%\n8   696-732     100 16.00%\n9   732-782     100 13.00%\n10  782-850     100 4.00%\n</code></pre>"},{"location":"user-guide/credit/scoring_model_validation/#visualizations","title":"Visualizations","text":""},{"location":"user-guide/credit/scoring_model_validation/#roc-curve","title":"ROC Curve","text":"<p>The ROC (Receiver Operating Characteristic) curve plots the True Positive Rate against the False Positive Rate at various threshold settings. The area under this curve (AUC) is a measure of the model's discriminatory power.</p>"},{"location":"user-guide/credit/scoring_model_validation/#default-rate-by-score-bin","title":"Default Rate by Score Bin","text":"<p>This visualization shows how default rates decrease as credit scores increase, which is a key indicator of a well-calibrated scoring model.</p> <p></p>"},{"location":"user-guide/credit/scoring_model_validation/#interpreting-the-results","title":"Interpreting the Results","text":"<p>In the example above:</p> <ol> <li> <p>AUC = 0.6845: The model has fair discriminatory power, correctly ranking good and bad customers 68.45% of the time.</p> </li> <li> <p>Gini = 0.3690: This indicates moderate predictive ability, typical of many real-world credit scoring models.</p> </li> <li> <p>KS Statistic = 0.2812: There is fair separation between the distributions of good and bad customers.</p> </li> <li> <p>Information Value = 0.4237: The model has strong predictive power, which is realistic for a credit scoring model in practice.</p> </li> <li> <p>Bin Analysis: Default rates decrease monotonically as scores increase, from 38% in the lowest bin to 2% in the highest bin. This indicates a well-calibrated model with a realistic gradient of risk.</p> </li> </ol>"},{"location":"user-guide/credit/scoring_model_validation/#business-applications","title":"Business Applications","text":"<p>The validation results can be used to:</p> <ol> <li> <p>Set Approval Thresholds: Based on the default rates in each bin, you can set appropriate approval, review, and rejection thresholds.</p> </li> <li> <p>Risk-Based Pricing: Assign different interest rates or terms based on score bins.</p> </li> <li> <p>Portfolio Segmentation: Divide your portfolio into risk segments for targeted management strategies.</p> </li> <li> <p>Model Refinement: Identify areas where the model could be improved.</p> </li> <li> <p>Regulatory Compliance: Demonstrate the statistical validity of your scoring model to regulators.</p> </li> </ol>"},{"location":"user-guide/credit/scoring_model_validation/#best-practices","title":"Best Practices","text":"<ol> <li> <p>Split Sample Validation: Always validate on a holdout sample not used in model development.</p> </li> <li> <p>Regular Revalidation: Periodically revalidate your model to ensure it remains effective over time.</p> </li> <li> <p>Compare Multiple Models: Use these metrics to compare different scoring models.</p> </li> <li> <p>Consider Population Stability: Ensure the validation sample is representative of your target population.</p> </li> <li> <p>Look Beyond the Numbers: While these metrics are important, also consider business context and practical implications.</p> </li> </ol>"},{"location":"user-guide/credit/transition_matrix/","title":"Credit Rating Transition Matrix","text":"<p>The <code>transition_matrix</code> function calculates a credit rating transition matrix, which shows the probability of credit ratings migrating from one level to another over a specified time period. This is a fundamental tool in credit risk management for understanding rating stability and modeling future rating changes.</p>"},{"location":"user-guide/credit/transition_matrix/#usage-in-pypulate","title":"Usage in Pypulate","text":"<pre><code>from pypulate.credit import transition_matrix\n\n# Calculate transition matrix from historical rating data\nresult = transition_matrix(\n    ratings_t0=['AAA', 'AA', 'A', 'BBB', 'BB', 'B', 'CCC'],  # Ratings at time 0\n    ratings_t1=['AA', 'A', 'BBB', 'BB', 'B', 'CCC', 'D']     # Ratings at time 1\n)\n\n# Access the results\nprob_matrix = result[\"probability_matrix\"]\ntrans_matrix = result[\"transition_matrix\"]\nratings = result[\"ratings\"]\n</code></pre>"},{"location":"user-guide/credit/transition_matrix/#parameters","title":"Parameters","text":"Parameter Type Description Default <code>ratings_t0</code> array_like Array of credit ratings at the beginning of the period Required <code>ratings_t1</code> array_like Array of credit ratings at the end of the period Required"},{"location":"user-guide/credit/transition_matrix/#return-value","title":"Return Value","text":"<p>The function returns a dictionary with the following keys:</p> Key Type Description <code>transition_matrix</code> list of lists Count of transitions from each rating to each other rating <code>probability_matrix</code> list of lists Probability of transitioning from each rating to each other rating <code>ratings</code> list Unique ratings found in the input data"},{"location":"user-guide/credit/transition_matrix/#risk-level-classification","title":"Risk Level Classification","text":"<p>Credit ratings are typically categorized into risk levels:</p> Rating Category Risk Level AAA, AA Investment Grade - Very Low Risk A, BBB Investment Grade - Low to Moderate Risk BB, B Non-Investment Grade - Moderate to High Risk CCC, CC, C Non-Investment Grade - Very High Risk D Default"},{"location":"user-guide/credit/transition_matrix/#comprehensive-example","title":"Comprehensive Example","text":"<p>Here's a complete example demonstrating how to calculate and analyze credit rating transitions:</p> <pre><code>from pypulate.credit import transition_matrix\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom collections import Counter\n\n# Sample historical rating data\n# Let's create a dataset with 100 companies and their ratings over two periods\nnp.random.seed(42)  # For reproducibility\n\n# Define possible ratings\nratings = ['AAA', 'AA', 'A', 'BBB', 'BB', 'B', 'CCC', 'D']\n\n# Generate initial ratings with a distribution skewed toward investment grade\nweights = [0.05, 0.15, 0.25, 0.25, 0.15, 0.10, 0.05, 0.00]  # No defaults at t0\ninitial_ratings = np.random.choice(ratings, size=100, p=weights)\n\n# Create a simple model for rating transitions\n# Higher ratings are more stable, lower ratings have higher probability of downgrade\ndef generate_next_rating(current_rating):\n    current_idx = ratings.index(current_rating)\n\n    if current_rating == 'D':\n        return 'D'  # Default is an absorbing state\n\n    # Probability of staying at the same rating\n    stay_prob = 0.7 - 0.05 * current_idx  # Higher ratings are more stable\n\n    # Probability of upgrading (less likely for higher ratings)\n    if current_idx == 0:\n        upgrade_prob = 0  # AAA can't be upgraded\n    else:\n        upgrade_prob = 0.05 * (8 - current_idx) / 7  # More room for upgrade at lower ratings\n\n    # Probability of downgrading (more likely for lower ratings)\n    downgrade_prob = 1 - stay_prob - upgrade_prob\n\n    # Determine direction of movement\n    r = np.random.random()\n    if r &lt; stay_prob:\n        return current_rating\n    elif r &lt; stay_prob + upgrade_prob:\n        return ratings[current_idx - 1]  # Upgrade\n    else:\n        # For downgrades, allow for multi-notch downgrades for lower ratings\n        if current_idx &gt;= 5:  # B or lower\n            # Possible to skip directly to default\n            possible_downgrades = ratings[current_idx+1:]\n            return np.random.choice(possible_downgrades)\n        else:\n            return ratings[current_idx + 1]  # Single notch downgrade\n\n# Generate ratings at time 1\nfinal_ratings = [generate_next_rating(rating) for rating in initial_ratings]\n\n# Calculate the transition matrix\nresult = transition_matrix(initial_ratings, final_ratings)\n\n# Print the transition probability matrix\nprint(\"Credit Rating Transition Matrix (Probabilities)\")\nprint(\"==============================================\")\nprob_matrix = result['probability_matrix']\nunique_ratings = result['ratings']\n\n# Print the matrix with proper formatting\nprint(f\"{'':5}\", end=\"\")\nfor r in unique_ratings:\n    print(f\"{r:6}\", end=\"\")\nprint()\n\nfor i, row in enumerate(prob_matrix):\n    print(f\"{unique_ratings[i]:5}\", end=\"\")\n    for val in row:\n        print(f\"{val:.2f}  \", end=\"\")\n    print()\n\n# Calculate some statistics\ndowngrades = sum(1 for i, j in zip(initial_ratings, final_ratings) \n                if ratings.index(j) &gt; ratings.index(i))\nupgrades = sum(1 for i, j in zip(initial_ratings, final_ratings) \n              if ratings.index(j) &lt; ratings.index(i))\nsame = sum(1 for i, j in zip(initial_ratings, final_ratings) if i == j)\ndefaults = sum(1 for rating in final_ratings if rating == 'D')\n\nprint(\"\\nTransition Statistics:\")\nprint(f\"Total Entities: {len(initial_ratings)}\")\nprint(f\"Upgrades: {upgrades} ({upgrades/len(initial_ratings):.1%})\")\nprint(f\"Downgrades: {downgrades} ({downgrades/len(initial_ratings):.1%})\")\nprint(f\"Unchanged: {same} ({same/len(initial_ratings):.1%})\")\nprint(f\"Defaults: {defaults} ({defaults/len(initial_ratings):.1%})\")\n\n# Visualize the transition matrix as a heatmap using matplotlib\nplt.figure(figsize=(10, 8))\nplt.imshow(prob_matrix, cmap='YlGnBu', aspect='equal')\nplt.colorbar(label='Transition Probability')\n\n# Add text annotations to the heatmap\nfor i in range(len(unique_ratings)):\n    for j in range(len(unique_ratings)):\n        plt.text(j, i, f\"{prob_matrix[i][j]:.2f}\", \n                 ha=\"center\", va=\"center\", \n                 color=\"black\" if prob_matrix[i][j] &lt; 0.7 else \"white\")\n\n# Set ticks and labels\nplt.xticks(range(len(unique_ratings)), unique_ratings)\nplt.yticks(range(len(unique_ratings)), unique_ratings)\nplt.xlabel('Rating at Time 1')\nplt.ylabel('Rating at Time 0')\nplt.title('Credit Rating Transition Matrix')\nplt.tight_layout()\nplt.show()\n\n# Visualize rating distribution before and after\nplt.figure(figsize=(12, 6))\n\n# Count ratings at each time period\nt0_counts = {r: 0 for r in ratings}\nt1_counts = {r: 0 for r in ratings}\n\n# Update with actual counts\nfor r in initial_ratings:\n    t0_counts[r] += 1\nfor r in final_ratings:\n    t1_counts[r] += 1\n\n# Create bar chart\nx = np.arange(len(ratings))\nwidth = 0.35\n\nfig, ax = plt.subplots(figsize=(12, 6))\nax.bar(x - width/2, [t0_counts[r] for r in ratings], width, label='Time 0')\nax.bar(x + width/2, [t1_counts[r] for r in ratings], width, label='Time 1')\n\n# Add labels and legend\nax.set_xlabel('Credit Rating')\nax.set_ylabel('Number of Entities')\nax.set_title('Rating Distribution: Before vs After')\nax.set_xticks(x)\nax.set_xticklabels(ratings)\nax.legend()\nax.grid(axis='y', linestyle='--', alpha=0.7)\n\nplt.tight_layout()\nplt.show()\n\n# Calculate and visualize the default rates by initial rating\ndefault_rates = []\nfor rating in ratings[:-1]:  # Exclude 'D' as initial rating\n    entities_with_rating = sum(1 for r in initial_ratings if r == rating)\n    if entities_with_rating &gt; 0:\n        defaults_from_rating = sum(1 for i, j in zip(initial_ratings, final_ratings) \n                                  if i == rating and j == 'D')\n        default_rate = defaults_from_rating / entities_with_rating\n    else:\n        default_rate = 0\n    default_rates.append(default_rate)\n\nplt.figure(figsize=(10, 6))\nplt.bar(ratings[:-1], [rate * 100 for rate in default_rates], color='darkred')\nplt.title('Default Rate by Initial Credit Rating')\nplt.xlabel('Initial Credit Rating')\nplt.ylabel('Default Rate (%)')\nplt.grid(axis='y', linestyle='--', alpha=0.7)\nplt.tight_layout()\nplt.show()\n</code></pre>"},{"location":"user-guide/credit/transition_matrix/#example-output","title":"Example Output","text":"<pre><code>Credit Rating Transition Matrix (Probabilities)\n==============================================\n     A     AA    AAA   B     BB    BBB   CCC   D     \nA    0.52  0.00  0.00  0.00  0.00  0.48  0.00  0.00  \nAA   0.23  0.68  0.09  0.00  0.00  0.00  0.00  0.00  \nAAA  0.00  0.33  0.67  0.00  0.00  0.00  0.00  0.00  \nB    0.00  0.00  0.00  0.50  0.00  0.00  0.00  0.50  \nBB   0.00  0.00  0.00  0.53  0.35  0.12  0.00  0.00  \nBBB  0.00  0.00  0.00  0.00  0.33  0.67  0.00  0.00  \nCCC  0.00  0.00  0.00  0.00  0.00  0.00  0.40  0.60  \nD    0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  \n\nTransition Statistics:\nTotal Entities: 100\nUpgrades: 4 (4.0%)\nDowngrades: 40 (40.0%)\nUnchanged: 56 (56.0%)\nDefaults: 7 (7.0%)\n</code></pre>"},{"location":"user-guide/credit/transition_matrix/#visualizations","title":"Visualizations","text":""},{"location":"user-guide/credit/transition_matrix/#transition-matrix-heatmap","title":"Transition Matrix Heatmap","text":"<p>This visualization shows the probability of transitioning from one rating to another as a color-coded heatmap, with darker colors indicating higher probabilities.</p> <p></p>"},{"location":"user-guide/credit/transition_matrix/#rating-distribution","title":"Rating Distribution","text":"<p>This bar chart compares the distribution of ratings at the beginning and end of the period, showing how the overall credit quality of the portfolio has changed.</p> <p></p>"},{"location":"user-guide/credit/transition_matrix/#default-rates-by-initial-rating","title":"Default Rates by Initial Rating","text":"<p>This visualization shows the relationship between initial credit rating and default rate, illustrating the higher default probabilities associated with lower credit ratings.</p>"},{"location":"user-guide/credit/transition_matrix/#practical-applications","title":"Practical Applications","text":"<p>Credit rating transition matrices can be used for:</p> <ol> <li>Credit Portfolio Management: Modeling the evolution of portfolio credit quality over time</li> <li>Economic Capital Calculation: Estimating potential credit losses under various scenarios</li> <li>Pricing Credit-Sensitive Instruments: Determining appropriate spreads for bonds and loans</li> <li>Stress Testing: Analyzing the impact of economic downturns on credit quality</li> <li>Regulatory Compliance: Meeting requirements for internal ratings-based approaches under Basel frameworks</li> </ol>"},{"location":"user-guide/credit/transition_matrix/#methodological-considerations","title":"Methodological Considerations","text":"<p>When calculating transition matrices, several methodological issues should be considered:</p> <ol> <li>Time Horizon: Transition probabilities depend on the length of the observation period (e.g., 1-year vs. 5-year)</li> <li>Rating Withdrawals: How to handle entities whose ratings are withdrawn during the period</li> <li>Point-in-Time vs. Through-the-Cycle: Whether to use ratings that reflect current conditions or long-term averages</li> <li>Cohort vs. Hazard Rate Method: Different approaches to calculating transition probabilities</li> <li>Economic Conditions: Transition probabilities vary across different phases of the economic cycle</li> </ol>"},{"location":"user-guide/credit/transition_matrix/#limitations","title":"Limitations","text":"<p>Credit rating transition matrices have several limitations:</p> <ol> <li>Rating Stability Bias: Rating agencies may be slow to change ratings, leading to underestimation of transition probabilities</li> <li>Limited History: For newer rating categories or markets, historical data may be insufficient</li> <li>Non-Markovian Behavior: Future rating changes may depend on rating history, not just current rating</li> <li>Heterogeneity Within Ratings: Entities with the same rating may have different default probabilities</li> <li>Time Variation: Transition probabilities change over time with economic conditions </li> </ol>"},{"location":"user-guide/credit/weight_of_evidence/","title":"Weight of Evidence (WOE) and Information Value (IV)","text":"<p>The <code>weight_of_evidence</code> function calculates Weight of Evidence (WOE) and Information Value (IV), which are powerful techniques used in credit scoring and risk modeling to assess the predictive power of variables and transform them into a format suitable for logistic regression models.</p>"},{"location":"user-guide/credit/weight_of_evidence/#usage-in-pypulate","title":"Usage in Pypulate","text":"<pre><code>from pypulate.credit import weight_of_evidence\n\n# Calculate WOE and IV for a variable's bins\nresult = weight_of_evidence(\n    good_count=[100, 80, 50, 30, 10],  # Count of non-default cases in each bin\n    bad_count=[5, 10, 15, 20, 25]      # Count of default cases in each bin\n)\n\n# Access the results\nwoe_values = result[\"woe\"]\niv = result[\"information_value\"]\niv_strength = result[\"iv_strength\"]\n</code></pre>"},{"location":"user-guide/credit/weight_of_evidence/#parameters","title":"Parameters","text":"Parameter Type Description Default <code>good_count</code> array_like Count of good cases (non-defaults) in each bin Required <code>bad_count</code> array_like Count of bad cases (defaults) in each bin Required <code>min_samples</code> float Minimum percentage of samples required in a bin 0.01 <code>adjustment</code> float Adjustment factor for zero counts 0.5"},{"location":"user-guide/credit/weight_of_evidence/#return-value","title":"Return Value","text":"<p>The function returns a dictionary with the following keys:</p> Key Type Description <code>woe</code> list Weight of Evidence values for each bin <code>information_value</code> float Information Value, measuring the overall predictive power <code>iv_strength</code> str Qualitative assessment of the IV strength <code>good_distribution</code> list Distribution of good cases across bins <code>bad_distribution</code> list Distribution of bad cases across bins <code>small_bins</code> list Boolean flags indicating bins with too few samples"},{"location":"user-guide/credit/weight_of_evidence/#risk-level-classification","title":"Risk Level Classification","text":"<p>Information Value (IV) is typically categorized into predictive power levels:</p> IV Range Predictive Power &lt; 0.02 Not predictive 0.02 - 0.1 Weak predictive power 0.1 - 0.3 Medium predictive power 0.3 - 0.5 Strong predictive power &gt; 0.5 Very strong predictive power"},{"location":"user-guide/credit/weight_of_evidence/#comprehensive-example","title":"Comprehensive Example","text":"<p>Here's a complete example demonstrating how to calculate and analyze Weight of Evidence and Information Value:</p> <pre><code>from pypulate.credit import weight_of_evidence\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Sample data: Age bins and default counts\nage_bins = [\"18-25\", \"26-35\", \"36-45\", \"46-55\", \"56-65\", \"65+\"]\nnon_defaults = [150, 450, 600, 500, 300, 200]  # Good cases\ndefaults = [50, 70, 60, 40, 30, 50]            # Bad cases\n\n# Calculate WOE and IV\nresult = weight_of_evidence(non_defaults, defaults)\n\n# Print the results\nprint(\"Weight of Evidence Analysis\")\nprint(\"==========================\")\nprint(f\"Information Value: {result['information_value']:.4f}\")\nprint(f\"Predictive Power: {result['iv_strength']}\")\nprint(\"\\nBin Analysis:\")\nprint(f\"{'Age Bin':&lt;10} {'Non-Defaults':&lt;15} {'Defaults':&lt;15} {'WOE':&lt;10} {'Small Bin':&lt;10}\")\nprint(\"-\" * 60)\n\nfor i, bin_name in enumerate(age_bins):\n    print(f\"{bin_name:&lt;10} {non_defaults[i]:&lt;15} {defaults[i]:&lt;15} {result['woe'][i]:&gt;+.4f} {'Yes' if result['small_bins'][i] else 'No':&lt;10}\")\n\n# Calculate default rates for comparison\ndefault_rates = [d/(d+n) for d, n in zip(defaults, non_defaults)]\n\n# Visualize WOE values\nplt.figure(figsize=(12, 8))\n\n# Create a subplot for WOE values\nplt.subplot(2, 1, 1)\nbars = plt.bar(age_bins, result['woe'], color='skyblue')\nplt.axhline(y=0, color='r', linestyle='-', alpha=0.3)\nplt.title('Weight of Evidence by Age Group')\nplt.ylabel('WOE Value')\nplt.grid(axis='y', linestyle='--', alpha=0.7)\n\n# Add value labels on top of bars\nfor bar in bars:\n    height = bar.get_height()\n    plt.text(bar.get_x() + bar.get_width()/2., \n             height + (0.1 if height &gt;= 0 else -0.1),\n             f'{height:.2f}', \n             ha='center', va='bottom' if height &gt;= 0 else 'top')\n\n# Create a subplot for default rates\nplt.subplot(2, 1, 2)\nplt.bar(age_bins, default_rates, color='salmon')\nplt.title('Default Rate by Age Group')\nplt.ylabel('Default Rate')\nplt.grid(axis='y', linestyle='--', alpha=0.7)\n\n# Add value labels on top of bars\nfor i, v in enumerate(default_rates):\n    plt.text(i, v + 0.01, f'{v:.2%}', ha='center')\n\nplt.tight_layout()\nplt.show()\n\n# Visualize distributions\nplt.figure(figsize=(12, 6))\n\nx = np.arange(len(age_bins))\nwidth = 0.35\n\nfig, ax = plt.subplots(figsize=(12, 6))\nax.bar(x - width/2, result['good_distribution'], width, label='Good Distribution')\nax.bar(x + width/2, result['bad_distribution'], width, label='Bad Distribution')\n\nax.set_xlabel('Age Group')\nax.set_ylabel('Distribution')\nax.set_title('Distribution of Good vs Bad Cases')\nax.set_xticks(x)\nax.set_xticklabels(age_bins)\nax.legend()\nax.grid(axis='y', linestyle='--', alpha=0.7)\n\nplt.tight_layout()\nplt.show()\n\n# Calculate and visualize the contribution to IV\niv_contributions = [(g - b) * w for g, b, w in zip(\n    result['good_distribution'], \n    result['bad_distribution'], \n    result['woe']\n)]\n\nplt.figure(figsize=(10, 6))\nplt.bar(age_bins, iv_contributions, color='green')\nplt.title('Contribution to Information Value by Age Group')\nplt.xlabel('Age Group')\nplt.ylabel('IV Contribution')\nplt.grid(axis='y', linestyle='--', alpha=0.7)\n\n# Add value labels\nfor i, v in enumerate(iv_contributions):\n    plt.text(i, v + 0.001, f'{v:.4f}', ha='center')\n\nplt.tight_layout()\nplt.show()\n</code></pre>"},{"location":"user-guide/credit/weight_of_evidence/#example-output","title":"Example Output","text":"<pre><code>Weight of Evidence Analysis\n==========================\nInformation Value: 0.2217\nPredictive Power: Medium predictive power\nBin Analysis:\nAge Bin    Non-Defaults    Defaults        WOE        Small Bin \n------------------------------------------------------------\n18-25      150             50              -0.8938 No        \n26-35      450             70              -0.1317 No        \n36-45      600             60              +0.3102 No        \n46-55      500             40              +0.5333 No        \n56-65      300             30              +0.3102 No        \n65+        200             50              -0.6061 No        \n</code></pre>"},{"location":"user-guide/credit/weight_of_evidence/#visualizations","title":"Visualizations","text":""},{"location":"user-guide/credit/weight_of_evidence/#weight-of-evidence-by-age-group","title":"Weight of Evidence by Age Group","text":"<p>This visualization shows the WOE values for each age bin. Positive values indicate lower risk (fewer defaults than expected), while negative values indicate higher risk (more defaults than expected).</p> <p></p>"},{"location":"user-guide/credit/weight_of_evidence/#default-rate-by-age-group","title":"Default Rate by Age Group","text":"<p>This chart shows the actual default rate for each age group, providing context for the WOE values.</p>"},{"location":"user-guide/credit/weight_of_evidence/#distribution-of-good-vs-bad-cases","title":"Distribution of Good vs Bad Cases","text":"<p>This bar chart compares the distribution of good cases (non-defaults) and bad cases (defaults) across the different age groups.</p>"},{"location":"user-guide/credit/weight_of_evidence/#contribution-to-information-value","title":"Contribution to Information Value","text":"<p>This visualization shows how much each bin contributes to the overall Information Value, helping identify which groups have the strongest discriminatory power.</p>"},{"location":"user-guide/credit/weight_of_evidence/#practical-applications","title":"Practical Applications","text":"<p>Weight of Evidence and Information Value are used for:</p> <ol> <li>Variable Selection: Identifying which variables have the strongest predictive power for credit scoring models</li> <li>Risk Segmentation: Creating meaningful risk segments based on variable characteristics</li> <li>Logistic Regression Preparation: Transforming categorical and continuous variables into WOE values for logistic regression</li> <li>Scorecard Development: Creating credit scorecards with optimal binning and variable transformation</li> <li>Model Validation: Assessing the predictive power of variables in existing models</li> </ol>"},{"location":"user-guide/credit/weight_of_evidence/#methodological-considerations","title":"Methodological Considerations","text":"<p>When calculating WOE and IV, several methodological issues should be considered:</p> <ol> <li>Binning Strategy: How to create optimal bins for continuous variables (equal width, equal frequency, or custom)</li> <li>Handling Zero Counts: Applying adjustments to avoid infinity values when a bin has zero good or bad cases</li> <li>Minimum Sample Size: Ensuring each bin has sufficient samples for reliable WOE calculation</li> <li>Monotonicity: Whether WOE values should be monotonic across ordered bins</li> <li>Outlier Treatment: How to handle extreme values that might distort WOE calculations</li> </ol>"},{"location":"user-guide/credit/weight_of_evidence/#limitations","title":"Limitations","text":"<p>Weight of Evidence and Information Value have several limitations:</p> <ol> <li>Univariate Analysis: They assess variables individually, not accounting for interactions</li> <li>Binning Dependency: Results can vary significantly based on the binning strategy</li> <li>Overfitting Risk: Excessive binning can lead to overfitting</li> <li>Interpretability Tradeoff: While WOE transformation improves model performance, it can reduce interpretability</li> <li>Population Stability: WOE values calculated on one population may not be valid for another </li> </ol>"}]}